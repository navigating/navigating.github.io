<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>On The Open Way</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description">
<meta property="og:type" content="website">
<meta property="og:title" content="On The Open Way">
<meta property="og:url" content="http://navigating.github.io/index.html">
<meta property="og:site_name" content="On The Open Way">
<meta property="og:description">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="On The Open Way">
<meta name="twitter:description">
<meta name="twitter:creator" content="@xujinghui">
  
    <link rel="alternative" href="/atom.xml" title="On The Open Way" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  <link rel="stylesheet" href="/css/style.css" type="text/css">
  
<script type="text/javascript">
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "//hm.baidu.com/hm.js?5554b1765137f9e84f6b5d1958c4bdfd";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>

  

  <script type="text/javascript">
  (function(w,d,t,u,n,s,e){w['SwiftypeObject']=n;w[n]=w[n]||function(){
  (w[n].q=w[n].q||[]).push(arguments);};s=d.createElement(t);
  e=d.getElementsByTagName(t)[0];s.async=1;s.src=u;e.parentNode.insertBefore(s,e);
  })(window,document,'script','//s.swiftypecdn.com/install/v2/st.js','_st');

  _st('install','W7_-_9WqoJq6hWaJJ8zZ','2.0.0');
</script>
</head>
<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">On The Open Way</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="/" id="subtitle">自信人生二百年，会当水击三千里！</a>
        </h2>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
          <a class="main-nav-link" href="/sitemap.xml">Sitemap</a>
        
      </nav>
      <nav id="sub-nav">	    
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>		
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" results="0" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://navigating.github.io"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main">
  
    <article id="post-2015/JVM监控与调优" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2015/JVM监控与调优/" class="article-date">
  <time datetime="2015-11-06T07:53:46.000Z" itemprop="datePublished">2015-11-06</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/技术/">技术</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2015/JVM监控与调优/">JVM监控与调优</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="题外话">题外话</h2><p>本文当前的范围是Java 8之前的虚拟机，因为Java 8之后虚拟机的架构有比较大的调整，存储类的元数据信息的永久代被删除了，而是放在虚拟机的元空间。<br>JDK 7及之前的版本中永久代有如下的特点：</p>
<ol>
<li>永久代和堆在内存分配上是相连的；</li>
<li>永久代的垃圾回收和老年代的垃圾回收是绑定的，一旦其中一个区域被占满，这两个区都要进行垃圾回收；</li>
<li>永久代一段连续的内存空间，在32位机器默认的永久代的大小为64M，64位的机器则为85M；当然，在JVM启动之前可以通过设置-XX:MaxPermSize的值来控制永久代的大小；</li>
</ol>
<h2 id="Java虚拟机">Java虚拟机</h2><p>Java虚拟机的架构如下图，其中和性能调优相关的组件有三个：Heap，JIT compiler 和 Garbage Collector。<br><img src="https://raw.githubusercontent.com/stevenxu/tuku/master/navigating.github.io/2015/JVM_Arch_001.PNG" alt="这是一张图片"></p>
<p>针对内存堆heap中创建的Java对象，采用的是垃圾回收机制进行处理。垃圾回收在Oracle官网叫 Automatic Garbage Collection，其目的寻找确定堆内存中哪些对象在使用，哪些不在使用，并且删除销毁那些不在使用的对象。<br>垃圾回收分为三步：</p>
<ol>
<li>标记，Marking<br>这个阶段识别出哪些对象正在使用，哪些对象不再使用，不再使用的对象标记为可回收的对象，在使用的对象标记为不可回收。在标记阶段需要对所有的对象进行全扫描来做决策。<br><img src="https://raw.githubusercontent.com/stevenxu/tuku/master/navigating.github.io/2015/JVM_Arch_003.PNG" alt="这是一张图片"></li>
<li>清除，Normal Deletion<br>这个阶段移除那些没有被引用的Java对象，并释放内存空间。<br><img src="https://raw.githubusercontent.com/stevenxu/tuku/master/navigating.github.io/2015/JVM_Arch_004.PNG" alt="这是一张图片"></li>
<li>压缩，Deletion with Compacting<br>为了更好的性能，需要对不可回收依然使用的对象进行压缩，就是把这一类对象迁移在一起，使得新内存的分配变得的更容易和更快。<br><img src="https://raw.githubusercontent.com/stevenxu/tuku/master/navigating.github.io/2015/JVM_Arch_005.PNG" alt="这是一张图片"></li>
</ol>
<h2 id="分代垃圾回收(Generational_Garbage_Collection)">分代垃圾回收(Generational Garbage Collection)</h2><p>由于标记和压缩堆内存中所有的对象是十分低效的，并且随着越来越多的对象被分配，垃圾回收的时间也会变得越来越长，因此引入引入了如下的回收策略：按着对象存活的时间窗口采用不同的垃圾回收机制，即是 Minor collections 和 Major collections。如下图：<br><img src="https://raw.githubusercontent.com/stevenxu/tuku/master/navigating.github.io/2015/JVM_Arch_006.gif" alt="这是一张图片"><br>其中Y轴标识已分配的字节数，X轴标识随着时间已经被分配内存并且处于使用状态的字节数的情况。从这张图可以看出，只有很少的对象能够长时间需要保留下来，大部分对象只有很短的生命周期。</p>
<p>Java Hotspot Heap结构：<br><img src="https://raw.githubusercontent.com/stevenxu/tuku/master/navigating.github.io/2015/JVM_Arch_002.PNG" alt="这是一张图片"><br>Hotspot内存由三部分组成：</p>
<ol>
<li>持久代，Permanent Generation：存储类和对象元数据的数据的地方，包括类的层级信息，方法数据和方法信息（如字节码，栈和变量大小），运行时常量池，已确定的符号引用和虚方法表。</li>
<li>年轻代，Young Generation：分为三个区，一个Eden区，两个Survivor区。新生代主要是存放新生成的Java对象，新生代的垃圾回收称为 minor garbage collection。</li>
<li>年老代，Old Genration： 即是Tenured区，存放在年轻代经过多次垃圾回收依然存活的对象的区域，年老代的垃圾回收称为 major garbage collection。</li>
</ol>
<h2 id="垃圾回收触发时机">垃圾回收触发时机</h2><p>Minor Collection<br>    在Eden空间已满，新对象申请空间失败时，就会触发Minor Collection，对Eden区域进行GC，清除非存活对象，并把尚且存活的对象移动到Survivor区。然后整理Survivor的两个区。这种方式的GC是对年轻代的Eden区进行，不会影响到年老代。因为大部分对象都是从Eden区开始的，同时Eden区不会分配的很大，所以Eden区的GC会频繁进行。因而，一般在这里需要使用速度快、效率高的算法，使Eden去能尽快空闲出来。</p>
<p>Major Collection(Full GC)<br>    对整个堆进行整理，包括Young、Tenured和Perm。Major Collection因为需要对整个对进行回收，所以比Minor Collection要慢，因此应该尽可能减少Full GC的次数。在对JVM调优的过程中，很大一部分工作就是对于Major Collection的调节。有如下原因可能导致Full GC：</p>
<ol>
<li>年老代（Tenured）被写满;</li>
<li>持久代（Perm）被写满;</li>
<li>System.gc()被显示调用;</li>
<li>上一次GC之后Heap的各域分配策略动态变化;</li>
</ol>
<h2 id="Garbage_Collector">Garbage Collector</h2><p>经过发展，Java已有如下的垃圾回收器：</p>
<ol>
<li><p>Serial收集器/SerialOld收集器<br>Serial收集器/Serial Old收集器，是单线程的，使用“复制”算法。当它工作时，必须暂停其它所有工作线程。特点：简单而高效。对于运行在Client模式下的虚拟机来说是一个很好的选择。<br>串行收集器并不是只能使用一个CPU进行收集，而是当JVM需要进行垃圾回收的时候，需要中断所有的用户线程，知道它回收结束为止，因此又号称“Stop The World” 的垃圾回收器。<br>Serial收集器默认新旧生代的回收器搭配为Serial+ SerialOld</p>
</li>
<li><p>ParNew收集器<br>ParNew收集器其实就是多线程版本的Serial收集器，同样有<br>Stop The World的问题，他是多CPU模式下的首选回收器（该回收器在单CPU的环境下回收效率远远低于Serial收集器，所以一定要注意场景哦），也是Server模式下默认的新生代收集器。除了Serial收集器外，目前只有它能与CMS收集器配合工作。</p>
</li>
<li><p>ParallelScavenge/ParallelOld收集器<br>ParallelScavenge又被称为是吞吐量优先的收集器，也是使用“复制”算法的、并行的多线程收集器。这些都和ParNew收集器一样。但它关注的是吞吐量（CPU用于运行用户代码的时间与CPU总消耗时间的比值），而其它收集器（Serial/Serial Old、ParNew、CMS）关注的是垃圾收集时用户线程的停顿时间。<br>Parallel Old收集器是Parallel Scavenge收集器的老年代版本。</p>
</li>
<li><p>CMS<br>CMS(Concurrent Mark Sweep）)又称响应时间优先(最短回收停顿)的回收器，使用并发模式回收垃圾，使用”标记-清除“算法，CMS对CPU是非常敏感的，它的回收线程数=（CPU+3）/4，因此当CPU是2核的实惠，回收线程将占用的CPU资源的50%，而当CPU核心数为4时仅占用25%。<br>CMS收集器分4个步骤进行垃圾收集工作：<br>a. 初始标记(CMS initial mark)<br>b. 并发标记(CMS concurrent mark)<br>c. 重新标记(CMS remark)<br>d. 并发清除(CMS concurrent sweep)</p>
</li>
<li><p>GarbageFirst(G1)<br>G1（Garbage First）收集器，基于“标记-整理”算法，可以非常精确地控制停顿。其实这是一个新的垃圾回收器，既可以回收新生代也可以回收旧生代，SunHotSpot 1.6u14以上EarlyAccess版本加入了这个回收器</p>
</li>
</ol>
<h2 id="监控命令">监控命令</h2><p>JDK自带的性能调优监控工具，包括：VisualVM、jConsole、jps、jstack、jmap、jhat、jstat、hprof等。<br>jstack 主要用于查看Java进程内的线程堆栈信息。<br>例子：<br><figure class="highlight vala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="preprocessor"># jps</span></span><br><span class="line"><span class="number">6923</span> HelloWorld</span><br><span class="line"><span class="number">14009</span> Jps</span><br><span class="line"></span><br><span class="line"><span class="preprocessor"># jstack -m 6923</span></span><br></pre></td></tr></table></figure></p>
<p>jmap 主要用于查看堆内存的使用情况。<br>例子：<br><figure class="highlight dns"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line"># jmap -heap 6923 </span><br><span class="line">Attaching to process ID 6923, please wait...</span><br><span class="line">Debugger attached successfully.</span><br><span class="line">Server compiler detected.</span><br><span class="line">JVM version is 24.65-b04</span><br><span class="line"></span><br><span class="line">using parallel threads in the new generation.</span><br><span class="line">using thread-local object allocation.</span><br><span class="line">Concurrent Mark-Sweep GC</span><br><span class="line"></span><br><span class="line">Heap Configuration:</span><br><span class="line">   MinHeapFreeRatio = 40</span><br><span class="line">   MaxHeapFreeRatio = 70</span><br><span class="line">   MaxHeapSize      = <span class="number">25769803776</span> (<span class="number">24576.0</span>MB)</span><br><span class="line">   NewSize          = <span class="number">2147483648</span> (2048.0MB)</span><br><span class="line">   MaxNewSize       = <span class="number">2147483648</span> (2048.0MB)</span><br><span class="line">   OldSize          = <span class="number">5439488</span> (5.1875MB)</span><br><span class="line">   NewRatio         = 2</span><br><span class="line">   SurvivorRatio    = 8</span><br><span class="line">   PermSize         = <span class="number">21757952</span> (20.75MB)</span><br><span class="line">   MaxPermSize      = <span class="number">85983232</span> (82.0MB)</span><br><span class="line">   G1HeapRegionSize = 0 (0.0MB)</span><br><span class="line"></span><br><span class="line">Heap Usage:</span><br><span class="line">New Generation (Eden + 1 Survivor Space):</span><br><span class="line">   capacity = <span class="number">1932787712</span> (1843.25MB)</span><br><span class="line">   used     = <span class="number">1216988784</span> (<span class="number">1160.61094</span><span class="number">66552734</span>MB)</span><br><span class="line">   free     = <span class="number">715798928</span> (<span class="number">682.63905</span><span class="number">33447266</span>MB)</span><br><span class="line">   <span class="number">62.96546570</span>759655% used</span><br><span class="line">Eden Space:</span><br><span class="line">   capacity = <span class="number">1718091776</span> (1638.5MB)</span><br><span class="line">   used     = <span class="number">1210401768</span> (<span class="number">1154.32907</span><span class="number">86743164</span>MB)</span><br><span class="line">   free     = <span class="number">507690008</span> (<span class="number">484.1709213</span>256836MB)</span><br><span class="line">   <span class="number">70.45035573</span>233545% used</span><br><span class="line">From Space:</span><br><span class="line">   capacity = <span class="number">214695936</span> (204.75MB)</span><br><span class="line">   used     = <span class="number">6587016</span> (<span class="number">6.28186798</span><span class="number">0957031</span>MB)</span><br><span class="line">   free     = <span class="number">208108920</span> (<span class="number">198.4681320190</span>4297MB)</span><br><span class="line">   <span class="number">3.06806738</span><span class="number">9966804</span>% used</span><br><span class="line">To Space:</span><br><span class="line">   capacity = <span class="number">214695936</span> (204.75MB)</span><br><span class="line">   used     = 0 (0.0MB)</span><br><span class="line">   free     = <span class="number">214695936</span> (204.75MB)</span><br><span class="line">   0.0% used</span><br><span class="line">concurrent mark-sweep generation:</span><br><span class="line">   capacity = <span class="number">23622320128</span> (<span class="number">22528.0</span>MB)</span><br><span class="line">   used     = <span class="number">9615124536</span> (<span class="number">9169.69731</span><span class="number">9030762</span>MB)</span><br><span class="line">   free     = <span class="number">14007195592</span> (<span class="number">13358.30268</span><span class="number">0969238</span>MB)</span><br><span class="line">   <span class="number">40.70355699</span><span class="number">1436265</span>% used</span><br><span class="line">Perm Generation:</span><br><span class="line">   capacity = <span class="number">64733184</span> (<span class="number">61.734375</span>MB)</span><br><span class="line">   used     = <span class="number">39187912</span> (<span class="number">37.372505187</span>98828MB)</span><br><span class="line">   free     = <span class="number">25545272</span> (<span class="number">24.36186981</span>201172MB)</span><br><span class="line">   <span class="number">60.53759382</span><span class="number">5139204</span>% used</span><br><span class="line"></span><br><span class="line">11258 interned Strings occupying <span class="number">1021928</span> bytes.</span><br></pre></td></tr></table></figure></p>
<p>jstat 主要用于查看Java进程的统计信息。</p>
<p>例子1：<br><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># <span class="tag">jstat</span> <span class="tag">-gc</span> 6923 2000 200000</span><br><span class="line"> <span class="tag">S0C</span>    <span class="tag">S1C</span>    <span class="tag">S0U</span>    <span class="tag">S1U</span>      <span class="tag">EC</span>       <span class="tag">EU</span>        <span class="tag">OC</span>         <span class="tag">OU</span>       <span class="tag">PC</span>     <span class="tag">PU</span>    <span class="tag">YGC</span>     <span class="tag">YGCT</span>    <span class="tag">FGC</span>    <span class="tag">FGCT</span>     <span class="tag">GCT</span>   </span><br><span class="line">209664<span class="class">.0</span> 209664<span class="class">.0</span> 83598<span class="class">.2</span> 39179<span class="class">.8</span> 1677824<span class="class">.0</span> 1677824<span class="class">.0</span> 23068672<span class="class">.0</span> 10786771<span class="class">.2</span> 64496<span class="class">.0</span> 38947<span class="class">.4</span>  21541 11322<span class="class">.520</span>   6     35<span class="class">.315</span> 11357<span class="class">.835</span></span><br><span class="line">209664<span class="class">.0</span> 209664<span class="class">.0</span>  0<span class="class">.0</span>   48833<span class="class">.8</span> 1677824<span class="class">.0</span> 502293<span class="class">.9</span> 23068672<span class="class">.0</span> 10787056<span class="class">.8</span> 64496<span class="class">.0</span> 38947<span class="class">.4</span>  21541 11325<span class="class">.066</span>   6     35<span class="class">.315</span> 11360<span class="class">.380</span></span><br><span class="line">209664<span class="class">.0</span> 209664<span class="class">.0</span>  0<span class="class">.0</span>   48833<span class="class">.8</span> 1677824<span class="class">.0</span> 1013386<span class="class">.7</span> 23068672<span class="class">.0</span> 10787056<span class="class">.8</span> 64496<span class="class">.0</span> 38947<span class="class">.4</span>  21541 11325<span class="class">.066</span>   6     35<span class="class">.315</span> 11360<span class="class">.380</span></span><br><span class="line">209664<span class="class">.0</span> 209664<span class="class">.0</span>  0<span class="class">.0</span>   48833<span class="class">.8</span> 1677824<span class="class">.0</span> 1515312<span class="class">.1</span> 23068672<span class="class">.0</span> 10787056<span class="class">.8</span> 64496<span class="class">.0</span> 38947<span class="class">.4</span>  21541 11325<span class="class">.066</span>   6     35<span class="class">.315</span> 11360<span class="class">.380</span></span><br><span class="line">209664<span class="class">.0</span> 209664<span class="class">.0</span> 79664<span class="class">.9</span>  0<span class="class">.0</span>   1677824<span class="class">.0</span> 363216<span class="class">.4</span> 23068672<span class="class">.0</span> 10787062<span class="class">.6</span> 64496<span class="class">.0</span> 38947<span class="class">.4</span>  21542 11325<span class="class">.180</span>   6     35<span class="class">.315</span> 11360<span class="class">.494</span></span><br></pre></td></tr></table></figure></p>
<p>显示结果标题栏字段含义：<br>S0C：Survivor 0区容量(Capacity)。<br>S1C：Survivor 1区容量(Capacity)。<br>S0U：Survivor 0区使用量(Used)。<br>S1U：Survivor 1区使用量(Used)。<br>EC：  Eden区容量。<br>EU：  Eden区使用量。<br>OC：  Old区容量。<br>OU：  Old区使用量。<br>PC：  Perm区容量。<br>PU：  Perm区使用量。<br>YGC： Young GC次数。<br>YGCT：Young GC耗时。<br>FGC： Full GC次数。<br>FGCT：Full GC耗时。<br>GCT： GC总耗时。</p>
<p>例子2：<br><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"># <span class="tag">jstat</span> <span class="tag">-gcutil</span> 6923 2000 1000</span><br><span class="line">  <span class="tag">S0</span>     <span class="tag">S1</span>     <span class="tag">E</span>      <span class="tag">O</span>      <span class="tag">P</span>     <span class="tag">YGC</span>     <span class="tag">YGCT</span>    <span class="tag">FGC</span>    <span class="tag">FGCT</span>     <span class="tag">GCT</span>   </span><br><span class="line">  1<span class="class">.73</span>   0<span class="class">.00</span>  70<span class="class">.22</span>  40<span class="class">.62</span>  99<span class="class">.85</span>   2764  125<span class="class">.732</span>     0    0<span class="class">.000</span>  125<span class="class">.732</span></span><br><span class="line">  1<span class="class">.73</span>   0<span class="class">.00</span>  70<span class="class">.22</span>  40<span class="class">.62</span>  99<span class="class">.85</span>   2764  125<span class="class">.732</span>     0    0<span class="class">.000</span>  125<span class="class">.732</span></span><br><span class="line">  1<span class="class">.73</span>   0<span class="class">.00</span>  70<span class="class">.22</span>  40<span class="class">.62</span>  99<span class="class">.85</span>   2764  125<span class="class">.732</span>     0    0<span class="class">.000</span>  125<span class="class">.732</span></span><br><span class="line">  1<span class="class">.73</span>   0<span class="class">.00</span>  70<span class="class">.22</span>  40<span class="class">.62</span>  99<span class="class">.85</span>   2764  125<span class="class">.732</span>     0    0<span class="class">.000</span>  125<span class="class">.732</span></span><br><span class="line">  1<span class="class">.73</span>   0<span class="class">.00</span>  70<span class="class">.22</span>  40<span class="class">.62</span>  99<span class="class">.85</span>   2764  125<span class="class">.732</span>     0    0<span class="class">.000</span>  125<span class="class">.732</span></span><br><span class="line">  1<span class="class">.73</span>   0<span class="class">.00</span>  70<span class="class">.36</span>  40<span class="class">.62</span>  99<span class="class">.85</span>   2764  125<span class="class">.732</span>     0    0<span class="class">.000</span>  125<span class="class">.732</span></span><br><span class="line">  1<span class="class">.73</span>   0<span class="class">.00</span>  70<span class="class">.36</span>  40<span class="class">.62</span>  99<span class="class">.85</span>   2764  125<span class="class">.732</span>     0    0<span class="class">.000</span>  125<span class="class">.732</span></span><br><span class="line">  1<span class="class">.73</span>   0<span class="class">.00</span>  70<span class="class">.36</span>  40<span class="class">.62</span>  99<span class="class">.85</span>   2764  125<span class="class">.732</span>     0    0<span class="class">.000</span>  125<span class="class">.732</span></span><br><span class="line">  1<span class="class">.73</span>   0<span class="class">.00</span>  70<span class="class">.39</span>  40<span class="class">.62</span>  99<span class="class">.85</span>   2764  125<span class="class">.732</span>     0    0<span class="class">.000</span>  125<span class="class">.732</span></span><br><span class="line">  1<span class="class">.73</span>   0<span class="class">.00</span>  70<span class="class">.42</span>  40<span class="class">.62</span>  99<span class="class">.85</span>   2764  125<span class="class">.732</span>     0    0<span class="class">.000</span>  125<span class="class">.732</span></span><br><span class="line">  1<span class="class">.73</span>   0<span class="class">.00</span>  70<span class="class">.80</span>  40<span class="class">.62</span>  99<span class="class">.85</span>   2764  125<span class="class">.732</span>     0    0<span class="class">.000</span>  125<span class="class">.732</span></span><br><span class="line">  1<span class="class">.73</span>   0<span class="class">.00</span>  70<span class="class">.80</span>  40<span class="class">.62</span>  99<span class="class">.85</span>   2764  125<span class="class">.732</span>     0    0<span class="class">.000</span>  125<span class="class">.732</span></span><br><span class="line">  1<span class="class">.73</span>   0<span class="class">.00</span>  71<span class="class">.04</span>  40<span class="class">.62</span>  99<span class="class">.85</span>   2764  125<span class="class">.732</span>     0    0<span class="class">.000</span>  125<span class="class">.732</span></span><br><span class="line">  1<span class="class">.73</span>   0<span class="class">.00</span>  71<span class="class">.17</span>  40<span class="class">.62</span>  99<span class="class">.85</span>   2764  125<span class="class">.732</span>     0    0<span class="class">.000</span>  125<span class="class">.732</span></span><br></pre></td></tr></table></figure></p>
<h2 id="GC_日志输出参数配置">GC 日志输出参数配置</h2><ul>
<li>打开 -verbose:gc 开关可显示GC的操作内容，包括最忙和最空闲收集行为发生的时间、收集前后的内存大小、收集需要的时间等。</li>
<li>打开 -xx:+printGCdetails 开关，可以详细了解GC中的变化。</li>
<li>打开 -XX:+PrintGCTimeStamps 开关，可以了解这些垃圾收集发生的时间，自JVM启动以后以秒计量。</li>
<li>打开 -xx:+PrintHeapAtGC 开关了解堆的更详细的信息。</li>
<li>打开 -XX:+PrintTenuringDistribution 开关了解获得使用期的对象权。</li>
<li>打开 -Xloggc:/var/log/gclogs/gc.log gc日志产生的路径</li>
<li>打开 -XX:+PrintGCApplicationStoppedTime 输出GC造成应用暂停的时间</li>
<li>打开 -XX:+PrintGCDateStamps GC发生的时间信息</li>
</ul>
<h2 id="GC_日志输出样例">GC 日志输出样例</h2><p>Minor GC日志：<br><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">2015<span class="tag">-05-08T15</span><span class="pseudo">:50</span><span class="pseudo">:10</span><span class="class">.113</span>+0800: 5<span class="class">.930</span>: <span class="attr_selector">[GC2015-05-08T15:50:10.113+0800: 5.930: [ParNew: 174706K-&gt;16932K(184320K), 0.0309770 secs]</span> 201085<span class="tag">K-</span>&gt;43310<span class="tag">K</span>(1028096<span class="tag">K</span>), 0<span class="class">.0311100</span> <span class="tag">secs</span>] <span class="attr_selector">[Times: user=0.14 sys=0.00, real=0.03 secs]</span></span><br></pre></td></tr></table></figure></p>
<ul>
<li>表示发生一次Minor GC，ParNew是新生代的gc算法，174706K表示Eden区的存活对象的内存总和，16932K表示回收后的存活对象的内存总和，184320K是整个eden区的内存总和。0.0309770 secs表示minor gc花费的时间。</li>
<li>201085K-&gt;43310K(1028096K) 表明这个JVM Heap从 201085K 降低到了 43310K。</li>
<li>[Times: user=0.14 sys=0.00, real=0.03 secs]表明这次GC的user time是0.14，而real time是0.03秒；( user/sys/real 的解释参见：<a href="http://stackoverflow.com/questions/556405/what-do-real-user-and-sys-mean-in-the-output-of-time1" target="_blank" rel="external">http://stackoverflow.com/questions/556405/what-do-real-user-and-sys-mean-in-the-output-of-time1</a> )</li>
</ul>
<p>Full GC日志：<br><figure class="highlight mathematica"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">2015</span>-<span class="number">04</span>-<span class="number">08</span>T17:<span class="number">31</span>:<span class="number">19.816</span>+<span class="number">0800</span>: <span class="number">8317.639</span>: [<span class="keyword">Full</span> GC2015-<span class="number">04</span>-<span class="number">08</span>T17:<span class="number">31</span>:<span class="number">19.816</span>+<span class="number">0800</span>: <span class="number">8317.639</span>: [CMS: <span class="number">603725</span><span class="keyword">K</span>-&gt;<span class="number">464743</span><span class="keyword">K</span>(<span class="number">843776</span><span class="keyword">K</span>), <span class="number">0.6577700</span> secs] <span class="number">788045</span><span class="keyword">K</span>-&gt;<span class="number">464743</span><span class="keyword">K</span>(<span class="number">1028096</span><span class="keyword">K</span>), [CMS Perm : <span class="number">40447</span><span class="keyword">K</span>-&gt;<span class="number">40446</span><span class="keyword">K</span>(<span class="number">67100</span><span class="keyword">K</span>)], <span class="number">0.6579650</span> secs] [<span class="keyword">Times</span>: user=<span class="number">0.54</span> sys=<span class="number">0.00</span>, real=<span class="number">0.65</span> secs]</span><br></pre></td></tr></table></figure></p>
<ul>
<li>最前面的数字 8317.639 代表GC发生的时间，是从Java虚拟机启动以来经过的秒数；</li>
<li>表示发生了一次Full GC，有Full说明发生了Stop-The-World，，如果是调用system.gc()方法所触发的收集，将显示(System)；</li>
<li>整个JVM都停顿了 0.6577700 秒。</li>
<li>CMS Perm表示GC发生的区域，名称是由收集器决定的。</li>
</ul>
<h2 id="参考：">参考：</h2><p><a href="http://docs.oracle.com/javase/8/docs/technotes/guides/vm/gctuning/generations.html" target="_blank" rel="external">http://docs.oracle.com/javase/8/docs/technotes/guides/vm/gctuning/generations.html</a><br><a href="http://www.oracle.com/webfolder/technetwork/tutorials/obe/java/gc01/index.html" target="_blank" rel="external">http://www.oracle.com/webfolder/technetwork/tutorials/obe/java/gc01/index.html</a><br><a href="http://www.oracle.com/technetwork/java/gc-tuning-5-138395.html" target="_blank" rel="external">http://www.oracle.com/technetwork/java/gc-tuning-5-138395.html</a><br><a href="http://www.oracle.com/technetwork/java/javase/gc-tuning-6-140523.html" target="_blank" rel="external">http://www.oracle.com/technetwork/java/javase/gc-tuning-6-140523.html</a><br><a href="http://www.infoq.com/cn/articles/Java-PERMGEN-Removed" target="_blank" rel="external">http://www.infoq.com/cn/articles/Java-PERMGEN-Removed</a><br><a href="http://docs.oracle.com/cd/E21764_01/web.1111/e13814/jvm_tuning.htm#PERFM169" target="_blank" rel="external">http://docs.oracle.com/cd/E21764_01/web.1111/e13814/jvm_tuning.htm#PERFM169</a><br><a href="http://blog.csdn.net/ning109314/article/details/10411495" target="_blank" rel="external">http://blog.csdn.net/ning109314/article/details/10411495</a><br><a href="http://jbutton.iteye.com/blog/1569746" target="_blank" rel="external">http://jbutton.iteye.com/blog/1569746</a><br><a href="http://buddie.iteye.com/blog/1824937" target="_blank" rel="external">http://buddie.iteye.com/blog/1824937</a><br><a href="http://www.cnblogs.com/ggjucheng/p/3977384.html" target="_blank" rel="external">http://www.cnblogs.com/ggjucheng/p/3977384.html</a><br><a href="http://blog.csdn.net/historyasamirror/article/details/6233007" target="_blank" rel="external">http://blog.csdn.net/historyasamirror/article/details/6233007</a><br><a href="http://sargeraswang.com/blog/2014/02/03/la-ji-shou-ji-qi-yu-nei-cun-fen-pei-ce-lue/" target="_blank" rel="external">http://sargeraswang.com/blog/2014/02/03/la-ji-shou-ji-qi-yu-nei-cun-fen-pei-ce-lue/</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://navigating.github.io/2015/JVM监控与调优/" data-id="cigszouhk003iwwlmkyj5qv9n" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/JVM/">JVM</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Java/">Java</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-2015/大数据动态之201509" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2015/大数据动态之201509/" class="article-date">
  <time datetime="2015-10-16T02:41:31.000Z" itemprop="datePublished">2015-10-16</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/技术/">技术</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2015/大数据动态之201509/">大数据动态之201509</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>Apache Kylin<br>Apache Kylin v1.0 发布，分布式分析引擎<br><a href="http://www.oschina.net/news/65938/apache-kylin-1-0-released" target="_blank" rel="external">http://www.oschina.net/news/65938/apache-kylin-1-0-released</a> </p>
<p>Apache Calcite<br>Apache Calcite：Hadoop中新型大数据查询引擎<br><a href="http://www.infoq.com/cn/articles/new-big-data-hadoop-query-engine-apache-calcite" target="_blank" rel="external">http://www.infoq.com/cn/articles/new-big-data-hadoop-query-engine-apache-calcite</a> </p>
<p>Apache Flink<br><a href="http://flink.apache.org/" target="_blank" rel="external">http://flink.apache.org/</a> </p>
<p>Cloudera<br>新的快数据存储Hadoop组件，Kudu:<br><a href="http://blog.cloudera.com/blog/2015/09/kudu-new-apache-hadoop-storage-for-fast-analytics-on-fast-data/" target="_blank" rel="external">http://blog.cloudera.com/blog/2015/09/kudu-new-apache-hadoop-storage-for-fast-analytics-on-fast-data/</a><br>Hadoop细粒度的安全增强组件，RecordService：<br><a href="http://blog.cloudera.com/blog/2015/09/recordservice-for-fine-grained-security-enforcement-across-the-hadoop-ecosystem/" target="_blank" rel="external">http://blog.cloudera.com/blog/2015/09/recordservice-for-fine-grained-security-enforcement-across-the-hadoop-ecosystem/</a><br>HDFS Erasure Coding特性<br><a href="http://blog.cloudera.com/blog/2015/09/introduction-to-hdfs-erasure-coding-in-apache-hadoop/" target="_blank" rel="external">http://blog.cloudera.com/blog/2015/09/introduction-to-hdfs-erasure-coding-in-apache-hadoop/</a><br>Spark测试基础库<br><a href="http://blog.cloudera.com/blog/2015/09/making-apache-spark-testing-easy-with-spark-testing-base/" target="_blank" rel="external">http://blog.cloudera.com/blog/2015/09/making-apache-spark-testing-easy-with-spark-testing-base/</a><br>如何使用Impala对非结构化数据进行分析：<br><a href="http://blog.cloudera.com/blog/2015/09/how-to-prepare-unstructured-data-in-impala-for-analysis/" target="_blank" rel="external">http://blog.cloudera.com/blog/2015/09/how-to-prepare-unstructured-data-in-impala-for-analysis/</a><br>BI场景下Impala测试结果<br><a href="http://blog.cloudera.com/blog/2015/09/how-impala-scales-for-business-intelligence-new-test-results/" target="_blank" rel="external">http://blog.cloudera.com/blog/2015/09/how-impala-scales-for-business-intelligence-new-test-results/</a><br>揭秘Apache Hadoop YARN:<br><a href="http://blog.cloudera.com/blog/2015/09/untangling-apache-hadoop-yarn-part-1/" target="_blank" rel="external">http://blog.cloudera.com/blog/2015/09/untangling-apache-hadoop-yarn-part-1/</a><br><a href="http://blog.cloudera.com/blog/2013/11/migrating-to-mapreduce-2-on-yarn-for-users/" target="_blank" rel="external">http://blog.cloudera.com/blog/2013/11/migrating-to-mapreduce-2-on-yarn-for-users/</a><br><a href="http://blog.cloudera.com/blog/2013/11/migrating-to-mapreduce-2-on-yarn-for-operators/" target="_blank" rel="external">http://blog.cloudera.com/blog/2013/11/migrating-to-mapreduce-2-on-yarn-for-operators/</a><br>Impala支持shell执行的动态进度报告(Impala’s debug webpages (http:::25000))：<br><a href="http://blog.cloudera.com/blog/2015/09/dynamic-progress-reports-in-the-impala-shell/" target="_blank" rel="external">http://blog.cloudera.com/blog/2015/09/dynamic-progress-reports-in-the-impala-shell/</a><br>Cloudera One Platform:<br><a href="http://vision.cloudera.com/one-platform/" target="_blank" rel="external">http://vision.cloudera.com/one-platform/</a> </p>
<p>Hortonworks<br>Microsoft Azure HDInsight对Ubuntu Linux支持，可以支持到Hadoop 2.6：<br><a href="http://hortonworks.com/blog/microsoft-azure-hdinsight-on-linux-choice/" target="_blank" rel="external">http://hortonworks.com/blog/microsoft-azure-hdinsight-on-linux-choice/</a><br>HDP 2.3 Sandbox在Microsoft Azure Gallery上线：<br><a href="http://hortonworks.com/blog/hortonworks-sandbox-with-hdp-2-3-is-now-available-on-microsoft-azure-gallery/" target="_blank" rel="external">http://hortonworks.com/blog/hortonworks-sandbox-with-hdp-2-3-is-now-available-on-microsoft-azure-gallery/</a><br>Impala与Hive性能对比<br><a href="http://hortonworks.com/blog/impala-vs-hive-performance-benchmark/" target="_blank" rel="external">http://hortonworks.com/blog/impala-vs-hive-performance-benchmark/</a><br>HDP迁移案例：<br><a href="http://hortonworks.com/blog/migration-to-hdp-as-easy-as-1-2-3-without-downtime-or-disruption/" target="_blank" rel="external">http://hortonworks.com/blog/migration-to-hdp-as-easy-as-1-2-3-without-downtime-or-disruption/</a> </p>
<p>MapR<br>Spark on YARN资源分配配置<br><a href="https://www.mapr.com/blog/resource-allocation-configuration-spark-yarn#.VfoRrSWqqko" target="_blank" rel="external">https://www.mapr.com/blog/resource-allocation-configuration-spark-yarn#.VfoRrSWqqko</a><br><a href="https://spark.apache.org/docs/latest/running-on-yarn.html" target="_blank" rel="external">https://spark.apache.org/docs/latest/running-on-yarn.html</a><br><a href="https://spark.apache.org/docs/latest/job-scheduling.html#dynamic-resource-allocation" target="_blank" rel="external">https://spark.apache.org/docs/latest/job-scheduling.html#dynamic-resource-allocation</a><br>SAP HANA与Mapr DP混合架构<br><a href="https://www.mapr.com/blog/sap-hana-vora-and-mapr-data-platform#.VfoRsCWqqko" target="_blank" rel="external">https://www.mapr.com/blog/sap-hana-vora-and-mapr-data-platform#.VfoRsCWqqko</a><br>Spark Streaming with HBase<br><a href="https://www.mapr.com/blog/spark-streaming-hbase#.VfoR0SWqqko" target="_blank" rel="external">https://www.mapr.com/blog/spark-streaming-hbase#.VfoR0SWqqko</a><br>MapR对Docker的支持<br><a href="https://www.mapr.com/blog/how-create-instant-mapr-clusters-docker#.VfoR2CWqqko" target="_blank" rel="external">https://www.mapr.com/blog/how-create-instant-mapr-clusters-docker#.VfoR2CWqqko</a><br><a href="https://www.mapr.com/blog/my-experience-running-docker-containers-on-mesos#.Vfoc_yWqqkp" target="_blank" rel="external">https://www.mapr.com/blog/my-experience-running-docker-containers-on-mesos#.Vfoc_yWqqkp</a> </p>
<p>Databricks<br>Spark Survey 2015调查结果：<br><a href="https://databricks.com/blog/2015/09/24/spark-survey-results-2015-are-now-available.html" target="_blank" rel="external">https://databricks.com/blog/2015/09/24/spark-survey-results-2015-are-now-available.html</a><br>Spark代码调试：实时进度条和Spark UI<br><a href="https://databricks.com/blog/2015/09/23/easier-spark-code-debugging-real-time-progress-bar-and-spark-ui-integration-in-databricks.html" target="_blank" rel="external">https://databricks.com/blog/2015/09/23/easier-spark-code-debugging-real-time-progress-bar-and-spark-ui-integration-in-databricks.html</a><br>新版本Spark 1.5上LDA算法的性能提升：<br><a href="https://databricks.com/blog/2015/09/22/large-scale-topic-modeling-improvements-to-lda-on-spark.html" target="_blank" rel="external">https://databricks.com/blog/2015/09/22/large-scale-topic-modeling-improvements-to-lda-on-spark.html</a><br>Spark 1.5 DataFrame API:<br><a href="https://databricks.com/blog/2015/09/16/spark-1-5-dataframe-api-highlights-datetimestring-handling-time-intervals-and-udafs.html" target="_blank" rel="external">https://databricks.com/blog/2015/09/16/spark-1-5-dataframe-api-highlights-datetimestring-handling-time-intervals-and-udafs.html</a><br>Spark 1.5发布，在性能、可用性、运维、Data Science API等方面有重大改进：<br><a href="https://databricks.com/blog/2015/09/09/announcing-spark-1-5.html" target="_blank" rel="external">https://databricks.com/blog/2015/09/09/announcing-spark-1-5.html</a><br><a href="http://www.csdn.net/article/2015-09-29/2825825" target="_blank" rel="external">http://www.csdn.net/article/2015-09-29/2825825</a><br><a href="http://www.csdn.net/article/2015-09-10/2825669" target="_blank" rel="external">http://www.csdn.net/article/2015-09-10/2825669</a> </p>
<p>MongoDB<br>MongoDB性能优化五个简单步骤：<br><a href="http://www.csdn.net/article/2015-09-30/2825833" target="_blank" rel="external">http://www.csdn.net/article/2015-09-30/2825833</a><br>MongoDB开发版本3.1.8发布<br><a href="http://www.csdn.net/article/2015-09-17/2825734" target="_blank" rel="external">http://www.csdn.net/article/2015-09-17/2825734</a><br>分布式文档数据库MongoDB开发版本3.1.7发布<br><a href="http://www.csdn.net/article/2015-09-01/2825599-mongodb-317-is-released" target="_blank" rel="external">http://www.csdn.net/article/2015-09-01/2825599-mongodb-317-is-released</a> </p>
<p>参考<br>逆水行舟，看前行中的Spark<br><a href="http://www.csdn.net/article/2015-09-21/2825754" target="_blank" rel="external">http://www.csdn.net/article/2015-09-21/2825754</a><br>微店的大数据平台建设实践与探讨<br><a href="http://www.csdn.net/article/2015-09-21/2825756" target="_blank" rel="external">http://www.csdn.net/article/2015-09-21/2825756</a><br>打造数据驱动的组织：第二年<br><a href="http://zhuanlan.zhihu.com/donglaoshi/20205116" target="_blank" rel="external">http://zhuanlan.zhihu.com/donglaoshi/20205116</a><br>揭开 Growth Hacking 的神秘面纱（上篇）<br><a href="http://zhuanlan.zhihu.com/qinchao/20190015" target="_blank" rel="external">http://zhuanlan.zhihu.com/qinchao/20190015</a><br>京东大数据基础架构和实践—王彦明<br><a href="http://share.csdn.net/slides/9138" target="_blank" rel="external">http://share.csdn.net/slides/9138</a><br>京东数据仓库海量数据交换工具—张侃<br><a href="http://share.csdn.net/slides/9137" target="_blank" rel="external">http://share.csdn.net/slides/9137</a><br>京东大数据分析与创新应用<br><a href="http://share.csdn.net/slides/9139" target="_blank" rel="external">http://share.csdn.net/slides/9139</a><br>LinkedIn架构这十年<br><a href="http://engineering.linkedin.com/architecture/brief-history-scaling-linkedin" target="_blank" rel="external">http://engineering.linkedin.com/architecture/brief-history-scaling-linkedin</a><br><a href="http://colobu.com/2015/07/24/brief-history-scaling-linkedin/" target="_blank" rel="external">http://colobu.com/2015/07/24/brief-history-scaling-linkedin/</a><br>LinkedIn是如何优化Kafka的<br><a href="http://www.infoq.com/cn/articles/linkedIn-improving-kafka" target="_blank" rel="external">http://www.infoq.com/cn/articles/linkedIn-improving-kafka</a><br><a href="http://engineering.linkedin.com/apache-kafka/how-we%E2%80%99re-improving-and-advancing-kafka-linkedin" target="_blank" rel="external">http://engineering.linkedin.com/apache-kafka/how-we%E2%80%99re-improving-and-advancing-kafka-linkedin</a><br>阿里CDN从自建到服务<br><a href="http://share.csdn.net/slides/8319" target="_blank" rel="external">http://share.csdn.net/slides/8319</a><br>系统架构设计-负载均衡和高可用<br><a href="http://share.csdn.net/slides/12338" target="_blank" rel="external">http://share.csdn.net/slides/12338</a><br>OSTC2015-朱照远（叔度）阿里开源经验分享<br><a href="http://share.csdn.net/slides/13730" target="_blank" rel="external">http://share.csdn.net/slides/13730</a><br>Voidbox<br><a href="http://dongxicheng.org/mapreduce-nextgen/voidbox-docker-on-hadoop-hulu/" target="_blank" rel="external">http://dongxicheng.org/mapreduce-nextgen/voidbox-docker-on-hadoop-hulu/</a><br>深入理解Spark Streaming执行模型<br><a href="http://www.csdn.net/article/2015-09-13/2825689" target="_blank" rel="external">http://www.csdn.net/article/2015-09-13/2825689</a><br>Apache Spark 1.5新特性介绍<br><a href="http://www.csdn.net/article/2015-09-10/2825669" target="_blank" rel="external">http://www.csdn.net/article/2015-09-10/2825669</a><br>盘点大数据生态圈，那些繁花似锦的开源项目<br><a href="http://www.csdn.net/article/2015-09-11/2825674" target="_blank" rel="external">http://www.csdn.net/article/2015-09-11/2825674</a><br>Redis整合Spring项目搭建实例<br><a href="http://www.csdn.net/article/2015-09-01/2825600" target="_blank" rel="external">http://www.csdn.net/article/2015-09-01/2825600</a><br>MongoDB开发版本3.1.8发布<br><a href="http://www.csdn.net/article/2015-09-17/2825734" target="_blank" rel="external">http://www.csdn.net/article/2015-09-17/2825734</a><br>分布式并行数据库将在 OLTP 领域促进去“Oracle”<br><a href="http://www.csdn.net/article/2015-09-11/2825678" target="_blank" rel="external">http://www.csdn.net/article/2015-09-11/2825678</a><br>Gartner 2015新兴技术发展周期简评：大数据实用化、机器学习崛起<br><a href="http://www.csdn.net/article/2015-09-06/2825620" target="_blank" rel="external">http://www.csdn.net/article/2015-09-06/2825620</a><br>Hortonworks收购Onyara，启动数据流自动化<br><a href="http://www.csdn.net/article/2015-09-02/2825612" target="_blank" rel="external">http://www.csdn.net/article/2015-09-02/2825612</a> </p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://navigating.github.io/2015/大数据动态之201509/" data-id="cigszoudz001lwwlmyspmqojm" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/BigData/">BigData</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/HBase/">HBase</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Hadoop/">Hadoop</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/MongoDB/">MongoDB</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Spark/">Spark</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-2015/学习《Impala-vs-Hive-Performance-Benchmark》" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2015/学习《Impala-vs-Hive-Performance-Benchmark》/" class="article-date">
  <time datetime="2015-09-24T04:56:08.000Z" itemprop="datePublished">2015-09-24</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/技术/">技术</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2015/学习《Impala-vs-Hive-Performance-Benchmark》/">学习《Impala vs. Hive Performance Benchmark》</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>原文：<a href="http://hortonworks.com/blog/impala-vs-hive-performance-benchmark/" target="_blank" rel="external">http://hortonworks.com/blog/impala-vs-hive-performance-benchmark/</a><br>学习如下：</p>
<p>本文是Yahoo! JAPAN针对自己的场景需求进行设计书选型，对Impala和Hive(Tez on YARN)所做的评测。<br>场景数据和要求：</p>
<ol>
<li>数据格式为 Text 或者 gz ;</li>
<li>每天新增数据文件为10G，数据记录为13亿行；</li>
<li>数据留存(retention)周期为13个月，共有数据6000G，共有4500亿行；</li>
<li>每个小时需要生成 15000 个报表(reporting)；</li>
<li>查询条件包含少量的的 grouping ，grouping的条件主要是地区(region)或者性别(gender)；</li>
<li>没有过滤条件查询；</li>
<li>绝大部分基于时间的报表(report)生成都是周期性的，除了小时报表，还有天报表和周报表；</li>
</ol>
<p>技术选型：</p>
<ol>
<li>Cloudera Impala，没提到所评估的版本，估计为最近的版本。当前Impala的最新版本为。</li>
<li>Hortonworks HDP 2.2, Apache Hive-0.14, Apache Tez。</li>
</ol>
<p>考虑Impala</p>
<ol>
<li>Imapa查询耗时比较少，一般在几秒到几十秒之间；</li>
<li>当一次查询的响应时间为15秒，每小时能够执行240次查询；</li>
<li>针对单位时间内处理量的不断增加，需要考虑通过增加单位时间内的并行查询数量来提升查询的数量；使用Impala遇到的问题是，随着查询并行度的增加，Impala查询的响应时间线性增加；因此，在每天数据更新之后Impala无法自动处理完成所有的批量查询。</li>
</ol>
<p>考虑Hive和Tez on YARN<br>Hadoop-2.x, YARN有更好粒度的并行执行控制，Tez引擎能大幅度的降低MapReduce的延时。<br>YARN和Tez大幅度的增加处理能力，每小时需要处理超过15000个任务。之前的Hadoop 1.0集群，每天已经能够处理100000个任务。</p>
<p>测试验证</p>
<p>测试条件</p>
<ol>
<li>计划模拟真实业务场景测试执行近2000个SQL；</li>
<li>绝大部分查询返回的结果少于 1000 行数据；</li>
<li>少数查询返回的结果超过100000行数据;</li>
<li>执行近2000个SQL的并发请求为32；</li>
</ol>
<p><img src="https://raw.githubusercontent.com/stevenxu/tuku/master/navigating.github.io/2015/HiveImpala_001.png" alt="这是一张图片"></p>
<p>测试结果</p>
<ol>
<li>Hive请求的大部分请求在20秒以内返回，随着返回结果集数据的增加查询时间也随之增加，最长返回时间为70秒；</li>
<li>Impala请求的大部分请求返回在30秒～60秒之间，最长返回时间为10分钟，随着返回结果集数据的增加查询时间大幅度显著的增加；</li>
<li>在一些低负载(low load)条件的查询中，Impala能够达到毫秒(milliseconds)级返回；如果没有SQL并行化的处理需求，Impala是有效的选择。</li>
<li>对于要求批处理，并且SQL并行化是必须的场景中，Hive on Tez是更好的选择。</li>
</ol>
<p><img src="https://raw.githubusercontent.com/stevenxu/tuku/master/navigating.github.io/2015/HiveImpala_002.png" alt="这是一张图片"></p>
<p>Hive的并发性<br>对于单个的HiveServer2实例，我们测试验证多少个并行查询可以被执行，多少并行度的处理是最有效的。<br>我们以16作为SQL并发执行的提升倍数，衡量的指标是SQL执行的处理时间。<br>在并发达到64之前查询的吞吐量快速增加，在这点之后开始下降，因此在当前环境下64是最好的并发数。</p>
<p><img src="https://raw.githubusercontent.com/stevenxu/tuku/master/navigating.github.io/2015/HiveImpala_003.png" alt="这是一张图片"></p>
<p>结论<br>对于Hive on Tez，单个SQL执行时间一般为15秒，会随着并行度的提升而增加。(并行度的限制主要依赖于集群的大小和性能。)<br>在低负载状态下Impala有非常快的响应时间，但并不适合于SQL并行度非常高的场景。<br>最后的结论是测试者最后选择了Hive on Tez，因为测试者的场景是每小时至少处理15000个SQL请求。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://navigating.github.io/2015/学习《Impala-vs-Hive-Performance-Benchmark》/" data-id="cigszoucz000rwwlm8eb4ll0c" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/BigData/">BigData</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Hadoop/">Hadoop</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Hive/">Hive</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Impala/">Impala</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Tez/">Tez</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-2015/Hortonworks-HDP-2-3-0" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2015/Hortonworks-HDP-2-3-0/" class="article-date">
  <time datetime="2015-09-22T02:23:39.000Z" itemprop="datePublished">2015-09-22</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/技术/">技术</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2015/Hortonworks-HDP-2-3-0/">Hortonworks HDP 2.3.0</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>HDP 2.3 相对于 HDP 2.2.6</p>
<ol>
<li>HBase版本变化比较大，HBase 1.1.1；</li>
<li>新增加了一些组件；</li>
<li>Ambari在配置、监控等方面有较大的升级；</li>
</ol>
<p>新增加的组件：</p>
<pre><code>1. <span class="tag">Apache</span> <span class="tag">Atlas</span> 0<span class="class">.5</span><span class="class">.0</span>
2. <span class="tag">Apache</span> <span class="tag">Calcite</span> 1<span class="class">.2</span><span class="class">.0</span>
3. <span class="tag">Apache</span> <span class="tag">Solr</span> 5<span class="class">.2</span><span class="class">.1</span>
4. <span class="tag">Cascading</span> 3<span class="class">.0</span><span class="class">.1</span>
5. <span class="tag">Cloudbreak</span> 1<span class="class">.0</span>
6. <span class="tag">SmartSense</span>
</code></pre><p>版本升级的组件：</p>
<pre><code>1. <span class="tag">Apache</span> <span class="tag">Ambari</span> 2<span class="class">.1</span>
2. <span class="tag">Apache</span> <span class="tag">Hadoop</span> 2<span class="class">.7</span><span class="class">.1</span>
3. <span class="tag">Apache</span> <span class="tag">HBase</span> 1<span class="class">.1</span><span class="class">.1</span>
4. <span class="tag">Apache</span> <span class="tag">Spark</span> 1<span class="class">.3</span><span class="class">.1</span>
5. <span class="tag">Apache</span> <span class="tag">Hive</span> 1<span class="class">.2</span><span class="class">.1</span>
6. <span class="tag">Apache</span> <span class="tag">Kafka</span> 0<span class="class">.8</span><span class="class">.2</span>
7. <span class="tag">Apache</span> <span class="tag">Phoenix</span> 4<span class="class">.4</span><span class="class">.0</span>
8. <span class="tag">Apache</span> <span class="tag">Pig</span> 0<span class="class">.15</span><span class="class">.0</span>
9. <span class="tag">Apache</span> <span class="tag">Sqoop</span> 1<span class="class">.4</span><span class="class">.6</span>
10. <span class="tag">Apache</span> <span class="tag">Oozie</span> 4<span class="class">.2</span><span class="class">.0</span>
11. <span class="tag">Apache</span> <span class="tag">Knox</span> 0<span class="class">.6</span><span class="class">.0</span>
12. <span class="tag">Apache</span> <span class="tag">Ranger</span> 0<span class="class">.5</span><span class="class">.0</span>
13. <span class="tag">Apache</span> <span class="tag">Falcon</span> 0<span class="class">.6</span><span class="class">.1</span>
14. <span class="tag">Slider</span> 0<span class="class">.80</span><span class="class">.0</span>
15. <span class="tag">Tez</span> 0<span class="class">.7</span><span class="class">.0</span>
16. <span class="tag">Storm</span> 0<span class="class">.10</span><span class="class">.0</span>
</code></pre><p>Ambari 2.1新特性：</p>
<pre><code><span class="bullet">1. </span>通过Ambari参数配置UI优化；
<span class="bullet">2. </span>各项服务Metrics可以进行监控指标添加，通过添加Widgets就可以；
<span class="bullet">3. </span>支持Hive, Pig, Files, Capacity Scheduler的User Views界面，可以通过UI执行Hive、Pig语句；
<span class="bullet">4. </span>配置 Capacity Scheduler 支持图形化了，更加方便；
<span class="bullet">5. </span>支持 SQL User View；
<span class="bullet">6. </span>支持机架感应(Rack Awareness)配置：通过Ambari来配置；
<span class="bullet">7. </span>支持 Cloudbreak；
<span class="bullet">8. </span>支持 SmartSense；
</code></pre><p>系统要求：</p>
<pre><code>1. <span class="tag">Red</span> <span class="tag">Hat</span> <span class="tag">Enterprise</span> <span class="tag">Linux</span> (<span class="tag">RHEL</span>) <span class="tag">v6</span><span class="class">.x</span> 或者 <span class="tag">Red</span> <span class="tag">Hat</span> <span class="tag">Enterprise</span> <span class="tag">Linux</span> (<span class="tag">RHEL</span>) <span class="tag">v7</span><span class="class">.x</span>
2. <span class="tag">Oracle</span> <span class="tag">JDK</span> 1<span class="class">.8</span> 64<span class="tag">-bit</span> (<span class="tag">minimum</span> <span class="tag">JDK</span> 1<span class="class">.8_40</span>) (<span class="tag">default</span>) 或者 <span class="tag">Oracle</span> <span class="tag">JDK</span> 1<span class="class">.7</span> 64<span class="tag">-bit</span> (<span class="tag">minimum</span> <span class="tag">JDK</span> 1<span class="class">.7_67</span>)
</code></pre><p>参考：<br><a href="http://docs.hortonworks.com/HDPDocuments/HDP2/HDP-2.3.0/bk_HDP_RelNotes/content/ch_relnotes_v230.html" target="_blank" rel="external">http://docs.hortonworks.com/HDPDocuments/HDP2/HDP-2.3.0/bk_HDP_RelNotes/content/ch_relnotes_v230.html</a><br><a href="http://docs.hortonworks.com/HDPDocuments/HDP2/HDP-2.2.6/bk_HDP_RelNotes/content/ch_relnotes_v226.html" target="_blank" rel="external">http://docs.hortonworks.com/HDPDocuments/HDP2/HDP-2.2.6/bk_HDP_RelNotes/content/ch_relnotes_v226.html</a> </p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://navigating.github.io/2015/Hortonworks-HDP-2-3-0/" data-id="cigszouhy003owwlmnpa8w0da" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Ambari/">Ambari</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/BigData/">BigData</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/HDP/">HDP</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Hadoop/">Hadoop</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-2015/Oozie：入门概述" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2015/Oozie：入门概述/" class="article-date">
  <time datetime="2015-09-18T15:24:54.000Z" itemprop="datePublished">2015-09-18</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/技术/">技术</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2015/Oozie：入门概述/">Oozie：入门概述</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h3 id="Oozie能做什么(What_Oozie_Does)">Oozie能做什么(What Oozie Does)</h3><p>Oozie是一个Java Web应用，用于Apache Hadoop的任务(jobs)调度。Oozie顺序的合并多个任务(jobs)成为一个可工作的逻辑单元。其主要是集成了Hadoop技术栈，包括YARN等，支持Apache MapReduce, Apache Pig, Apache Hive, Apache Sqoop等。Oozie使得用户能够通过Java应用或者Shell脚本的方式调度任务。<br>Oozie任务有两种基本类型</p>
<pre><code>* Oozie Workflow jobs：这种任务是一个有向无环图(DAG, <span class="keyword">Direct</span> Acyclical Graph)，并按着规则顺序的执行，即上一个<span class="keyword">Action</span>运行完成后才能运行下一个<span class="keyword">Action</span>。所以其经常不得不等待。
* Oozie Coordinator jobs：这种任务是重复性的工作流，一般被时间或者数据达到可用会被触发。
</code></pre><p>Oozie Bundle提供一个复合的方式，将多个Workflow jobs和Coordinator jobs打包合并在一起并能对它们的生命周期进行管理。</p>
<h3 id="Oozie如何工作(How_Oozie_works)">Oozie如何工作(How Oozie works)</h3><p>一个Oozie Workflow是一系列编排成有向无环图（DAG）的Action集合。控制节点定义job时间,设置开始和结束workflow的规则(rules)。这样，Oozie通过decision，fork和join节点控制工作流的执行路径。Action节点触发任务的执行。<br>Oozie触发工作流的action操作，实际上由Hadoop MapReduce去执行。Oozie利用Hadoop技术栈来均衡负载和处理失败。<br>Oozie通过回调(callback)和轮询(polling)来检测任务的是否完成。当Oozie开始一个任务(task)，它的提供了一个唯一的可以回调的HTTP URL，当这个任务完成的时候就通知这个URL。如果任务失败就调用回调URL，Oozie可以设置任务完成。<br>经常有这种需求，在规则的时间间隔内运行Oozie workflow，处理那些无法预期的有效数据或者时间。在这些情况下，Oozie Coordinator允许你根据、时间或者事件的条件对工作流触发的时机进行建模。在这些条件得到满足之后，工作流任务就就开始启动。<br>Oozie Coordinator也可以管理多个工作流，是依赖于子工作流的输出结果。子工作流程的输出将会成为下一个工作流的输入。这条链被称为“数据应用管道”(data application pipeline)。</p>
<h3 id="工作流定义">工作流定义</h3><p>定义一个Oozie工作流，两个配置文件是必须的，job.properties和workflow.xml。<br>job.properties的环境变量如下：<br>nameNode                        hdfs://mycluster:8020                HDFS地址<br>jobTracker                        localhost:8034                        jobTracker地址<br>queueName                        default                                Oozie队列<br>examplesRoot                    examples                            全局目录<br>oozie.usr.system.libpath        true                                是否加载用户的lib库<br>oozie.libpath                    share/lib/user                        用户lib库<br>oozie.wf.application.path        ${nameNode}/user/${user.name}/        Oozie流程所在的HDFS地址</p>
<p>workflow.xml示例如下：<br><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!--</span><br><span class="line">  Licensed to the Apache Software Foundation (ASF) under one</span><br><span class="line">  or more contributor license agreements.  See the NOTICE file</span><br><span class="line">  distributed with this work for additional information</span><br><span class="line">  regarding copyright ownership.  The ASF licenses this file</span><br><span class="line">  to you under the Apache License, Version 2.0 (the</span><br><span class="line">  "License"); you may not use this file except in compliance</span><br><span class="line">  with the License.  You may obtain a copy of the License at</span><br><span class="line"></span><br><span class="line">       http://www.apache.org/licenses/LICENSE-2.0</span><br><span class="line"></span><br><span class="line">  Unless required by applicable law or agreed to in writing, software</span><br><span class="line">  distributed under the License is distributed on an "AS IS" BASIS,</span><br><span class="line">  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span><br><span class="line">  See the License for the specific language governing permissions and</span><br><span class="line">  limitations under the License.</span><br><span class="line">--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="title">workflow-app</span> <span class="attribute">xmlns</span>=<span class="value">"uri:oozie:workflow:0.2"</span> <span class="attribute">name</span>=<span class="value">"map-reduce-wf"</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="title">start</span> <span class="attribute">to</span>=<span class="value">"mr-node"</span>/&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="title">action</span> <span class="attribute">name</span>=<span class="value">"mr-node"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="title">map-reduce</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="title">job-tracker</span>&gt;</span>$&#123;jobTracker&#125;<span class="tag">&lt;/<span class="title">job-tracker</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="title">name-node</span>&gt;</span>$&#123;nameNode&#125;<span class="tag">&lt;/<span class="title">name-node</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="title">prepare</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="title">delete</span> <span class="attribute">path</span>=<span class="value">"$&#123;nameNode&#125;/user/$&#123;wf:user()&#125;/$&#123;examplesRoot&#125;/output-data/$&#123;outputDir&#125;"</span>/&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="title">prepare</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="title">configuration</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="title">property</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="title">name</span>&gt;</span>mapred.job.queue.name<span class="tag">&lt;/<span class="title">name</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="title">value</span>&gt;</span>$&#123;queueName&#125;<span class="tag">&lt;/<span class="title">value</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;/<span class="title">property</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="title">property</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="title">name</span>&gt;</span>mapred.mapper.class<span class="tag">&lt;/<span class="title">name</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="title">value</span>&gt;</span>org.apache.oozie.example.SampleMapper<span class="tag">&lt;/<span class="title">value</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;/<span class="title">property</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="title">property</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="title">name</span>&gt;</span>mapred.reducer.class<span class="tag">&lt;/<span class="title">name</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="title">value</span>&gt;</span>org.apache.oozie.example.SampleReducer<span class="tag">&lt;/<span class="title">value</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;/<span class="title">property</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="title">property</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="title">name</span>&gt;</span>mapred.map.tasks<span class="tag">&lt;/<span class="title">name</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="title">value</span>&gt;</span>1<span class="tag">&lt;/<span class="title">value</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;/<span class="title">property</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="title">property</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="title">name</span>&gt;</span>mapred.input.dir<span class="tag">&lt;/<span class="title">name</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="title">value</span>&gt;</span>/user/$&#123;wf:user()&#125;/$&#123;examplesRoot&#125;/input-data/text<span class="tag">&lt;/<span class="title">value</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;/<span class="title">property</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="title">property</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="title">name</span>&gt;</span>mapred.output.dir<span class="tag">&lt;/<span class="title">name</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="title">value</span>&gt;</span>/user/$&#123;wf:user()&#125;/$&#123;examplesRoot&#125;/output-data/$&#123;outputDir&#125;<span class="tag">&lt;/<span class="title">value</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;/<span class="title">property</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="title">configuration</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="title">map-reduce</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="title">ok</span> <span class="attribute">to</span>=<span class="value">"end"</span>/&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="title">error</span> <span class="attribute">to</span>=<span class="value">"fail"</span>/&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="title">action</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="title">kill</span> <span class="attribute">name</span>=<span class="value">"fail"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="title">message</span>&gt;</span>Map/Reduce failed, error message[$&#123;wf:errorMessage(wf:lastErrorNode())&#125;]<span class="tag">&lt;/<span class="title">message</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="title">kill</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="title">end</span> <span class="attribute">name</span>=<span class="value">"end"</span>/&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="title">workflow-app</span>&gt;</span></span><br></pre></td></tr></table></figure></p>
<h3 id="实战命令">实战命令</h3><p>上传example目录到hdfs用户oozie根目录(/user/oozie)下：<br><figure class="highlight groovy"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">su - oozie</span><br><span class="line">cd <span class="regexp">/usr/</span>hdp<span class="regexp">/current/</span>oozie-server/doc</span><br><span class="line">hdfs dfs -put example example</span><br></pre></td></tr></table></figure></p>
<p>启动任务命令：<br><figure class="highlight groovy"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">oozie job -oozie <span class="string">http:</span><span class="comment">//localhost:11000/oozie -config examples/apps/map-reduce/job.properties -run</span></span><br></pre></td></tr></table></figure></p>
<p>停止任务命令：<br><figure class="highlight dns"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">oozie job -oozie http://localhost:11000/oozie -kill <span class="number">0000002-150</span><span class="number">914143759473</span>-oozie-oozi-W</span><br></pre></td></tr></table></figure></p>
<h3 id="Oozie_Web_UI效果图：">Oozie Web UI效果图：</h3><p><img src="https://raw.githubusercontent.com/stevenxu/tuku/master/navigating.github.io/2015/Oozie_001.JPG" alt="这是一张图片"><br><img src="https://raw.githubusercontent.com/stevenxu/tuku/master/navigating.github.io/2015/Oozie_002.JPG" alt="这是一张图片"><br><img src="https://raw.githubusercontent.com/stevenxu/tuku/master/navigating.github.io/2015/Oozie_003.JPG" alt="这是一张图片"></p>
<p>参考：<br><a href="http://hortonworks.com/hadoop/oozie/" target="_blank" rel="external">http://hortonworks.com/hadoop/oozie/</a><br><a href="http://oozie.apache.org/" target="_blank" rel="external">http://oozie.apache.org/</a><br><a href="http://hortonworks.com/hadoop/oozie/#blog" target="_blank" rel="external">http://hortonworks.com/hadoop/oozie/#blog</a><br><a href="http://hortonworks.com/hadoop/oozie/#forums" target="_blank" rel="external">http://hortonworks.com/hadoop/oozie/#forums</a><br><a href="http://hortonworks.com/blog/introducing-availability-of-hdp-2-3-part-3/" target="_blank" rel="external">http://hortonworks.com/blog/introducing-availability-of-hdp-2-3-part-3/</a><br><a href="https://github.com/yahoo/oozie" target="_blank" rel="external">https://github.com/yahoo/oozie</a><br>书籍：<br>《Apache Oozie: The Workflow Scheduler for Hadoop》<br><a href="http://book.douban.com/subject/26348732/" target="_blank" rel="external">http://book.douban.com/subject/26348732/</a> </p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://navigating.github.io/2015/Oozie：入门概述/" data-id="cigszouh9003cwwlmvad56h8q" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/BigData/">BigData</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Hadoop/">Hadoop</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Oozie/">Oozie</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-2015/大数据技术百度指数201508" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2015/大数据技术百度指数201508/" class="article-date">
  <time datetime="2015-09-16T06:17:00.000Z" itemprop="datePublished">2015-09-16</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/技术/">技术</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2015/大数据技术百度指数201508/">大数据技术百度指数201508</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>关于大数据技术点的搜索指数，这里只关注一下百度指数的结果。</p>
<ol>
<li>当前最热的依次是：Hadoop、Redis、MongoDB、Spark、Storm。可以看到国内Redis、MongoDB的用户很多，有时候比HBase都热，可见热度之高。</li>
<li>从趋势来看，Spark是最强劲的，Hadoop、Redis表现都很不错。</li>
<li>从搜索热词看，当前主要表现在入门介绍、安装、教程的需求量非常大。对于使用中的问题、优化议题还不多，对于监控更少。</li>
<li>当前搜索热词来源Top5的城市：北京、上海、深圳、广州、南京。北京、珠三角、长三角，同时整体上中部IT发展的相对不错。</li>
<li>用户人群的年龄主要是30～39之间，几乎达到50%，其次是20～29，几乎40%，其他年龄段的人很少。</li>
</ol>
<p>首先是意外的收获，就是发现Redis和MongoDB在国内这么火，热词竟然超过了Hadoop了，也许是两个比较简单易用，不像Hadoop如今已经发展成为了一个大家族了。<br>第二个意外是，发现Cloudera、Hortonworks、CHD、HDP尽然不是指数热词，看来一般印象的大数据技术等于Hadoop真的是偏见啊。<br>第三个意外，发现中部城市IT整体发展的不错，除了上海、南京，还包括：成都、重庆、武汉、长沙、西安、郑州。</p>
<p>趋势研究<br><img src="https://raw.githubusercontent.com/stevenxu/tuku/master/navigating.github.io/2015/bigdata_zhishu_baidu_01.JPG" alt="这是一张图片"><br><img src="https://raw.githubusercontent.com/stevenxu/tuku/master/navigating.github.io/2015/bigdata_zhishu_baidu_02.JPG" alt="这是一张图片"></p>
<p>需求图谱<br><img src="https://raw.githubusercontent.com/stevenxu/tuku/master/navigating.github.io/2015/bigdata_zhishu_baidu_03.JPG" alt="这是一张图片"><br><img src="https://raw.githubusercontent.com/stevenxu/tuku/master/navigating.github.io/2015/bigdata_zhishu_baidu_04.JPG" alt="这是一张图片"><br><img src="https://raw.githubusercontent.com/stevenxu/tuku/master/navigating.github.io/2015/bigdata_zhishu_baidu_05.JPG" alt="这是一张图片"><br><img src="https://raw.githubusercontent.com/stevenxu/tuku/master/navigating.github.io/2015/bigdata_zhishu_baidu_06.JPG" alt="这是一张图片"><br><img src="https://raw.githubusercontent.com/stevenxu/tuku/master/navigating.github.io/2015/bigdata_zhishu_baidu_07.JPG" alt="这是一张图片"><br><img src="https://raw.githubusercontent.com/stevenxu/tuku/master/navigating.github.io/2015/bigdata_zhishu_baidu_08.JPG" alt="这是一张图片"><br><img src="https://raw.githubusercontent.com/stevenxu/tuku/master/navigating.github.io/2015/bigdata_zhishu_baidu_09.JPG" alt="这是一张图片"><br><img src="https://raw.githubusercontent.com/stevenxu/tuku/master/navigating.github.io/2015/bigdata_zhishu_baidu_10.JPG" alt="这是一张图片"><br><img src="https://raw.githubusercontent.com/stevenxu/tuku/master/navigating.github.io/2015/bigdata_zhishu_baidu_11.JPG" alt="这是一张图片"><br><img src="https://raw.githubusercontent.com/stevenxu/tuku/master/navigating.github.io/2015/bigdata_zhishu_baidu_12.JPG" alt="这是一张图片"></p>
<p>人群画像<br><img src="https://raw.githubusercontent.com/stevenxu/tuku/master/navigating.github.io/2015/bigdata_zhishu_baidu_13.JPG" alt="这是一张图片"><br><img src="https://raw.githubusercontent.com/stevenxu/tuku/master/navigating.github.io/2015/bigdata_zhishu_baidu_14.JPG" alt="这是一张图片"><br><img src="https://raw.githubusercontent.com/stevenxu/tuku/master/navigating.github.io/2015/bigdata_zhishu_baidu_15.JPG" alt="这是一张图片"></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://navigating.github.io/2015/大数据技术百度指数201508/" data-id="cigszoudm001bwwlmhnpfav2p" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Hadoop/">Hadoop</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/MongoDB/">MongoDB</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Redis/">Redis</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Spark/">Spark</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Storm/">Storm</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-2015/大数据动态之201508" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2015/大数据动态之201508/" class="article-date">
  <time datetime="2015-09-07T08:13:04.000Z" itemprop="datePublished">2015-09-07</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/技术/">技术</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2015/大数据动态之201508/">大数据动态之201508</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>Cloudera：<br>Cloudera Navigator路线图<br><a href="http://blog.cloudera.com/blog/2015/08/whats-next-for-apache-hadoop-data-management-and-governance-cloudera-navigator-roadmap/" target="_blank" rel="external">http://blog.cloudera.com/blog/2015/08/whats-next-for-apache-hadoop-data-management-and-governance-cloudera-navigator-roadmap/</a><br>NoSQL性能测试开放标准套件YCSB加入Cloudera实验室项目中<br><a href="http://blog.cloudera.com/blog/2015/08/ycsb-the-open-standard-for-nosql-benchmarking-joins-cloudera-labs/" target="_blank" rel="external">http://blog.cloudera.com/blog/2015/08/ycsb-the-open-standard-for-nosql-benchmarking-joins-cloudera-labs/</a><br>Spark在TripAdvisor的机器学习应用案例<br><a href="http://blog.cloudera.com/blog/2015/08/using-apache-spark-for-massively-parallel-nlp-at-tripadvisor/" target="_blank" rel="external">http://blog.cloudera.com/blog/2015/08/using-apache-spark-for-massively-parallel-nlp-at-tripadvisor/</a><br>CDH支持Mesos<br><a href="http://blog.cloudera.com/blog/2015/08/how-to-run-apache-mesos-on-cdh/" target="_blank" rel="external">http://blog.cloudera.com/blog/2015/08/how-to-run-apache-mesos-on-cdh/</a><br>HBase开始支持HBase-Spark模块<br><a href="http://blog.cloudera.com/blog/2015/08/apache-spark-comes-to-apache-hbase-with-hbase-spark-module/" target="_blank" rel="external">http://blog.cloudera.com/blog/2015/08/apache-spark-comes-to-apache-hbase-with-hbase-spark-module/</a><br>Navigator Encrypt开始支持YARN Container安全<br><a href="http://blog.cloudera.com/blog/2015/08/how-to-secure-yarn-containers-with-cloudera-navigator-encrypt/" target="_blank" rel="external">http://blog.cloudera.com/blog/2015/08/how-to-secure-yarn-containers-with-cloudera-navigator-encrypt/</a><br>基于Kafka和HBase的近实时集成架构案例: Santanders<br><a href="http://blog.cloudera.com/blog/2015/08/inside-santanders-near-real-time-data-ingest-architecture/" target="_blank" rel="external">http://blog.cloudera.com/blog/2015/08/inside-santanders-near-real-time-data-ingest-architecture/</a> </p>
<p>Hortonworks:<br>Microsoft Azure Gallery开始支持HDP 2.3<br><a href="http://hortonworks.com/blog/hortonworks-sandbox-with-hdp-2-3-is-now-available-on-microsoft-azure-gallery/" target="_blank" rel="external">http://hortonworks.com/blog/hortonworks-sandbox-with-hdp-2-3-is-now-available-on-microsoft-azure-gallery/</a><br>Microsoft Azure支持Spark<br><a href="http://hortonworks.com/blog/microsoft-and-hortonworks-do-spark-in-the-cloud/" target="_blank" rel="external">http://hortonworks.com/blog/microsoft-and-hortonworks-do-spark-in-the-cloud/</a><br>Storm的容错Nimbus架构<br><a href="http://hortonworks.com/blog/fault-tolerant-nimbus-in-apache-storm/" target="_blank" rel="external">http://hortonworks.com/blog/fault-tolerant-nimbus-in-apache-storm/</a> </p>
<p>MapR<br>Spark Streaming with HBase<br><a href="https://www.mapr.com/blog/spark-streaming-hbase" target="_blank" rel="external">https://www.mapr.com/blog/spark-streaming-hbase</a><br>Apache Drill Architecture: The Ultimate Guide<br><a href="https://www.mapr.com/blog/apache-drill-architecture-ultimate-guide" target="_blank" rel="external">https://www.mapr.com/blog/apache-drill-architecture-ultimate-guide</a><br>HBase架构深度剖析<br><a href="https://www.mapr.com/blog/in-depth-look-hbase-architecture" target="_blank" rel="external">https://www.mapr.com/blog/in-depth-look-hbase-architecture</a><br>HBase Schema设计指导<br><a href="https://www.mapr.com/blog/guidelines-hbase-schema-design" target="_blank" rel="external">https://www.mapr.com/blog/guidelines-hbase-schema-design</a><br>如何利用Spark进行机器学习的并行与交互处理<br><a href="https://www.mapr.com/blog/parallel-and-iterative-processing-machine-learning-recommendations-spark" target="_blank" rel="external">https://www.mapr.com/blog/parallel-and-iterative-processing-machine-learning-recommendations-spark</a></p>
<p>Databricks<br>Spark 1.5发布，包含Tungsten，其利用代码生成技术和Cache感知算法，大幅度提升运行时的性能：<br><a href="https://databricks.com/blog/2015/08/18/spark-1-5-preview-now-available-in-databricks.html" target="_blank" rel="external">https://databricks.com/blog/2015/08/18/spark-1-5-preview-now-available-in-databricks.html</a><br><a href="https://databricks.com/blog/2015/04/28/project-tungsten-bringing-spark-closer-to-bare-metal.html" target="_blank" rel="external">https://databricks.com/blog/2015/04/28/project-tungsten-bringing-spark-closer-to-bare-metal.html</a></p>
<p>mongoDB<br>mongoDB 2.x版本发布了2个，3.x发布了3个：<br><a href="http://blog.mongodb.org/post/128063809158/mongodb-306-rc2-is-released" target="_blank" rel="external">http://blog.mongodb.org/post/128063809158/mongodb-306-rc2-is-released</a><br><a href="http://blog.mongodb.org/post/127802855483/mongodb-317-is-released" target="_blank" rel="external">http://blog.mongodb.org/post/127802855483/mongodb-317-is-released</a><br><a href="http://blog.mongodb.org/post/126436298628/mongodb-2611-is-released" target="_blank" rel="external">http://blog.mongodb.org/post/126436298628/mongodb-2611-is-released</a><br><a href="http://blog.mongodb.org/post/126436227873/mongodb-306-rc0-is-released" target="_blank" rel="external">http://blog.mongodb.org/post/126436227873/mongodb-306-rc0-is-released</a><br><a href="http://blog.mongodb.org/post/125850939688/mongodb-2611-rc0-is-released" target="_blank" rel="external">http://blog.mongodb.org/post/125850939688/mongodb-2611-rc0-is-released</a> </p>
<p>Redis</p>
<p>参考：<br>NoSQL大数据分类<br><a href="http://www.nosql-database.org/" target="_blank" rel="external">http://www.nosql-database.org/</a><br>Autodesk基于Mesos的通用事件系统架构<br><a href="http://www.csdn.net/article/2015-08-27/2825550" target="_blank" rel="external">http://www.csdn.net/article/2015-08-27/2825550</a><br>QingCloud推出Spark即服务<br><a href="http://mt.sohu.com/20150826/n419752360.shtml" target="_blank" rel="external">http://mt.sohu.com/20150826/n419752360.shtml</a><br>Spark大数据分析框架的核心部件<br><a href="http://my.oschina.net/u/2306127/blog/489024?p=1" target="_blank" rel="external">http://my.oschina.net/u/2306127/blog/489024?p=1</a><br>Hadoop和大数据：60款顶级开源工具<br><a href="http://os.51cto.com/art/201508/487936.htm" target="_blank" rel="external">http://os.51cto.com/art/201508/487936.htm</a><br>【微信分享】QingCloud周小四：Spark学习简谈<br><a href="http://www.csdn.net/article/2015-08-07/2825404" target="_blank" rel="external">http://www.csdn.net/article/2015-08-07/2825404</a><br>【微信分享】李滔：搜狐基于Spark的新闻和广告推荐实战<br><a href="http://www.csdn.net/article/2015-07-31/2825353" target="_blank" rel="external">http://www.csdn.net/article/2015-07-31/2825353</a><br>【微信分享】王团结：七牛是如何搞定每天500亿条日志的<br><a href="http://www.csdn.net/article/2015-07-30/2825342" target="_blank" rel="external">http://www.csdn.net/article/2015-07-30/2825342</a><br>对七牛云存储日志处理的思考<br><a href="http://hadoop1989.com/2015/08/02/Think-QiNiu-Cloud/" target="_blank" rel="external">http://hadoop1989.com/2015/08/02/Think-QiNiu-Cloud/</a><br>STORM在线业务实践-集群空闲CPU飙高问题排查<br><a href="http://daiwa.ninja/index.php/2015/07/18/storm-cpu-overload/" target="_blank" rel="external">http://daiwa.ninja/index.php/2015/07/18/storm-cpu-overload/</a><br>Spark与Flink：对比与分析<br><a href="http://www.csdn.net/article/2015-07-16/2825232" target="_blank" rel="external">http://www.csdn.net/article/2015-07-16/2825232</a><br>一共81个，开源大数据处理工具汇总（上）<br><a href="http://www.36dsj.com/archives/24852" target="_blank" rel="external">http://www.36dsj.com/archives/24852</a><br>一共81个，开源大数据处理工具汇总（下）<br><a href="http://home.hylanda.com/show_26_11558.html" target="_blank" rel="external">http://home.hylanda.com/show_26_11558.html</a></p>
<p>总结：</p>
<pre><code><span class="bullet">1. </span>Cloudera和Hortonworks都开始注重数据管理和数据治理，Cloudera是通过增强Cloudera Navigator来实现，Hortonworks通过引入Informatic组件Fabric来实现。
<span class="bullet">2. </span>Spark 1.5发布；
<span class="bullet">3. </span>HBase、Cassandra是Column Families/Wide Column Store；
<span class="bullet">4. </span>MongoDB是Document Store；
<span class="bullet">5. </span>Redis是Key Value/Tuple Store；
<span class="bullet">6. </span>Neo4J是Graph Databases；
</code></pre>
      
    </div>
    <footer class="article-footer">
      <a data-url="http://navigating.github.io/2015/大数据动态之201508/" data-id="cigszoueh001swwlmkmblgx76" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/BigData/">BigData</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/HBase/">HBase</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Hadoop/">Hadoop</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/MongoDB/">MongoDB</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Spark/">Spark</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-2015/SparkOnHBase-Cloudera" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2015/SparkOnHBase-Cloudera/" class="article-date">
  <time datetime="2015-08-18T05:35:51.000Z" itemprop="datePublished">2015-08-18</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/技术/">技术</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2015/SparkOnHBase-Cloudera/">SparkOnHBase(Cloudera)</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>2014年2月4日，Cloudera宣布CDH支持Spark，在CDH 4.4中引入Spark 0.9。<br><a href="http://vision.cloudera.com/apache-spark-welcome-to-the-cdh-family/" target="_blank" rel="external">http://vision.cloudera.com/apache-spark-welcome-to-the-cdh-family/</a><br>在引入的时候强调了三点：</p>
<pre><code><span class="bullet">1. </span>Machine Learning
<span class="bullet">2. </span>Spark Streaming
<span class="bullet">3. </span>Faster Batch
</code></pre><p>2014年7月，在github上创建了Apache HBase与Spark的集成项目SparkOnHBase<br><a href="http://blog.cloudera.com/blog/2014/12/new-in-cloudera-labs-sparkonhbase/" target="_blank" rel="external">http://blog.cloudera.com/blog/2014/12/new-in-cloudera-labs-sparkonhbase/</a><br><a href="https://github.com/cloudera-labs/SparkOnHBase" target="_blank" rel="external">https://github.com/cloudera-labs/SparkOnHBase</a><br>当前SparkOnHBase主要集中在这几个方面的功能改进：</p>
<pre><code>1. 在MR的map或者reduce阶段对HBase的全量访问(Full Access)；
2. 支持bulk <span class="operator"><span class="keyword">load</span>；
<span class="number">3.</span> 支持<span class="keyword">get</span>, put, <span class="keyword">delete</span>等bulk操作(bulk operation)；
<span class="number">4.</span> 支持成为<span class="keyword">SQL</span> <span class="keyword">engines</span>。</span>
</code></pre><p>2015年8月SparkOnHBase项目有了里程碑似的进展，被提交到HBase的主干(trunk)上，模块名为HBase-Spark Module，HBASE-13992 。<br><a href="http://blog.cloudera.com/blog/2015/08/apache-spark-comes-to-apache-hbase-with-hbase-spark-module/" target="_blank" rel="external">http://blog.cloudera.com/blog/2015/08/apache-spark-comes-to-apache-hbase-with-hbase-spark-module/</a><br><a href="https://issues.apache.org/jira/browse/HBASE-13992" target="_blank" rel="external">https://issues.apache.org/jira/browse/HBASE-13992</a><br>HBase-Spark module相比于SparkOnHBase在架构上没有什么变化：<br><img src="https://raw.githubusercontent.com/stevenxu/tuku/master/navigating.github.io/2015/Cloudera_Spark_2015_01.png" alt="这是一张图片"><br>在具体实现上当前有三点改进：</p>
<pre><code><span class="bullet">1. </span>使用了全新的HBase 1.0+的API；
<span class="bullet">2. </span>从RDD和DStream functions操作HBase的直接支持；
<span class="bullet">3. </span>简化 foreach 和 map functions；
</code></pre><p>计划工作有两项：</p>
<pre><code><span class="bullet">1. </span>Spark-HBase Module支持bulkload；
<span class="bullet">2. </span>Spark-HBase Module支持Spark DataFrame DataSource；
</code></pre><p><a href="https://issues.apache.org/jira/browse/HBASE-14150" target="_blank" rel="external">https://issues.apache.org/jira/browse/HBASE-14150</a><br><a href="https://issues.apache.org/jira/browse/HBASE-14181" target="_blank" rel="external">https://issues.apache.org/jira/browse/HBASE-14181</a> </p>
<p>实际上集成Spark作为计算引擎的项目还有Hive和Pig：<br><a href="http://www.cloudera.com/content/cloudera/en/products-and-services/cdh/spark.html" target="_blank" rel="external">http://www.cloudera.com/content/cloudera/en/products-and-services/cdh/spark.html</a><br><a href="http://blog.cloudera.com/blog/2015/02/download-the-hive-on-spark-beta/" target="_blank" rel="external">http://blog.cloudera.com/blog/2015/02/download-the-hive-on-spark-beta/</a><br><a href="http://blog.cloudera.com/blog/2014/09/pig-is-flying-apache-pig-on-apache-spark/" target="_blank" rel="external">http://blog.cloudera.com/blog/2014/09/pig-is-flying-apache-pig-on-apache-spark/</a> </p>
<p>参考：<br><a href="http://blog.cloudera.com/blog/2015/08/apache-spark-comes-to-apache-hbase-with-hbase-spark-module/" target="_blank" rel="external">http://blog.cloudera.com/blog/2015/08/apache-spark-comes-to-apache-hbase-with-hbase-spark-module/</a><br><a href="https://github.com/cloudera-labs/SparkOnHBase" target="_blank" rel="external">https://github.com/cloudera-labs/SparkOnHBase</a><br><a href="http://blog.cloudera.com/blog/2013/11/putting-spark-to-use-fast-in-memory-computing-for-your-big-data-applications/" target="_blank" rel="external">http://blog.cloudera.com/blog/2013/11/putting-spark-to-use-fast-in-memory-computing-for-your-big-data-applications/</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://navigating.github.io/2015/SparkOnHBase-Cloudera/" data-id="cigszougr0035wwlmdr2tidh6" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/BigData/">BigData</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Cloudera/">Cloudera</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/HBase/">HBase</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Spark/">Spark</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-2015/学习《Hadoop生态技术在阿里全网商品搜索实战》" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2015/学习《Hadoop生态技术在阿里全网商品搜索实战》/" class="article-date">
  <time datetime="2015-08-17T04:41:00.000Z" itemprop="datePublished">2015-08-17</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/技术/">技术</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2015/学习《Hadoop生态技术在阿里全网商品搜索实战》/">学习《Hadoop生态技术在阿里全网商品搜索实战》</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>资料参见文档：<a href="http://wenku.it168.com/d_001428550.shtml" target="_blank" rel="external">http://wenku.it168.com/d_001428550.shtml</a><br>版本:</p>
<pre><code><span class="bullet">1. </span>Hadoop: 基于 Hadoop 2.2 的阿里定制版
<span class="bullet">2. </span>HBase: 基于 HBase 0.94 的阿里定制版
</code></pre><p>部署方式：</p>
<pre><code><span class="bullet">1. </span>服务总数近1000台，分2个集群；
<span class="bullet">2. </span>Hadoop/HBase共同部署；
</code></pre><p>分析：服务器数量可能是2014年初的数据；HBase部署方式可能是RS和DN部署在同一个节点上。<br>服务器配置：</p>
<pre><code><span class="bullet">1. </span>CPU：24/32 Cores
<span class="bullet">2. </span>Memory：48G/96G
<span class="bullet">3. </span>Disk：12 <span class="bullet">* 1T SATA Disk 或者 12 *</span> 2T SATA Disk
</code></pre><p>分析：服务器配置计算能力比较强，内存和磁盘配置都不是很高。<br>大数据组件：</p>
<pre><code><span class="bullet">1. </span>HDFS + YARN
<span class="bullet">2. </span>HBase
<span class="bullet">3. </span>MR
<span class="bullet">4. </span>iStream
<span class="bullet">5. </span>Spark
<span class="bullet">6. </span>HQueue
<span class="bullet">7. </span>Phoenix
<span class="bullet">8. </span>OpenTSDB
<span class="bullet">9. </span>Zookeeper
</code></pre><p><img src="https://raw.githubusercontent.com/stevenxu/tuku/master/navigating.github.io/2015/Ali_Search_2015_01.JPG" alt="这是一张图片"><br>分析：</p>
<pre><code>* 对于基于HBase的HQueue是一个创新，当前没有看到更多的资料，无法和Kafka对比。(在性能和TPC上可能Kafka更强大，但通过对HBase的复用做出Queue，很赞。)
* iStream是一个Steaming <span class="function_start"><span class="keyword">on</span></span> YARN的产品，从架构上看很类似storm的设计理念。
</code></pre><p><img src="https://raw.githubusercontent.com/stevenxu/tuku/master/navigating.github.io/2015/Ali_Search_2015_02.JPG" alt="这是一张图片"><br>HBase<br>HBase应用</p>
<pre><code><span class="number">1</span>. <span class="function"><span class="title">Phoenix</span><span class="params">(SQL on HBase)</span></span>
<span class="number">2</span>. <span class="function"><span class="title">OpenTSDB</span><span class="params">(Metrics on HBase)</span></span>
<span class="number">3</span>. <span class="function"><span class="title">HQueue</span><span class="params">(Queue on HBase)</span></span>
</code></pre><p>分析：</p>
<pre><code><span class="bullet">* </span>在HBase集群上运行了Phoenix、OpenTSDB、HQueue三种应用，因此HBase具有作为一种数据存储的基础设施的能力。
</code></pre><p>HBase网页库存储方案</p>
<pre><code>1. 版本从0<span class="class">.25</span>、0<span class="class">.26</span>、0<span class="class">.90</span>、0<span class="class">.92</span>、0<span class="class">.94</span>、0<span class="class">.98</span>逐步升级的。
2. <span class="tag">HBase</span>集群规模从30多台持续升级到300多台。
3. <span class="tag">HBase</span> <span class="tag">Region</span>个数从 1<span class="tag">K</span> 增长到 20<span class="tag">K</span>。
4. 网页数量从 十亿 增长到 百亿。
</code></pre><p>存储业务数据的CF如下：<br><img src="https://raw.githubusercontent.com/stevenxu/tuku/master/navigating.github.io/2015/Ali_Search_2015_05.JPG" alt="这是一张图片"><br>在HBase/Hadoop的I/O上的优化如下：</p>
<pre><code><span class="bullet">1. </span>Compression：Snappy/Gzip
<span class="bullet">2. </span>Block Encoding：Diff
<span class="bullet">3. </span>Block Size：64KB - 1MB
<span class="bullet">4. </span>Block Cache：InMemory
<span class="bullet">5. </span>Bloom Filter：ROW
</code></pre><p><img src="https://raw.githubusercontent.com/stevenxu/tuku/master/navigating.github.io/2015/Ali_Search_2015_06.JPG" alt="这是一张图片"><br>HBase Coprocessor应用<br>在网页库中使用了三种Coprocessor：</p>
<pre><code><span class="bullet">1. </span>Trace Coprocessor
<span class="bullet">2. </span>Clone Coprocessor
<span class="bullet">3. </span>Incremental Coprocessor
</code></pre><p><img src="https://raw.githubusercontent.com/stevenxu/tuku/master/navigating.github.io/2015/Ali_Search_2015_07.JPG" alt="这是一张图片"><br>分析：</p>
<pre><code><span class="keyword">*</span> 如果HBase集群就是两个集群中的一个，那么裸存储容量最大为：12 <span class="keyword">*</span> 2T <span class="keyword">*</span> 300 = 7200T = 7.2P，如果考虑到压缩、复制因子、数据冗余、容量冗余，可以存储有效数据约为：8P 数据。 
<span class="keyword">*</span> 平均每台服务器运行的Region个数：20K/300 = 67 个，这个数字比较符合HBase官方推荐的值。
<span class="keyword">*</span> Compression方法用了snappy和gzip两种。CF访问频繁，使用snappy，速度快；Raw CF访问较少，使用gzip，压缩比高。
<span class="keyword">*</span> Block Encoding使用Diff，0.98后改用PrefixTree；
<span class="keyword">*</span> Block Size的大小为 64KB - 1MB 
</code></pre><p>实时处理架构<br><img src="https://raw.githubusercontent.com/stevenxu/tuku/master/navigating.github.io/2015/Ali_Search_2015_08.JPG" alt="这是一张图片"><br>分析</p>
<pre><code><span class="subst">*</span> Metrics实时采集的流程大约是：HBase <span class="subst">-&gt; </span>HQueue <span class="subst">-&gt; </span>iStream <span class="subst">-&gt; </span>OpenTSDB <span class="keyword">on</span> HBase
<span class="subst">*</span> 流处理的全流程：HBase <span class="subst">-&gt; </span>HQueue <span class="subst">-&gt; </span>iStream <span class="subst">-&gt; </span>HQueue <span class="subst">-&gt; </span>iSearch/iStream
<span class="subst">*</span> 参见前文分析，猜测iStream是一个类似Storm的YARN框架。
</code></pre><p>关于阿里搜索自研的iStream的架构与文档参加如下：<br><img src="https://raw.githubusercontent.com/stevenxu/tuku/master/navigating.github.io/2015/Ali_Search_2015_09.JPG" alt="这是一张图片"><br><img src="https://raw.githubusercontent.com/stevenxu/tuku/master/navigating.github.io/2015/Ali_Search_2015_10.JPG" alt="这是一张图片"></p>
<p><a href="http://www.infoq.com/cn/news/2014/09/hadoop-alibaba-yarn" target="_blank" rel="external">http://www.infoq.com/cn/news/2014/09/hadoop-alibaba-yarn</a><br><a href="http://club.alibabatech.org/resource_detail.htm?topicId=140" target="_blank" rel="external">http://club.alibabatech.org/resource_detail.htm?topicId=140</a> </p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://navigating.github.io/2015/学习《Hadoop生态技术在阿里全网商品搜索实战》/" data-id="cigszoudb0011wwlm41i9li3m" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/BigData/">BigData</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/HBase/">HBase</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/HQueue/">HQueue</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Hadoop/">Hadoop</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/iStream/">iStream</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-2015/Hadoop发行版(2015第二季)" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2015/Hadoop发行版(2015第二季)/" class="article-date">
  <time datetime="2015-08-11T14:40:02.000Z" itemprop="datePublished">2015-08-11</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/技术/">技术</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2015/Hadoop发行版(2015第二季)/">Hadoop发行版(2015第二季)</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>自从Hadoop的出现，引领大数据的浪潮越来越热。大数据存储的主要技术路线有几种：<br>1.Hadoop<br>2.Cassandra<br>3.MongoDB<br>Hadoop是Apache的开源项目，同时有很多商业公司对Hadoop进行版本发行和商业支持,参见：<a href="http://wiki.apache.org/hadoop/Distributions%20and%20Commercial%20Support" target="_blank" rel="external">http://wiki.apache.org/hadoop/Distributions%20and%20Commercial%20Support</a><br>其中在最有名为人所知的三家：<br>1.Cloudera<br><img src="https://raw.githubusercontent.com/stevenxu/tuku/master/navigating.github.io/2015/Hadoop_2015_1.JPG" alt="这是一张图片"><br>2.Hortonwork<br><img src="https://raw.githubusercontent.com/stevenxu/tuku/master/navigating.github.io/2015/Hadoop_2015_2.JPG" alt="这是一张图片"><br>3.MapR<br><img src="https://raw.githubusercontent.com/stevenxu/tuku/master/navigating.github.io/2015/Hadoop_2015_3.JPG" alt="这是一张图片"><br>这三个厂商之中，MapR最为封闭；Hortonworks最为开放，产品线全开源，在线文档比较丰富。国内使用Cloudera CDH和Hortonworks的应该是最多的。<br>国内市场当前有两家也非常有竞争力，一家是Huawei，一家是星环科技。<br>4.Huawei FusionInsight<br><img src="https://raw.githubusercontent.com/stevenxu/tuku/master/navigating.github.io/2015/Hadoop_2015_7.JPG" alt="这是一张图片"><br>5.星环科技TDH，TDH对Spark的支持据说非常不错的，有良好的性能表现。<br><img src="https://raw.githubusercontent.com/stevenxu/tuku/master/navigating.github.io/2015/Hadoop_2015_6.JPG" alt="这是一张图片"><br>准实时计算框架/即席查询<br>1.CDH的框架有：Impala + Spark；<br>2.HDP的框架有：Tez + Spark；<br>3.MapR的框架有：Drill + Tez + Spark。<br>关于Spark：<br>2014年大数据最热门的技术路线就是算是Spark了，而且得力于Spark不遗余力的推广和快速成长。Cloudera是最早支持Spark，也是最激进的。下图即是Spark在Cloudera产品线中的定位：<br><img src="https://raw.githubusercontent.com/stevenxu/tuku/master/navigating.github.io/2015/Hadoop_2015_4.JPG" alt="这是一张图片"><br>实际上基于Hadoop的快速计算框架的发展才刚刚开始，社区中已经有如下几种：<br>1.Spark/Shark<br>2.Hortonworks Tez/Stinger<br>3.Cloudera Impala<br>4.Apache Drill<br>5.Apache Flink<br>6.Apache Nifi<br>7.Facebook Presto</p>
<p>SQL on Hadoop<br>SQL on Hadoop的发展主要是传统的SQL过于强大，人才库非常庞大，从Hadoop出现的第一天就在SQL发力。当前技术路线上更是百花齐放，这里从开源和商业产品来说。<br>Open Source</p>
<pre><code><span class="bullet">1. </span>Apache Hive(Hive on MR)
<span class="bullet">2. </span>Hortonworks Tez/Stinger(Hive on Tez)
<span class="bullet">3. </span>Cloudera Impala
<span class="bullet">4. </span>Shark
<span class="bullet">5. </span>Spark SQL
<span class="bullet">6. </span>Apache Drill - MapR
<span class="bullet">7. </span>Facebook Presto
<span class="bullet">8. </span>Apache Phoenix(on HBase) - Saleforce
<span class="bullet">9. </span>Apache Kylin
<span class="bullet">10. </span>Apache Tajo - (Database Lab, Korea University)
<span class="bullet">11. </span>Cascading Lingual - (Cascading, Optiq)
<span class="bullet">12. </span>Dato (GraphLab) - Dato
</code></pre><p>Commercial</p>
<pre><code><span class="bullet">1. </span>EMC HAWQ
<span class="bullet">2. </span>IBM BigSQL
<span class="bullet">3. </span>TERADATA SQL-H
<span class="bullet">4. </span>Hadapt/HadoopDB
<span class="bullet">5. </span>Transwarp Inceptor
</code></pre><p>在开源领域里面，当前比受追捧的主要是：Hive、Impala、Spark、Phoenix。</p>
<p>参考：<br>SQL on Hadoop开源项目总结<br><a href="http://segmentfault.com/a/1190000002799235" target="_blank" rel="external">http://segmentfault.com/a/1190000002799235</a><br>如何选择满足需求的SQL on Hadoop系统<br><a href="http://www.searchbi.com.cn/showcontent_89816.htm" target="_blank" rel="external">http://www.searchbi.com.cn/showcontent_89816.htm</a><br>2015Hadoop技术峰会演讲速记3： 基于Transwarp Stream和Discover的实时大数据人流密度估计<br><a href="http://www.transwarp.cn/news/detail?id=70" target="_blank" rel="external">http://www.transwarp.cn/news/detail?id=70</a> </p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://navigating.github.io/2015/Hadoop发行版(2015第二季)/" data-id="cigszouia003uwwlmjnl0rsvr" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/BigData/">BigData</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/CDH/">CDH</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/HDP/">HDP</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Hadoop/">Hadoop</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/SQL-on-Hadoop/">SQL on Hadoop</a></li></ul>

    </footer>
  </div>
  
</article>


  
  
    <nav id="page-nav">
      <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="page-number" href="/page/3/">3</a><span class="space">&hellip;</span><a class="page-number" href="/page/12/">12</a><a class="extend next" rel="next" href="/page/2/">Next &raquo;</a>
    </nav>
  
</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/技术/">技术</a><span class="category-list-count">74</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/生活/">生活</a><span class="category-list-count">12</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/读书/">读书</a><span class="category-list-count">25</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/Ambari/" style="font-size: 11.11px;">Ambari</a> <a href="/tags/Android/" style="font-size: 14.44px;">Android</a> <a href="/tags/Annotation/" style="font-size: 10px;">Annotation</a> <a href="/tags/Apple/" style="font-size: 10px;">Apple</a> <a href="/tags/Architecture/" style="font-size: 14.44px;">Architecture</a> <a href="/tags/BigData/" style="font-size: 20px;">BigData</a> <a href="/tags/CDH/" style="font-size: 15.56px;">CDH</a> <a href="/tags/Cassandra/" style="font-size: 10px;">Cassandra</a> <a href="/tags/Cloudera/" style="font-size: 10px;">Cloudera</a> <a href="/tags/Eclipse/" style="font-size: 10px;">Eclipse</a> <a href="/tags/Flume/" style="font-size: 10px;">Flume</a> <a href="/tags/Google/" style="font-size: 11.11px;">Google</a> <a href="/tags/HBase/" style="font-size: 14.44px;">HBase</a> <a href="/tags/HDP/" style="font-size: 16.67px;">HDP</a> <a href="/tags/HQueue/" style="font-size: 10px;">HQueue</a> <a href="/tags/Hadoop/" style="font-size: 20px;">Hadoop</a> <a href="/tags/Hive/" style="font-size: 11.11px;">Hive</a> <a href="/tags/Impala/" style="font-size: 10px;">Impala</a> <a href="/tags/JNI/" style="font-size: 10px;">JNI</a> <a href="/tags/JUnit/" style="font-size: 11.11px;">JUnit</a> <a href="/tags/JVM/" style="font-size: 10px;">JVM</a> <a href="/tags/Java/" style="font-size: 18.89px;">Java</a> <a href="/tags/Kafka/" style="font-size: 11.11px;">Kafka</a> <a href="/tags/Linux/" style="font-size: 10px;">Linux</a> <a href="/tags/MapR/" style="font-size: 10px;">MapR</a> <a href="/tags/MongoDB/" style="font-size: 13.33px;">MongoDB</a> <a href="/tags/NIO/" style="font-size: 12.22px;">NIO</a> <a href="/tags/Netty/" style="font-size: 11.11px;">Netty</a> <a href="/tags/NoSQL/" style="font-size: 10px;">NoSQL</a> <a href="/tags/Oozie/" style="font-size: 10px;">Oozie</a> <a href="/tags/Performance/" style="font-size: 10px;">Performance</a> <a href="/tags/Redis/" style="font-size: 10px;">Redis</a> <a href="/tags/Review/" style="font-size: 10px;">Review</a> <a href="/tags/Ruby/" style="font-size: 10px;">Ruby</a> <a href="/tags/SOA/" style="font-size: 10px;">SOA</a> <a href="/tags/SQL-on-Hadoop/" style="font-size: 11.11px;">SQL on Hadoop</a> <a href="/tags/Spark/" style="font-size: 17.78px;">Spark</a> <a href="/tags/Storm/" style="font-size: 10px;">Storm</a> <a href="/tags/Tez/" style="font-size: 10px;">Tez</a> <a href="/tags/Ubuntu/" style="font-size: 10px;">Ubuntu</a> <a href="/tags/XP/" style="font-size: 11.11px;">XP</a> <a href="/tags/blog/" style="font-size: 10px;">blog</a> <a href="/tags/github/" style="font-size: 10px;">github</a> <a href="/tags/hexo/" style="font-size: 11.11px;">hexo</a> <a href="/tags/iOS/" style="font-size: 10px;">iOS</a> <a href="/tags/iStream/" style="font-size: 10px;">iStream</a>
    </div>
  </div>

  
    <div class="widget-wrap">
  <input type="text" class="st-default-search-input">
</div>
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recents</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2015/JVM监控与调优/">JVM监控与调优</a>
          </li>
        
          <li>
            <a href="/2015/大数据动态之201509/">大数据动态之201509</a>
          </li>
        
          <li>
            <a href="/2015/学习《Impala-vs-Hive-Performance-Benchmark》/">学习《Impala vs. Hive Performance Benchmark》</a>
          </li>
        
          <li>
            <a href="/2015/Hortonworks-HDP-2-3-0/">Hortonworks HDP 2.3.0</a>
          </li>
        
          <li>
            <a href="/2015/Oozie：入门概述/">Oozie：入门概述</a>
          </li>
        
          <li>
            <a href="/2015/大数据技术百度指数201508/">大数据技术百度指数201508</a>
          </li>
        
          <li>
            <a href="/2015/大数据动态之201508/">大数据动态之201508</a>
          </li>
        
          <li>
            <a href="/2015/SparkOnHBase-Cloudera/">SparkOnHBase(Cloudera)</a>
          </li>
        
          <li>
            <a href="/2015/学习《Hadoop生态技术在阿里全网商品搜索实战》/">学习《Hadoop生态技术在阿里全网商品搜索实战》</a>
          </li>
        
          <li>
            <a href="/2015/Hadoop发行版(2015第二季)/">Hadoop发行版(2015第二季)</a>
          </li>
        
          <li>
            <a href="/2015/学习《七牛是如何搞定每天500亿条日志的》/">学习《七牛是如何搞定每天500亿条日志的》</a>
          </li>
        
          <li>
            <a href="/2015/学习《腾讯在Spark上的应用与实践优化》/">学习《腾讯在Spark上的应用与实践优化》</a>
          </li>
        
          <li>
            <a href="/2015/13-14年收集的大数据的一些技术架构图/">13~14年收集的大数据的一些技术架构图</a>
          </li>
        
          <li>
            <a href="/2015/读《微软研发制胜策略》/">读《微软研发制胜策略》</a>
          </li>
        
          <li>
            <a href="/2015/大数据动态之201507/">大数据动态之201507</a>
          </li>
        
          <li>
            <a href="/2015/使用Hexo搭建Github静态博客/">使用Hexo搭建Github静态博客</a>
          </li>
        
          <li>
            <a href="/2015/hello-world/">Hello World</a>
          </li>
        
          <li>
            <a href="/2015/Hadoop-2-7-1-发布/">Hadoop 2.7.1 发布</a>
          </li>
        
          <li>
            <a href="/2015/读《Deploying-Apache-Kafka-A-Practical-FAQ》/">读《Deploying Apache Kafka: A Practical FAQ》</a>
          </li>
        
          <li>
            <a href="/2015/大数据动态之201506/">大数据动态之201506</a>
          </li>
        
      </ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/11/">十一月 2015</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/10/">十月 2015</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/09/">九月 2015</a><span class="archive-list-count">5</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/08/">八月 2015</a><span class="archive-list-count">7</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/07/">七月 2015</a><span class="archive-list-count">5</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/06/">六月 2015</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/05/">五月 2015</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/03/">三月 2015</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/01/">一月 2015</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2013/12/">十二月 2013</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2013/08/">八月 2013</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2012/12/">十二月 2012</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2011/11/">十一月 2011</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2011/10/">十月 2011</a><span class="archive-list-count">7</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2011/03/">三月 2011</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2010/11/">十一月 2010</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2010/09/">九月 2010</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2010/08/">八月 2010</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2010/06/">六月 2010</a><span class="archive-list-count">5</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2010/05/">五月 2010</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2010/04/">四月 2010</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2010/03/">三月 2010</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2010/01/">一月 2010</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2009/12/">十二月 2009</a><span class="archive-list-count">6</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2009/10/">十月 2009</a><span class="archive-list-count">8</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2008/04/">四月 2008</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2008/03/">三月 2008</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2007/11/">十一月 2007</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2007/08/">八月 2007</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2007/07/">七月 2007</a><span class="archive-list-count">5</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2007/06/">六月 2007</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2007/05/">五月 2007</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2007/03/">三月 2007</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2006/12/">十二月 2006</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2006/11/">十一月 2006</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2006/10/">十月 2006</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2006/08/">八月 2006</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2006/04/">四月 2006</a><span class="archive-list-count">4</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2005/09/">九月 2005</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2005/08/">八月 2005</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2005/05/">五月 2005</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2005/02/">二月 2005</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2005/01/">一月 2005</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2004/12/">十二月 2004</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2004/11/">十一月 2004</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2004/10/">十月 2004</a><span class="archive-list-count">7</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2004/09/">九月 2004</a><span class="archive-list-count">4</span></li></ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2015 Steven Xu<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
    <a href="/sitemap.xml" class="mobile-nav-link">Sitemap</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css" type="text/css">
  <script src="/fancybox/jquery.fancybox.pack.js" type="text/javascript"></script>


<script src="/js/script.js" type="text/javascript"></script>

  </div>
</body>
</html>