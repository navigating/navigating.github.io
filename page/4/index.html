<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>On The Open Way</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description">
<meta property="og:type" content="website">
<meta property="og:title" content="On The Open Way">
<meta property="og:url" content="http://navigating.github.io/page/4/index.html">
<meta property="og:site_name" content="On The Open Way">
<meta property="og:description">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="On The Open Way">
<meta name="twitter:description">
<meta name="twitter:creator" content="@xujinghui">
  
    <link rel="alternative" href="/atom.xml" title="On The Open Way" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  <link rel="stylesheet" href="/css/style.css" type="text/css">
  
<script type="text/javascript">
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "//hm.baidu.com/hm.js?5554b1765137f9e84f6b5d1958c4bdfd";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>

  

  <script type="text/javascript">
  (function(w,d,t,u,n,s,e){w['SwiftypeObject']=n;w[n]=w[n]||function(){
  (w[n].q=w[n].q||[]).push(arguments);};s=d.createElement(t);
  e=d.getElementsByTagName(t)[0];s.async=1;s.src=u;e.parentNode.insertBefore(s,e);
  })(window,document,'script','//s.swiftypecdn.com/install/v2/st.js','_st');

  _st('install','W7_-_9WqoJq6hWaJJ8zZ','2.0.0');
</script>
</head>
<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">On The Open Way</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="/" id="subtitle">自信人生二百年，会当水击三千里！</a>
        </h2>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
          <a class="main-nav-link" href="/sitemap.xml">Sitemap</a>
        
      </nav>
      <nav id="sub-nav">	    
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>		
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" results="0" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://navigating.github.io"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main">
  
    <article id="post-2015/Hadoop-2-7-1-发布" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2015/Hadoop-2-7-1-发布/" class="article-date">
  <time datetime="2015-07-09T13:49:30.000Z" itemprop="datePublished">2015-07-09</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/技术/">技术</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2015/Hadoop-2-7-1-发布/">Hadoop 2.7.1 发布</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>2015年7月6日，Apache Hadoop的稳定版本 2.7.1 正式发布。<br><a href="http://hadoop.apache.org/releases.html#Release+Notes" target="_blank" rel="external">http://hadoop.apache.org/releases.html#Release+Notes</a> </p>
<p>Hadoop 2.7的一个小版本发布了，本版本属于稳定版本。<br>修复了2.7.0中存在的131个bug。<br>这是2.7.x第一个稳定版本，增强的功能列表请通过2.7.0版本部分查看。<br>按着计划，下一个2.7.x的小版本是2.7.2.</p>
<p>原文：<br>06 July, 2015: Release 2.7.1 (stable) availableA point release for the 2.7 line. This release is now considered stable.<br>Please see the Hadoop 2.7.1 Release Notes for the list of 131 bug fixes and patches since the previous release 2.7.0. Please look at the 2.7.0 section below for the list of enhancements enabled by this first stable release of 2.7.x.</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://navigating.github.io/2015/Hadoop-2-7-1-发布/" data-id="ciq5hr066005y80lmpki8qjvq" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Hadoop/">Hadoop</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-2015/读《Deploying-Apache-Kafka-A-Practical-FAQ》" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2015/读《Deploying-Apache-Kafka-A-Practical-FAQ》/" class="article-date">
  <time datetime="2015-07-02T14:57:45.000Z" itemprop="datePublished">2015-07-02</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/技术/">技术</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2015/读《Deploying-Apache-Kafka-A-Practical-FAQ》/">读《Deploying Apache Kafka: A Practical FAQ》</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>Cloudera发布了Kafka的好文，《Deploying Apache Kafka: A Practical FAQ》，参见：<a href="http://blog.cloudera.com/blog/2015/07/deploying-apache-kafka-a-practical-faq" target="_blank" rel="external">http://blog.cloudera.com/blog/2015/07/deploying-apache-kafka-a-practical-faq</a></p>
<p>是否应当为Kafka Broker使用 固态硬盘 (SSD)<br>实际上使用SSD盘并不能显著地改善 Kafka 的性能，主要有两个原因：</p>
<pre><code>* Kafka写磁盘是异步的，不是同步的。就是说，除了启动、停止之外，Kafka的任何操作都不会去等待磁盘同步（sync）完成；而磁盘同步(disk syncs)总是在后台完成的。这就是为什么Kafka消息至少复制到三个副本是至关重要的，因为一旦单个副本崩溃，这个副本就会丢失数据无法同步写到磁盘。
* 每一个Kafka <span class="keyword">Partition</span>被存储为一个串行的WAL（<span class="keyword">Write</span> Ahead <span class="keyword">Log</span>）日志文件。因此，除了极少数的数据查询，Kafka中的磁盘读写都是串行的。现代的操作系统已经对串行读写做了大量的优化工作。
</code></pre><p>如何对Kafka Broker上持久化的数据进行加密<br>目前，Kafka不提供任何机制对Broker上持久化的数据进行加密。用户可以自己对写入到Kafka的数据进行加密，即是，生产者(Producers)在写Kafka之前加密数据，消费者(Consumers)能解密收到的消息。这就要求生产者(Producers)把加密协议(protocols)和密钥(keys)分享给消费者(Consumers)。<br>另外一种选择，就是使用软件提供的文件系统级别的加密，例如Cloudera Navigator Encrypt。Cloudera Navigator Encrypt是Cloudera企业版(Cloudera Enterprise)的一部分，在应用程序和文件系统之间提供了一个透明的加密层。<br>Apache Zookeeper正成为Kafka集群的一个痛点(pain point)，真的吗？<br>Kafka高级消费者(high-level consumer)的早期版本(0.8.1或更早)使用Zookeeper来维护读的偏移量(offsets，主要是Topic的每个Partition的读偏移量)。如果有大量生产者(consumers)同时从Kafka中读数据，对Kafka的读写负载可能就会超出它的容量，Zookeeper就变成一个瓶颈(bottleneck)。当然，这仅仅出现在一些很极端的案例中(extreme cases)，即有成百上千个消费者(consumers)在使用同一个Zookeeper集群来管理偏移量(offset)。<br>不过，这个问题已经在Kafka当前的版本(0.8.2)中解决。从版本0.8.2开始，高级消费者(high-level consumer)能够使用Kafka自己来管理偏移量(offsets)。本质上讲，它使用一个单独的Kafka Topic来管理最近的读偏移量(read offsets)，因此偏移量管理(offset management)不再要求Zookeeper必须存在。然后，用户将不得不面临选择是用Kafka还是Zookeeper来管理偏移量(offsets)，由消费者(consumer)配置参数 offsets.storage 决定。<br>Cloudera强烈推荐使用Kafka来存储偏移量。当然，为了保证向后兼容性，你可以继续选择使用Zookeeper存储偏移量。(例如，你可能有一个监控平台需要从Zookeeper中读取偏移量信息。) 假如你不得不使用Zookeeper进行偏移量(offset)管理，我们推荐你为Kafka集群使用一个专用的Zookeeper集群。假如一个专用的Zookeeper集群仍然有性能瓶颈，你依然可以通过在Zookeeper节点上使用固态硬盘(SSD)来解决问题。<br>Kafka是否支持跨数据中心的可用性<br>Kafka跨数据中心可用性的推荐解决方案是使用MirrorMaker(<a href="https://cwiki.apache.org/confluence/pages/viewpage.action?pageId=27846330" target="_blank" rel="external">https://cwiki.apache.org/confluence/pages/viewpage.action?pageId=27846330</a> ) 。在你的每一个数据中心都搭建一个Kafka集群，在Kafka集群之间使用MirrorMaker来完成近实时的数据复制。<br>使用MirrorMaker的架构模式是为每一个”逻辑”的topic在每一个数据中心创建一个topic：例如，在逻辑上你有一个”clicks”的topic，那么你实际上有”DC1.clicks”和“DC2.clicks”两个topic(DC1和DC2指得是你的数据中心)。DC1向DC1.clicks中写数据，DC2向DC2.clicks中写数据。MirrorMaker将复制所有的DC1 topics到DC2，并且复制所有的DC2 topics到DC1。现在每个DC上的应用程序都能够访问写入到两个DC的事件。这个应用程序能够合并信息和处理相应的冲突。<br>另一种更复杂的模式是在每一个DC都搭建本地和聚合Kafka集群。这个模式已经被Linkedin使用，Linkedin Kafka运维团队已经在这篇Blog(<a href="https://engineering.linkedin.com/kafka/running-kafka-scale" target="_blank" rel="external">https://engineering.linkedin.com/kafka/running-kafka-scale</a> )中有详细的描述(参见“Tiers and Aggregation”)。<br>Kafka支持哪些类型的数据转换(data transformation)<br>数据流过的Kafka的时候，Kafka并不能进行数据转换。为了处理数据转换，我们推荐如下方法：</p>
<pre><code>* 对于简单事件处理，使用<span class="constant">Flume Kafka </span>integration(<span class="symbol">http:</span>/<span class="regexp">/blog.cloudera.com/blog</span><span class="regexp">/2014/</span><span class="number">11</span>/flafka-apache-flume-meets-apache-kafka-<span class="keyword">for</span>-event-processing )，并且写一个简单的<span class="constant">Apache Flume Interceptor。</span>
* 对于复杂(事件)处理，使用<span class="constant">Apache Spark Streaming从Kafka中</span>读数据和处理数据。
</code></pre><p>在这两种情况下，被转换或者处理的数据可被写会到新的Kafka Topic中，或者直接传送到数据的最终消费者(Consumer)那里。<br>对于实时事件处理模式更全面的描述，看看这篇文章(<a href="http://blog.cloudera.com/blog/2015/06/architectural-patterns-for-near-real-time-data-processing-with-apache-hadoop/" target="_blank" rel="external">http://blog.cloudera.com/blog/2015/06/architectural-patterns-for-near-real-time-data-processing-with-apache-hadoop/</a> )。<br>如何通过Kafka发送大消息或者超大负荷量？<br>Cloudera的性能测试表明Kafka达到最大吞吐量的消息大小为10K左右。更大的消息将导致吞吐量下降。然后，在一些情况下，用户需要发送比10K大的多的消息。<br>如果消息负荷大小是每100s处理MB级别，我们推荐探索以下选择：</p>
<pre><code><span class="bullet">* </span>如果可以使用共享存储(HDFS、S3、NAS)，那么将超负载放在共享存储上，仅用Kafka发送负载数据位置的消息。
<span class="bullet">* </span>对于大消息，在写入Kafka之前将消息拆分成更小的部分，使用消息Key确保所有的拆分部分都写入到同一个partition中，以便于它们能被同一个消息着(Consumer)消费的到，在消费的时候将拆分部分重新组装成一个大消息。
</code></pre><p>在通过Kafka发送大消息时，请记住以下几点：<br>压缩配置</p>
<pre><code><span class="keyword">*</span> Kafka生产者(Producers)能够压缩消息。通过配置参数compression.codec确保压缩已经开启。有效的选项为<span class="string">"gzip"</span>和<span class="string">"snappy"</span>。
</code></pre><p>Broker配置</p>
<pre><code>* message.<span class="built_in">max</span>.<span class="keyword">bytes</span> (default: <span class="number">1000000</span>): Broker能够接受的最大消息。增加这个值以便于匹配你的最大消息。
* <span class="built_in">log</span>.<span class="keyword">segment</span>.<span class="keyword">bytes</span> (default: <span class="number">1</span>GB): Kafka数据文件的大小。确保它至少大于一条消息。默认情况下已经够用，一般最大的消息不会超过<span class="number">1</span>G大小。
* replica.fetch.<span class="built_in">max</span>.<span class="keyword">bytes</span> (default: <span class="number">1</span>MB): Broker间复制的最大的数据大小。这个值必须大于message.<span class="built_in">max</span>.<span class="keyword">bytes</span>，否则一个Broker接受到消息但是会复制失败，从而导致潜在的数据丢失。
</code></pre><p>Consumer配置</p>
<pre><code>* <span class="tag">fetch</span><span class="class">.message</span><span class="class">.max</span><span class="class">.bytes</span> (<span class="rule"><span class="attribute">default</span>:<span class="value"> <span class="number">1</span>MB): Consumer所读消息的最大大小。这个值应该大于或者等于Broker配置的message.max.bytes的值。</span></span>
</code></pre><p>其他方面的考虑：</p>
<pre><code>* <span class="tag">Broker</span>需要针对复制为每一个<span class="tag">partition</span>分配一个<span class="tag">replica</span><span class="class">.fetch</span><span class="class">.max</span><span class="class">.bytes</span>大小的缓存区。需要计算确认( <span class="tag">partition</span>的数量 * 最大消息的大小 )不会超过可用的内存，否则就会引发<span class="tag">OOMs</span>（内存溢出异常）。
* <span class="tag">Consumers</span>有同样的问题，因子参数为 <span class="tag">fetch</span><span class="class">.message</span><span class="class">.max</span><span class="class">.bytes</span> ：确认每一个<span class="tag">partition</span>的消费者针对最大的消息有足够可用的内存。
* 大消息可能引发更长时间的垃圾回收停顿(<span class="tag">garbage</span> <span class="tag">collection</span> <span class="tag">pauses</span>)(<span class="tag">brokers</span>需要申请更大块的内存)。注意观察<span class="tag">GC</span>日志和服务器日志。假如发现长时间的<span class="tag">GC</span>停顿导致<span class="tag">Kafka</span>丢失了<span class="tag">Zookeeper</span> <span class="tag">session</span>，你可能需要为<span class="tag">zookeeper</span><span class="class">.session</span><span class="class">.timeout</span><span class="class">.ms</span>配置更长的<span class="tag">timeout</span>值。
</code></pre><p>Kafka是否支持MQTT或JMS协议<br>目前，Kafka针对上述协议不提供直接支持。但是，用户可以自己编写Adaptors从MQTT或者JMS中读取数据，然后写入到Kafka中。</p>
<p>更多关于在CDH中使用Kafka的信息，下载Deployment Guide(<a href="http://www.cloudera.com/content/cloudera/en/resources/library/datasheet/kafka-reference-architecture.html" target="_blank" rel="external">http://www.cloudera.com/content/cloudera/en/resources/library/datasheet/kafka-reference-architecture.html</a> ) 或者 观看webinar “Bringing Real-Time Data to Hadoop”(<a href="http://www.cloudera.com/content/cloudera/en/resources/library/recordedwebinar/kafka-webinar-recording.html" target="_blank" rel="external">http://www.cloudera.com/content/cloudera/en/resources/library/recordedwebinar/kafka-webinar-recording.html</a> )。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://navigating.github.io/2015/读《Deploying-Apache-Kafka-A-Practical-FAQ》/" data-id="ciq5hr00z001w80lm7w3vpvnt" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/CDH/">CDH</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Kafka/">Kafka</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-2015/大数据动态之201506" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2015/大数据动态之201506/" class="article-date">
  <time datetime="2015-06-09T13:52:23.000Z" itemprop="datePublished">2015-06-09</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/技术/">技术</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2015/大数据动态之201506/">大数据动态之201506</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>Pinot：LinkedIn的实时数据分析系统<br><a href="http://www.infoq.com/cn/news/2014/10/linkdln" target="_blank" rel="external">http://www.infoq.com/cn/news/2014/10/linkdln</a><br><a href="https://engineering.linkedin.com/analytics/real-time-analytics-massive-scale-pinot" target="_blank" rel="external">https://engineering.linkedin.com/analytics/real-time-analytics-massive-scale-pinot</a></p>
<p>Twitter Heron：Twitter发布新的大数据实时分析系统Heron<br><a href="http://geek.csdn.net/news/detail/33750" target="_blank" rel="external">http://geek.csdn.net/news/detail/33750</a><br><a href="http://www.longda.us/?p=529" target="_blank" rel="external">http://www.longda.us/?p=529</a> </p>
<p>Cloudera<br>HBase对MOBs( Moderate Objects, 主要是大小100K到10M的对象存储 )的支持<br><a href="http://blog.cloudera.com/blog/2015/06/inside-apache-hbases-new-support-for-mobs/" target="_blank" rel="external">http://blog.cloudera.com/blog/2015/06/inside-apache-hbases-new-support-for-mobs/</a><br>准实时计算架构模式<br><a href="http://blog.cloudera.com/blog/2015/06/architectural-patterns-for-near-real-time-data-processing-with-apache-hadoop/" target="_blank" rel="external">http://blog.cloudera.com/blog/2015/06/architectural-patterns-for-near-real-time-data-processing-with-apache-hadoop/</a><br>(翻译：<a href="http://zhuanlan.zhihu.com/donglaoshi/20082628" target="_blank" rel="external">http://zhuanlan.zhihu.com/donglaoshi/20082628</a> )<br>CDH 5.4 新功能：敏感数据处理(Sensitive Data Redaction)<br><a href="http://blog.cloudera.com/blog/2015/06/new-in-cdh-5-4-sensitive-data-redaction/" target="_blank" rel="external">http://blog.cloudera.com/blog/2015/06/new-in-cdh-5-4-sensitive-data-redaction/</a> </p>
<p>Hortonworks<br>YARN的CapacityScheduler对Resource-preemption的支持<br><a href="http://hortonworks.com/blog/better-slas-via-resource-preemption-in-yarns-capacityscheduler/" target="_blank" rel="external">http://hortonworks.com/blog/better-slas-via-resource-preemption-in-yarns-capacityscheduler/</a><br>Hadoop集群对Multihoming的支持<br><a href="http://hortonworks.com/blog/multihoming-on-hadoop-yarn-clusters/" target="_blank" rel="external">http://hortonworks.com/blog/multihoming-on-hadoop-yarn-clusters/</a><br>HDP 2.3企业级HDFS数据加密<br><a href="http://hortonworks.com/blog/new-in-hdp-2-3-enterprise-grade-hdfs-data-at-rest-encryption/" target="_blank" rel="external">http://hortonworks.com/blog/new-in-hdp-2-3-enterprise-grade-hdfs-data-at-rest-encryption/</a><br>Apache Slider 0.80.0版本发布<br><a href="http://hortonworks.com/blog/announcing-apache-slider-0-80-0/" target="_blank" rel="external">http://hortonworks.com/blog/announcing-apache-slider-0-80-0/</a><br>Apache Spark 1.3.1 on HDP 2.2<br><a href="http://hortonworks.com/blog/apache-spark-on-hdp-learn-try-and-do/" target="_blank" rel="external">http://hortonworks.com/blog/apache-spark-on-hdp-learn-try-and-do/</a><br><a href="http://hortonworks.com/hadoop-tutorial/using-apache-spark-technical-preview-with-hdp-2-2/" target="_blank" rel="external">http://hortonworks.com/hadoop-tutorial/using-apache-spark-technical-preview-with-hdp-2-2/</a><br>Ambari 2.0.1 和 HDP 2.2.6 发布<br><a href="http://docs.hortonworks.com/HDPDocuments/HDP2/HDP-2.2.6/bk_HDP_RelNotes/content/ch_relnotes_v226.html" target="_blank" rel="external">http://docs.hortonworks.com/HDPDocuments/HDP2/HDP-2.2.6/bk_HDP_RelNotes/content/ch_relnotes_v226.html</a><br><a href="http://docs.hortonworks.com/HDPDocuments/Ambari-2.0.1.0/bk_releasenotes_ambari_2.0.1.0/content/ch_relnotes-ambari-2.0.1.0.html" target="_blank" rel="external">http://docs.hortonworks.com/HDPDocuments/Ambari-2.0.1.0/bk_releasenotes_ambari_2.0.1.0/content/ch_relnotes-ambari-2.0.1.0.html</a></p>
<p>其他：<br>Graphite的百万Metrics实践之路<br><a href="http://calvin1978.blogcn.com/articles/graphite.html" target="_blank" rel="external">http://calvin1978.blogcn.com/articles/graphite.html</a><br>HBaseCon 2015 大会幻灯片 &amp; 视频<br><a href="http://hbasecon.com/archive.html" target="_blank" rel="external">http://hbasecon.com/archive.html</a><br>HBase在腾讯大数据的应用实践<br><a href="http://www.d1net.com/bigdata/news/353500.html" target="_blank" rel="external">http://www.d1net.com/bigdata/news/353500.html</a><br>从Spark到Hadoop的架构实践<br><a href="http://www.csdn.net/article/2015-06-08/2824889" target="_blank" rel="external">http://www.csdn.net/article/2015-06-08/2824889</a><br>56网大数据<br><a href="http://share.csdn.net/slides/10903" target="_blank" rel="external">http://share.csdn.net/slides/10903</a><br>七牛技术总监陈超：记Spark Summit China 2015<br><a href="http://www.csdn.net/article/2015-04-30/2824594-spark-summit-china-2015" target="_blank" rel="external">http://www.csdn.net/article/2015-04-30/2824594-spark-summit-china-2015</a><br>唯品会美研中心郭安琪：2015 Hadoop Summit见闻<br><a href="http://zhuanlan.zhihu.com/donglaoshi/20072576" target="_blank" rel="external">http://zhuanlan.zhihu.com/donglaoshi/20072576</a><br>华为叶琪：论Spark Streaming的数据可靠性和一致性<br><a href="http://www.csdn.net/article/2015-06-12/2824938" target="_blank" rel="external">http://www.csdn.net/article/2015-06-12/2824938</a><br>Hadoop Summit 2015<br><a href="http://2015.hadoopsummit.org/san-jose/agenda/" target="_blank" rel="external">http://2015.hadoopsummit.org/san-jose/agenda/</a><br>Spark Summit 2015<br><a href="https://spark-summit.org/2015/" target="_blank" rel="external">https://spark-summit.org/2015/</a> </p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://navigating.github.io/2015/大数据动态之201506/" data-id="ciq5hr03l003x80lmlhyniipk" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/BigData/">BigData</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/CDH/">CDH</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/HDP/">HDP</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Hadoop/">Hadoop</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Spark/">Spark</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-2015/大数据动态之201505" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2015/大数据动态之201505/" class="article-date">
  <time datetime="2015-05-19T02:17:28.000Z" itemprop="datePublished">2015-05-19</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/技术/">技术</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2015/大数据动态之201505/">大数据动态之201505</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>近期动态：<br>Hadoop 2.7发布。<br>Hortonworks HDP 2.2.4.2发布。<br>Ambari 2.0发布。<br>Cloudera Enterperise 5.4发布。<br>Hive 1.2.0 发布，支持Hive on Spark。</p>
<p>HDP 2.2/HDP 2.2.4/Ambari 2.0/Ambari 2.0.1</p>
<pre><code><span class="bullet">1. </span>HDP支持异构存储Heterogeneous storage，主要是对SSD的支持；
<span class="bullet">2. </span>Hive开始支持 ACID 事务，向企业级应用场景前进了一大步；
<span class="bullet">3. </span>HDP支持Spark 1.2.1；
<span class="bullet">4. </span>HDP支持通过DominantResourceCalculator对CPU的资源隔离与资源调度；
<span class="bullet">5. </span>Ambari 支持Blurprint，通过 REST API 管理和运维有更好的支持；
<span class="bullet">6. </span>Ambari 支持Stacks，通过Stacks方式来定义一系列的集成组件；
<span class="bullet">7. </span>Ambari 2.0支持HDP 2.2平台的Rolling Upgrades；
<span class="bullet">8. </span>Ambari 2.0支持安装、配置Apache Ranger；
<span class="bullet">9. </span>Ambari 2.0开始集成Ambari Alerts；
<span class="bullet">10. </span>Ambari 2.0开始集成Ambari Metrics，替代之前的Ganglia；
<span class="bullet">11. </span>Ambari 2.0开始支持User Views功能，User Views提供给运维人员更好的界面，包括Tez View、Capacity Scheduler View、Hive View、Pig View、Files View；
</code></pre><p>HDP 2.2之后部署的结构与之前有调整，新部署的结构与说明如下：</p>
<p>目录结构<br>从HDP 2.2之后，HDP安装后的目录结构发生了变化，之前安装后的Hadoop在/usr/lib目录下，现在变更到/usr/hdp目录下，结构如下：<br><figure class="highlight groovy"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line"> &#123;code&#125;</span><br><span class="line">├── <span class="regexp">/usr/</span>hdp<span class="regexp">/2.2.0.0-2041/</span>hadoop</span><br><span class="line">│   ├── <span class="regexp">/usr/</span>hdp<span class="regexp">/2.2.0.0-2041/</span>hadoop/bin</span><br><span class="line">│   ├── <span class="regexp">/usr/</span>hdp<span class="regexp">/2.2.0.0-2041/</span>hadoop<span class="regexp">/conf -&gt; /</span>etc<span class="regexp">/hadoop/</span>conf</span><br><span class="line">│   ├── <span class="regexp">/usr/</span>hdp<span class="regexp">/2.2.0.0-2041/</span>hadoop/lib</span><br><span class="line">│   │   ├── <span class="regexp">/usr/</span>hdp<span class="regexp">/2.2.0.0-2041/</span>hadoop<span class="regexp">/lib/</span>native</span><br><span class="line">│   ├── <span class="regexp">/usr/</span>hdp<span class="regexp">/2.2.0.0-2041/</span>hadoop/libexec</span><br><span class="line">│   ├── <span class="regexp">/usr/</span>hdp<span class="regexp">/2.2.0.0-2041/</span>hadoop/man</span><br><span class="line">│   └── <span class="regexp">/usr/</span>hdp<span class="regexp">/2.2.0.0-2041/</span>hadoop/sbin</span><br><span class="line">├── <span class="regexp">/usr/</span>hdp<span class="regexp">/2.2.0.0-2041/</span>hadoop-hdfs</span><br><span class="line">│   ├── <span class="regexp">/usr/</span>hdp<span class="regexp">/2.2.0.0-2041/</span>hadoop-hdfs/bin</span><br><span class="line">│   ├── <span class="regexp">/usr/</span>hdp<span class="regexp">/2.2.0.0-2041/</span>hadoop-hdfs/lib</span><br><span class="line">│   ├── <span class="regexp">/usr/</span>hdp<span class="regexp">/2.2.0.0-2041/</span>hadoop-hdfs/sbin</span><br><span class="line">│   └── <span class="regexp">/usr/</span>hdp<span class="regexp">/2.2.0.0-2041/</span>hadoop-hdfs/webapps</span><br><span class="line">├── <span class="regexp">/usr/</span>hdp<span class="regexp">/2.2.0.0-2041/</span>hbase</span><br><span class="line">│   ├── <span class="regexp">/usr/</span>hdp<span class="regexp">/2.2.0.0-2041/</span>hbase/bin</span><br><span class="line">│   ├── <span class="regexp">/usr/</span>hdp<span class="regexp">/2.2.0.0-2041/</span>hbase<span class="regexp">/conf -&gt; /</span>etc<span class="regexp">/hbase/</span>conf</span><br><span class="line">│   ├── <span class="regexp">/usr/</span>hdp<span class="regexp">/2.2.0.0-2041/</span>hbase/doc</span><br><span class="line">│   ├── <span class="regexp">/usr/</span>hdp<span class="regexp">/2.2.0.0-2041/</span>hbase/include</span><br><span class="line">│   ├── <span class="regexp">/usr/</span>hdp<span class="regexp">/2.2.0.0-2041/</span>hbase/lib</span><br><span class="line">└── <span class="regexp">/usr/</span>hdp<span class="regexp">/2.2.0.0-2041/</span>zookeeper</span><br><span class="line">├── <span class="regexp">/usr/</span>hdp<span class="regexp">/2.2.0.0-2041/</span>zookeeper/bin</span><br><span class="line">├── <span class="regexp">/usr/</span>hdp<span class="regexp">/2.2.0.0-2041/</span>zookeeper<span class="regexp">/conf -&gt; /</span>etc<span class="regexp">/zookeeper/</span>conf</span><br><span class="line">├── <span class="regexp">/usr/</span>hdp<span class="regexp">/2.2.0.0-2041/</span>zookeeper/doc</span><br><span class="line">├── <span class="regexp">/usr/</span>hdp<span class="regexp">/2.2.0.0-2041/</span>zookeeper/lib</span><br><span class="line">├── <span class="regexp">/usr/</span>hdp<span class="regexp">/2.2.0.0-2041/</span>zookeeper/man</span><br><span class="line"> &#123;code&#125;</span><br><span class="line"> &#123;code&#125;</span><br><span class="line"><span class="regexp">/usr/</span>hdp/<span class="number">2.2</span>.3.0-<span class="number">2611</span></span><br><span class="line">├── <span class="regexp">/usr/</span>hdp<span class="regexp">/2.2.3.0-2611/</span>hadoop</span><br><span class="line">│   ├── <span class="regexp">/usr/</span>hdp<span class="regexp">/2.2.3.0-2611/</span>hadoop/bin</span><br><span class="line">│   ├── <span class="regexp">/usr/</span>hdp<span class="regexp">/2.2.3.0-2611/</span>hadoop<span class="regexp">/conf -&gt; /</span>etc<span class="regexp">/hadoop/</span>conf</span><br><span class="line">│   ├── <span class="regexp">/usr/</span>hdp<span class="regexp">/2.2.3.0-2611/</span>hadoop/lib</span><br><span class="line">│   │   ├── <span class="regexp">/usr/</span>hdp<span class="regexp">/2.2.3.0-2611/</span>hadoop<span class="regexp">/lib/</span>native</span><br><span class="line">│   ├── <span class="regexp">/usr/</span>hdp<span class="regexp">/2.2.3.0-2611/</span>hadoop/libexec</span><br><span class="line">│   ├── <span class="regexp">/usr/</span>hdp<span class="regexp">/2.2.3.0-2611/</span>hadoop/man</span><br><span class="line">│   └── <span class="regexp">/usr/</span>hdp<span class="regexp">/2.2.3.0-2611/</span>hadoop/sbin</span><br><span class="line">├── <span class="regexp">/usr/</span>hdp<span class="regexp">/2.2.3.0-2611/</span>hadoop-hdfs</span><br><span class="line">│   ├── <span class="regexp">/usr/</span>hdp<span class="regexp">/2.2.3.0-2611/</span>hadoop-hdfs/bin</span><br><span class="line">│   ├── <span class="regexp">/usr/</span>hdp<span class="regexp">/2.2.3.0-2611/</span>hadoop-hdfs/lib</span><br><span class="line">│   ├── <span class="regexp">/usr/</span>hdp<span class="regexp">/2.2.3.0-2611/</span>hadoop-hdfs/sbin</span><br><span class="line">│   └── <span class="regexp">/usr/</span>hdp<span class="regexp">/2.2.3.0-2611/</span>hadoop-hdfs/webapps</span><br><span class="line">├── <span class="regexp">/usr/</span>hdp<span class="regexp">/2.2.3.0-2611/</span>hbase</span><br><span class="line">│   ├── <span class="regexp">/usr/</span>hdp<span class="regexp">/2.2.3.0-2611/</span>hbase/bin</span><br><span class="line">│   ├── <span class="regexp">/usr/</span>hdp<span class="regexp">/2.2.3.0-2611/</span>hbase<span class="regexp">/conf -&gt; /</span>etc<span class="regexp">/hbase/</span>conf</span><br><span class="line">│   ├── <span class="regexp">/usr/</span>hdp<span class="regexp">/2.2.3.0-2611/</span>hbase/doc</span><br><span class="line">│   ├── <span class="regexp">/usr/</span>hdp<span class="regexp">/2.2.3.0-2611/</span>hbase/include</span><br><span class="line">│   ├── <span class="regexp">/usr/</span>hdp<span class="regexp">/2.2.3.0-2611/</span>hbase/lib</span><br><span class="line">└── <span class="regexp">/usr/</span>hdp<span class="regexp">/2.2.3.0-2611/</span>zookeeper</span><br><span class="line">├── <span class="regexp">/usr/</span>hdp<span class="regexp">/2.2.3.0-2611/</span>zookeeper/bin</span><br><span class="line">├── <span class="regexp">/usr/</span>hdp<span class="regexp">/2.2.3.0-2611/</span>zookeeper<span class="regexp">/conf -&gt; /</span>etc<span class="regexp">/zookeeper/</span>conf</span><br><span class="line">├── <span class="regexp">/usr/</span>hdp<span class="regexp">/2.2.3.0-2611/</span>zookeeper/doc</span><br><span class="line">├── <span class="regexp">/usr/</span>hdp<span class="regexp">/2.2.3.0-2611/</span>zookeeper/lib</span><br><span class="line">├── <span class="regexp">/usr/</span>hdp<span class="regexp">/2.2.3.0-2611/</span>zookeeper/man</span><br><span class="line"> &#123;code&#125;</span><br></pre></td></tr></table></figure></p>
<p>管理活动版本<br>HDP 2.0之后推出了hdp-select服务，通过这个服务可以管理活动版本，默认就会安装hdp-select，可以通过hdp-select命令验证是否安装。<br><figure class="highlight armasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt; hdp-<span class="keyword">select</span><br><span class="line"></span>&gt; hdp-<span class="keyword">select </span>versions</span><br></pre></td></tr></table></figure></p>
<p>同样支持管理命令，例如：</p>
<pre><code>&gt; <span class="tag">hdp-select</span> <span class="tag">set</span> <span class="tag">hadoop-hdfs-datanode</span> 2<span class="class">.2</span><span class="class">.3</span><span class="class">.0-2600</span>
</code></pre><p>安装后的库、工具和脚本<br>库<br>HDP 2.0之前安装后库放在/usr/lib下，现在放在/usr/hdp/current下：</p>
<pre><code><span class="regexp">/usr/</span>hdp<span class="regexp">/current/</span>hadoop-hdfs-namenode/
<span class="regexp">/usr/</span>hdp<span class="regexp">/current/</span>hadoop-yarn-resourcemanager
<span class="regexp">/usr/</span>hdp<span class="regexp">/current/</span>hadoop-mapreduce-client/hadoop-mapreduce-examples.jar
</code></pre><p>Daemon Scripts</p>
<pre><code><span class="regexp">/usr/</span>hdp<span class="regexp">/current/</span>hadoop-hdfs-namenode<span class="regexp">/../</span>hadoop<span class="regexp">/sbin/</span>hadoop-deamon.sh
<span class="regexp">/usr/</span>hdp<span class="regexp">/current/</span>hadoop-yarn-resourcemanager<span class="regexp">/sbin/y</span>arn-daemon.sh
<span class="regexp">/usr/</span>hdp<span class="regexp">/current/</span>hadoop-yarn-nodemanager<span class="regexp">/sbin/y</span>arn-daemon.sh
</code></pre><p>Configuration files</p>
<pre><code><span class="regexp">/etc/</span>hadoop<span class="regexp">/conf</span>
</code></pre><p>Bin Scripts</p>
<pre><code><span class="regexp">/usr/</span>bin<span class="regexp">/hadoop -&gt; /u</span>sr<span class="regexp">/hdp/</span>current<span class="regexp">/hadoop-client/</span>bin<span class="regexp">/hadoop</span>
</code></pre>
      
    </div>
    <footer class="article-footer">
      <a data-url="http://navigating.github.io/2015/大数据动态之201505/" data-id="ciq5hr03l004580lm2x951ref" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Ambari/">Ambari</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/BigData/">BigData</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/CDH/">CDH</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/HDP/">HDP</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Hadoop/">Hadoop</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-2015/大数据动态之201502" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2015/大数据动态之201502/" class="article-date">
  <time datetime="2015-03-24T14:10:07.000Z" itemprop="datePublished">2015-03-24</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/技术/">技术</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2015/大数据动态之201502/">大数据动态之201502</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>本月Hadoop技术动态：<br>1.经过6年的孵化，Hive 1.0 发布了。<br>2.经过7年的孵化，HBase 1.0 发布了。<br>3.Cloudera 开始提供 Hive-on-Spark Beta版的下载。</p>
<p>HBase 1.0 需要特别关注的特性：<br>1.API的重新组织和变更；<br>2.读的高可用；<br>3.在线配置变更；</p>
<p>HDP 2.2 发布有一段时间：<br><a href="http://hortonworks.com/blog/announcing-hive-1-0-stable-moment-time/" target="_blank" rel="external">http://hortonworks.com/blog/announcing-hive-1-0-stable-moment-time/</a><br><a href="http://hortonworks.com/blog/start-new-era-apache-hbase-1-0/" target="_blank" rel="external">http://hortonworks.com/blog/start-new-era-apache-hbase-1-0/</a><br><a href="http://blog.cloudera.com/blog/2015/02/apache-hbase-1-0-is-released/" target="_blank" rel="external">http://blog.cloudera.com/blog/2015/02/apache-hbase-1-0-is-released/</a><br><a href="http://blog.cloudera.com/blog/2015/02/download-the-hive-on-spark-beta/" target="_blank" rel="external">http://blog.cloudera.com/blog/2015/02/download-the-hive-on-spark-beta/</a><br><a href="https://issues.apache.org/jira/secure/attachment/12652517/Hive-on-Spark.pdf" target="_blank" rel="external">https://issues.apache.org/jira/secure/attachment/12652517/Hive-on-Spark.pdf</a></p>
<p>Cluster Manager Framework:<br>1.YARN<br>2.Apache Helix</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://navigating.github.io/2015/大数据动态之201502/" data-id="ciq5hr040004d80lmnoaeyj5r" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/BigData/">BigData</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/CDH/">CDH</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/HDP/">HDP</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Hadoop/">Hadoop</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Spark/">Spark</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-2015/Hadoop发行版(2015第一季)" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2015/Hadoop发行版(2015第一季)/" class="article-date">
  <time datetime="2015-01-09T14:40:02.000Z" itemprop="datePublished">2015-01-09</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/技术/">技术</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2015/Hadoop发行版(2015第一季)/">Hadoop发行版(2015第一季)</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>自从Hadoop的出现，引领大数据的浪潮越来越热。大数据存储的主要技术路线有几种：<br>1.Hadoop<br>2.Cassandra<br>3.MongoDB<br>Hadoop是Apache的开源项目，同时有很多商业公司对Hadoop进行版本发行和商业支持,参见：<a href="http://wiki.apache.org/hadoop/Distributions%20and%20Commercial%20Support" target="_blank" rel="external">http://wiki.apache.org/hadoop/Distributions%20and%20Commercial%20Support</a><br>其中在最有名为人所知的三家：<br>1.Cloudera<br><img src="https://raw.githubusercontent.com/stevenxu/tuku/master/navigating.github.io/2015/Hadoop_2015_1.JPG" alt="这是一张图片"></p>
<p>2.Hortonwork<br><img src="https://raw.githubusercontent.com/stevenxu/tuku/master/navigating.github.io/2015/Hadoop_2015_2.JPG" alt="这是一张图片"></p>
<p>3.MapR<br><img src="https://raw.githubusercontent.com/stevenxu/tuku/master/navigating.github.io/2015/Hadoop_2015_3.JPG" alt="这是一张图片"></p>
<p>这三个厂商之中，MapR最为封闭；Hortonworks最为开放，产品线全开源，在线文档比较丰富。国内使用Cloudera CDH和Hortonworks的应该是最多的。<br>准实时计算框架/即席查询<br>1.CDH的框架有：Impala + Spark；<br>2.HDP的框架有：Tez + Spark；<br>3.MapR的框架有：Drill + Tez + Spark。<br>关于Spark：<br>2014年大数据最热门的技术路线就是算是Spark了，而且得力于Spark不遗余力的推广和快速成长。Cloudera是最早支持Spark，也是最激进的。下图即是Spark在Cloudera产品线中的定位：<br><img src="https://raw.githubusercontent.com/stevenxu/tuku/master/navigating.github.io/2015/Hadoop_2015_4.JPG" alt="这是一张图片"></p>
<p>实际上快速计算框架的发展才刚刚开始，社区中已经有如下几种：<br>1.Spark/Shark<br>2.Hortonworks Tez/Stinger<br>3.Cloudera Impala<br>4.Apache Drill<br>5.Apache Flink<br>6.Apache Nifi<br>7.Facebook Presto</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://navigating.github.io/2015/Hadoop发行版(2015第一季)/" data-id="ciq5hr05r005r80lm6uzqbmni" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/BigData/">BigData</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/CDH/">CDH</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/HDP/">HDP</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Hadoop/">Hadoop</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/SQL-on-Hadoop/">SQL on Hadoop</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-2013/2013年年终总结" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2013/2013年年终总结/" class="article-date">
  <time datetime="2013-12-31T14:23:51.000Z" itemprop="datePublished">2013-12-31</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/生活/">生活</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2013/2013年年终总结/">2013年年终总结</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>又到了一年总结的时候，今年倒是有点晚了。感觉今年的时间过得飞快，放佛没感觉到时光的流逝，一直没想总结这事，这两天才开始琢磨。</p>
<p>年初给自己的两个目标，一个是多读书，一个是多了解架构知识。</p>
<p>多读书，这点上今年倒是读了不少杂书，包括：</p>
<p>重读了金庸的几本武侠小说，几本书基本上以前也读过，再次阅读，一是回想当初读的那个情景、那个思绪映像，另外再读的时候完全换了视角了，以一种置身世外的解读的心态来看，常常揣摩主人公在场景下的心态与抉择；</p>
<p>重读了四大名著除红楼之外的三部，特别是《西游记》，是第一次去读，以前只翻过几页，都没看过，一直觉得应该当着故事会来读，真读起来，才发现书中有很多有意思的地方，比方说书的第一主角真应该算是孙悟空吧，还有唐僧、孙悟空、猪八戒、沙和尚的关系和观念，都很有意思，还有孙悟空的诚心打动了猪八戒，确是一本可以细读的书。</p>
<p>读了《明朝那些事儿》《浪潮之巅》《乔布斯传》《基业长青》《创新者的窘境》等，读的都很粗线条，大部分都没有细读和做笔记。</p>
<p>另外有Kindle读了一些书，Kindle读书确实很方便，对我来说唯一的缺陷就是翻页查找太不方便了，对于我这种记忆里不好的人来说比较累。</p>
<p>了解架构，关于架构的书读得少，了解一下架构的范围和大致概念，比较收获的是开始去理解EA和TOGAF，可能他们对工作不会起到很大的直接作用，但发现对工作有非常大的辅助作用。架构方面实际脚踏实地的做事上做的很欠缺。</p>
<p>工作上今年做的事，大部分都能反映到WIKI上去，这里就不说了，想对自己说的就是：太被动，主动做的事儿太少。</p>
<p>言而总之，总而言之，这一年在读书和工作上对自己的评价是，看的多，做的少，创新的东西更少。身体健康方面是：体重增加了，锻炼减少了。</p>
<p>今年给自己打分，也就60分吧。</p>
<p>说了过去，就得展望一下未来：</p>
<p>读书这块，当然要继续读，下一步可能会更聚焦，有目的性的去读一些书。少随意性的阅读，多一些专注的阅读。</p>
<p>同时会把博客捡起来，坚持写博客，记录自己的想法。</p>
<p>工作这块，现在还没有想好，脑子里就是一些可能大家都知道的关键词，希望自己能做到：多创新，多行动，就是坚持做一些没做过的事；要主动，要规划，要坚持；要能落地的事，多总结积累。</p>
<p>用这篇小文，记录那渐行渐远的2013，迎接蓬勃而来的2014。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://navigating.github.io/2013/2013年年终总结/" data-id="ciq5hr06m006b80lmr2oalt24" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-2013/响应式网页设计-Responsive-Web-Design" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2013/响应式网页设计-Responsive-Web-Design/" class="article-date">
  <time datetime="2013-08-11T15:04:46.000Z" itemprop="datePublished">2013-08-11</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/技术/">技术</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2013/响应式网页设计-Responsive-Web-Design/">响应式网页设计(Responsive Web Design)</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>响应式网页设计，也叫：自适应网页设计。2010年，由Ethan Marcotte提出这个名词(Responsive Web Design) ，指可以自动识别屏幕宽度、并做出相应调整的网页设计。其目的就是希望搭建一个网站能够满足兼容多种终端的需求，不再是为每一种终端定制开发一个版本。应该是，这个思想主要是应对当前Web应用在各种移动终端上展示的挑战的。</p>
<p>主要的应对策略：</p>
<p>允许网页宽度自动调整；<br>不允许绝对宽度；<br>使用相对大小的字体；<br>流动布局；<br>选择加载CSS；<br>CSS的@media规则；<br>图片的自适应。<br>参考：<br><a href="http://alistapart.com/article/responsive-web-design" target="_blank" rel="external">http://alistapart.com/article/responsive-web-design</a><br><a href="http://www.ruanyifeng.com/blog/2012/05/responsive_web_design.html" target="_blank" rel="external">http://www.ruanyifeng.com/blog/2012/05/responsive_web_design.html</a><br><a href="http://www.qianduan.net/responsive-web-design.html" target="_blank" rel="external">http://www.qianduan.net/responsive-web-design.html</a><br><a href="http://www.qianduan.net/media-type-and-media-query.html" target="_blank" rel="external">http://www.qianduan.net/media-type-and-media-query.html</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://navigating.github.io/2013/响应式网页设计-Responsive-Web-Design/" data-id="ciq5hr06m006980lmew9hvgyo" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-2012/HBTC-2012-见闻" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2012/HBTC-2012-见闻/" class="article-date">
  <time datetime="2012-12-25T15:05:29.000Z" itemprop="datePublished">2012-12-25</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/技术/">技术</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2012/HBTC-2012-见闻/">HBTC 2012 见闻</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>今年Hadoop大会，加上了BigData，全称“Hadoop&amp;Bigdata Technology Conference(Hadoop与大数据技术大会)”，随着“云计算”“Hadoop”“大数据”的热点，今年的大会事先很是期待，之后从中收获很多，坚信了我们在工作中的一些判断。从我的视角，今年HBTC主要覆盖如下的内容：<br>Hadoop与BigData主要的产品进展：<br>1.Hortonworks Hadoop/HBase<br>2.Intel Hadoop/Free Edition<br>3.Huawei Contributing Hadoop/HBase<br>4.Facebook Hadoop/HBase<br>5.Vmware Hadoop Virtualization<br>6.Oracle NoSQL<br>7.Taobao Tair<br>8.eBay Hadoop/HBase<br>意外的是Huawei对Hadoop社区的贡献度很大；Hortonworks只是一般性的宣讲，并没有重大的消息或者特性宣布。<br>Hadoop生态圈中本次被关注的技术：<br>1.Hadoop Security(Etu)<br>2.HIVE<br>3.HDFS Namenode<br>4.HBase<br>5.Pig<br>今年重点被关注的是HBase、Hive。<br>应用方面:<br>1.阿里Hadoop集群<br>a.3200台服务器，30K核，内存10TB，存储36K磁盘60PB。<br>b.支撑支付宝、CBU、聚划算、一淘、天猫、淘宝,1K+客户端/100+部门<br>c.Hadoop组件：Hive、Streaming MR、Mahout、Pig、HBase<br>d.客户端，用户/用户组权限管理/资源管理，申请/审批；云梯医生/JobTracker心跳频率/NameNode RPC性能指标；<br>e.数据采集：TimeTunnel分布式日志收集，DataX数据库同步，DBSync大表增量同步；<br>2.HIVE在腾讯分布式数据仓库<br>a.腾讯分布式数据仓库，简称：TDW；<br>b.基于Hadoop/Hive/PostgreSQL构建；<br>c.特性列表：存储和计算容灾/存储和计算线性扩展，SQL语言/SQL函数，过程语言，多维分析，MR，多种存储结构，SQL/MED，开发工具，任务调度系统，系统DB<br>d.TDW在Hive基础上进行的功能增强：    基于角色的权限管理；    兼容Oracle的分区功能；    窗口函数；多维分析；公用表表达式；DML(Update/Delete)；入库数据校验；命令行工具；DB存储引擎；SQL语法细节增强；Eclipse IDE开发环境/流程开发工具；自定义的存储格式；Hash Join；按行split；Order by limit优化；<br>3.阿里数据交换平台<br>a.平台能力：存储与计算的调度、元数据管理、数据建模、IDE；市场应用：应用市场、数据市场；数据管理：预警、质量监控、ODS、生命周期管理；数据开发：安全、审计、计量、监控；<br>b.分析可视化；数据可视化；<br>c.ODPS：开放；服务化；离线数据分析服务；<br>d.ODS：开放与共享；源头数据质量监控；元数据管理；<br>4.百度大数据平台<br>a.基础能力包括：分布式存储(KV/Table)；计算(批量计算/小批量计算/流式计算)；调度(底层资源管理/上层通用调度)；数据仓库体系(格式化/传输/数据仓库/报表&amp;多维分析引擎/Ad Hoc查询引擎/BI)<br>b.OLAP查询以MySQL作为前端。<br>5.IBM在Hadoop/大数据方面的架构与实践<br>6.Startup企业MemSQL提供实时查询方案<br>7.Yahoo Hadoop应用、运维，还有其基于Hadoop的Data workflow<br>学校<br>有不少做研究的老师过来传道，其中有不少精华的东西，特别是哈尔滨工业大学的李建中和俄亥俄州立大学的张晓东教授给我留下了深刻的印象。<br>缺失<br>1.实时查询/流计算内容很少；也许会是明年的热点吧；<br>2.Cloudera/MapR都厂商没有来，无法面对面了解其一些技术特点和产品特性；<br>个人总结<br>1.技术上，今年Hadoop生态圈的热点是HBase、HDFS NameNode、HDFS Security;<br>2.应用与平台上，阿里/淘宝发展最快，其次是腾讯/百度。这三个公司的Hadoop集群为公司内部众多部门提供hadoop平台服务，特别是阿里比较突出，其中共有的特性：<br>    a.工作的内容都是围绕为内部提供Hadoop集群/大数据服务平台；<br>    b.技术路线都是以Hadoop、HBase、Hive/Pig、关系型数据库为主；<br>    c.用户查询语言以兼容SQL语言为主；<br>    d.计算查询主要是以批量计算、实时查询为主；<br>    e.可视化方面的工作基本雷同：分析可视化、数据可视化、数据流程编排可视化；<br>    f.平台在安全、隔离、调度、元数据管理、监控、预警告警、服务化、数据集成与共享等方面提供功能。<br>3.实时查询/流计算，虽然今年没有覆盖，但是各个厂商都有提到自己已经在这两个方面着手或者取得了一些进展。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://navigating.github.io/2012/HBTC-2012-见闻/" data-id="ciq5hr071006e80lm173gtx8n" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/BigData/">BigData</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/HBase/">HBase</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/HDP/">HDP</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Hadoop/">Hadoop</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Hive/">Hive</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-2011/佛教禅宗-六祖慧能" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2011/佛教禅宗-六祖慧能/" class="article-date">
  <time datetime="2011-11-14T16:20:56.000Z" itemprop="datePublished">2011-11-15</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/读书/">读书</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2011/佛教禅宗-六祖慧能/">佛教禅宗 六祖慧能</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>佛教禅宗 六祖慧能</p>
<p>慧能 （公元 638 年－ 713 年），俗姓卢氏，唐代岭南新州（今广东新兴县）人，父亲名卢行瑫，早逝，母李氏，其籍贯为范阳（今北京大兴） , 因其父贬于岭南才南迁。慧能生于贞观，圆寂于开元初年，经历了唐朝太宗、高宗、中宗、睿宗、武周 ( 武则天 ) 、中宗、恭宗、睿宗、玄宗八位国君阶段。自幼以卖柴为生，因一次卖柴回家的路上听到有人读诵《金刚经》，便萌生学习佛法之念；后去湖北的黄梅山拜谒佛教禅宗五祖弘忍大师为师，由此开始了学佛生涯。其时弘忍年事已高，急于传付衣法，遂命弟子作偈以呈，当时大弟子神秀也是大家公认的禅宗衣钵的继承人，为了避嫌半夜起来，在院墙上写了一首偈子曰：</p>
<pre><code>“身是菩提树，心如明镜台，

  时时勤拂拭，莫使惹尘埃。”
</code></pre><p>弘忍认为神秀还没有完全顿悟。</p>
<p>惠能当时做砍柴、碾米，听说这件事之后慧能就叫人带他去看偈子，听后亦诵一偈，因为自己是不会识字不会写字，并请当时在场的江州别驾张日用代劳题于壁上：</p>
<pre><code>“菩提本无树，明镜亦非台，

  本来无一物，何处惹尘埃。”
</code></pre><p>弘忍见后，当众用鞋把慧能的偈搽掉，并说“亦未见性”。次日，弘忍大师来到碾米房，以杖击碓 ( 捣米器具 ) 而去；惠能立刻理解了五祖的意思，于是他在当晚上三更的时候去了弘忍的禅房。弘忍为其宣讲《金刚经》，并传衣钵，定为传人。然后为了防止有人伤害惠能，让惠能连夜逃走。于是惠能连夜远走南方，隐居 10 年之后才出来讲经传法。</p>
<p>676 年，唐高宗仪凤元年，正月初八到广州法性寺，印宗法师在该寺内讲《涅槃经》之际，正好遇到风吹幡动，一僧曰：风动；一僧曰：幡动；争论不休，惠能进曰：</p>
<pre><code>“不是风动，亦非幡动，仁者心动”。
</code></pre><p>印宗闻之折服，遂拜为师，并为之剃度。</p>
<p>仪凤二年 (677 年 ) ，韶州刺史韦璩仰其道风，率同僚入山请惠能入城曹溪宝林寺（今广东韶关南华寺），于大梵寺讲堂为众说法，兼授无相戒。僧尼道俗集者千余人，门人法海编录其法语。慧能在此弘扬禅宗传法长达 37 年，奠定了禅宗“南宗”的基础。</p>
<p>神龙元年 (705 年 ) ，武则天和唐中宗即遣内侍薛简往曹溪召其入京。惠能以久处山林，年迈风疾，辞却不去。薛简恳请说法，将记录带回报命。中宗因赠摩纳袈裟一领及绢五百匹以为供养。并命改称宝林寺为中兴寺，由韶州刺史重修，又给予法泉寺额，并以惠能新州故宅为国恩寺。</p>
<p>延和元年 (712 年 ) 惠能回至新州，命门人建报恩塔。唐玄宗先天二年（ 713 年），圆寂于新州国恩寺，世寿七十六，唐宪宗谥号大鉴禅师。惠能圆寂后，其真身不坏，被运回韶州（今广东韶关）曹溪，其门人裹综涂漆，保持其生前形像。其肉身像至今还保存在南华寺，供奉在灵照塔中。</p>
<p>南北宗之争</p>
<p>惠能，主张“顿悟”，影响华南诸宗派，人称“南宗”，在曹溪宝林寺（今广东韶关南华寺）弘扬禅宗传法长达 37 年之久。六祖惠能的同门师兄神秀，主张“渐悟”，在华北势力颇盛，号称“北宗”。</p>
<p>唐玄宗开元二年（ 730 年），在河南滑台（今滑县）的无遮大会上，惠能弟子荷泽神会辩倒了神秀门人崇远、普寂，使得“南宗”成为中国禅宗正统。</p>
<p>惠能为禅宗的发展奠定了理论基础，对于后来各派禅师建立门庭，影响极大。在他死后，他的弟子传承禅法，形成惠能禅法的南北二宗。惠能禅法的北宗即是荷泽神会门下，称荷泽宗。惠能禅法的南宗则以南岳怀让门下的洪州宗，与青原行思、石头希迁一系的石头宗为代表。</p>
<p>惠能禅法在北宗荷泽一派的推动下，取代了原先北宗神秀一系的地位，成为禅门正宗，但荷泽一派因后继无人，在唐末衰亡。对后世影响较大的反而是南宗门下。南宗门下，后来形成河北临济宗、江西曹洞宗、湖南沩仰宗、广东云门宗、江苏法眼宗五宗，即“一花开五叶”。</p>
<p>后来，法眼宗远传于泰国、朝鲜；云门宗、临济宗更远播欧美。在中国、日本，则是临济宗、曹洞宗两宗最盛。</p>
<p>经典</p>
<p>惠能圆寂后，其弟子们 将其经历和言论录整理成《六祖坛经》，简称《坛经》，是禅宗的经典。</p>
<p>著名弟子</p>
<p>弟子众多，最著名的有：荷泽神会、青原行思、南岳怀让、石头希迁、净藏。</p>
<p>禅宗</p>
<p>禅宗，又称宗门，汉传佛教宗派之一，始于菩提达摩，盛于六祖惠能，中晚唐之后成为汉传佛教的主流，也是汉传佛教最主要的象征之一。汉传佛教宗派多来自于印度，但唯独天台宗、华严宗与禅宗，是由中国独立发展出的三个本土佛教宗派。其中又以禅宗最具独特的性格。禅宗祖师会运用各种教学方法，以求达到这种境界，这又称开悟。其核心思想为：</p>
<pre><code>“不立文字，教外别传；

  直指人心，见性成佛”。
</code></pre><p>轶事</p>
<p>《西游记》孙悟空学艺的故事可能取材于六祖慧能的学佛经历。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://navigating.github.io/2011/佛教禅宗-六祖慧能/" data-id="ciq5hr07x006x80lm8gpm92r8" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
  
    <nav id="page-nav">
      <a class="extend prev" rel="prev" href="/page/3/">&laquo; Prev</a><a class="page-number" href="/">1</a><a class="page-number" href="/page/2/">2</a><a class="page-number" href="/page/3/">3</a><span class="page-number current">4</span><a class="page-number" href="/page/5/">5</a><a class="page-number" href="/page/6/">6</a><span class="space">&hellip;</span><a class="page-number" href="/page/13/">13</a><a class="extend next" rel="next" href="/page/5/">Next &raquo;</a>
    </nav>
  
</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/技术/">技术</a><span class="category-list-count">87</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/生活/">生活</a><span class="category-list-count">12</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/读书/">读书</a><span class="category-list-count">25</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/Agile/" style="font-size: 10px;">Agile</a> <a href="/tags/Ambari/" style="font-size: 11.25px;">Ambari</a> <a href="/tags/Android/" style="font-size: 13.75px;">Android</a> <a href="/tags/Annotation/" style="font-size: 10px;">Annotation</a> <a href="/tags/Apple/" style="font-size: 10px;">Apple</a> <a href="/tags/Architecture/" style="font-size: 13.75px;">Architecture</a> <a href="/tags/BigData/" style="font-size: 20px;">BigData</a> <a href="/tags/CDH/" style="font-size: 15px;">CDH</a> <a href="/tags/Cassandra/" style="font-size: 10px;">Cassandra</a> <a href="/tags/Cloudera/" style="font-size: 10px;">Cloudera</a> <a href="/tags/Eclipse/" style="font-size: 10px;">Eclipse</a> <a href="/tags/Flume/" style="font-size: 11.25px;">Flume</a> <a href="/tags/G1/" style="font-size: 10px;">G1</a> <a href="/tags/Google/" style="font-size: 11.25px;">Google</a> <a href="/tags/HBase/" style="font-size: 16.25px;">HBase</a> <a href="/tags/HDP/" style="font-size: 16.25px;">HDP</a> <a href="/tags/HQueue/" style="font-size: 10px;">HQueue</a> <a href="/tags/Hadoop/" style="font-size: 20px;">Hadoop</a> <a href="/tags/Hive/" style="font-size: 11.25px;">Hive</a> <a href="/tags/Impala/" style="font-size: 10px;">Impala</a> <a href="/tags/JAVA/" style="font-size: 10px;">JAVA</a> <a href="/tags/JNI/" style="font-size: 10px;">JNI</a> <a href="/tags/JUnit/" style="font-size: 11.25px;">JUnit</a> <a href="/tags/JVM/" style="font-size: 11.25px;">JVM</a> <a href="/tags/Java/" style="font-size: 17.5px;">Java</a> <a href="/tags/Kafka/" style="font-size: 12.5px;">Kafka</a> <a href="/tags/Linux/" style="font-size: 10px;">Linux</a> <a href="/tags/MapR/" style="font-size: 10px;">MapR</a> <a href="/tags/MongoDB/" style="font-size: 15px;">MongoDB</a> <a href="/tags/NIO/" style="font-size: 12.5px;">NIO</a> <a href="/tags/Netty/" style="font-size: 11.25px;">Netty</a> <a href="/tags/NoSQL/" style="font-size: 10px;">NoSQL</a> <a href="/tags/Oozie/" style="font-size: 10px;">Oozie</a> <a href="/tags/Performance/" style="font-size: 10px;">Performance</a> <a href="/tags/Redis/" style="font-size: 10px;">Redis</a> <a href="/tags/Review/" style="font-size: 10px;">Review</a> <a href="/tags/Ruby/" style="font-size: 10px;">Ruby</a> <a href="/tags/SOA/" style="font-size: 10px;">SOA</a> <a href="/tags/SQL-on-Hadoop/" style="font-size: 11.25px;">SQL on Hadoop</a> <a href="/tags/Spark/" style="font-size: 18.75px;">Spark</a> <a href="/tags/Storm/" style="font-size: 10px;">Storm</a> <a href="/tags/Tez/" style="font-size: 10px;">Tez</a> <a href="/tags/Ubuntu/" style="font-size: 10px;">Ubuntu</a> <a href="/tags/XP/" style="font-size: 11.25px;">XP</a> <a href="/tags/blog/" style="font-size: 10px;">blog</a> <a href="/tags/github/" style="font-size: 10px;">github</a> <a href="/tags/hexo/" style="font-size: 11.25px;">hexo</a> <a href="/tags/iOS/" style="font-size: 10px;">iOS</a> <a href="/tags/iStream/" style="font-size: 10px;">iStream</a>
    </div>
  </div>

  
    <div class="widget-wrap">
  <input type="text" class="st-default-search-input">
</div>
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recents</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2016/JAVA虚拟机：G1/">JAVA虚拟机：G1</a>
          </li>
        
          <li>
            <a href="/2016/简报：大数据产品分析 - 2016Q2/">简报：大数据产品分析 - 2016Q2</a>
          </li>
        
          <li>
            <a href="/2016/简报：BI&数据挖掘&机器学习 - 2016Q2/">简报：BI&amp;数据挖掘&amp;机器学习 - 2016Q2</a>
          </li>
        
          <li>
            <a href="/2016/开源流计算框架 - 201605/">开源流计算框架 - 201605</a>
          </li>
        
          <li>
            <a href="/2016/大数据之电信运营商案例/">大数据之电信运营商案例</a>
          </li>
        
          <li>
            <a href="/2016/敏捷之如何切分用户故事/">敏捷之如何切分用户故事</a>
          </li>
        
          <li>
            <a href="/2016/简报：人工智能 - 2016Q2/">简报：人工智能 - 2016Q2</a>
          </li>
        
          <li>
            <a href="/2016/学习《Thoughtworks技术雷达201604》/">学习《Thoughtworks技术雷达201604》</a>
          </li>
        
          <li>
            <a href="/2016/HDFS Snapshot/">HDFS Snapshot</a>
          </li>
        
          <li>
            <a href="/2016/学习《Real-Time Event Streaming What Are Your Options》/">学习《Real-Time Event Streaming What Are Your Options》</a>
          </li>
        
          <li>
            <a href="/2016/大数据动态之2016Q2/">大数据动态之2016Q2</a>
          </li>
        
          <li>
            <a href="/2016/大数据动态之2016Q1/">大数据动态之2016Q1</a>
          </li>
        
          <li>
            <a href="/2015/大数据动态之2015Q4/">大数据动态之2015Q4</a>
          </li>
        
          <li>
            <a href="/2015/JAVA虚拟机：JVM监控与调优/">JVM监控与调优</a>
          </li>
        
          <li>
            <a href="/2015/大数据动态之201509/">大数据动态之201509</a>
          </li>
        
          <li>
            <a href="/2015/学习《Impala-vs-Hive-Performance-Benchmark》/">学习《Impala vs. Hive Performance Benchmark》</a>
          </li>
        
          <li>
            <a href="/2015/Hortonworks-HDP-2-3-0/">Hortonworks HDP 2.3.0</a>
          </li>
        
          <li>
            <a href="/2015/Oozie：入门概述/">Oozie：入门概述</a>
          </li>
        
          <li>
            <a href="/2015/大数据技术百度指数201508/">大数据技术百度指数201508</a>
          </li>
        
          <li>
            <a href="/2015/大数据动态之201508/">大数据动态之201508</a>
          </li>
        
      </ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/06/">六月 2016</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/05/">五月 2016</a><span class="archive-list-count">5</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/04/">四月 2016</a><span class="archive-list-count">4</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/01/">一月 2016</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/11/">十一月 2015</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/10/">十月 2015</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/09/">九月 2015</a><span class="archive-list-count">5</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/08/">八月 2015</a><span class="archive-list-count">7</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/07/">七月 2015</a><span class="archive-list-count">5</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/06/">六月 2015</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/05/">五月 2015</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/03/">三月 2015</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/01/">一月 2015</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2013/12/">十二月 2013</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2013/08/">八月 2013</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2012/12/">十二月 2012</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2011/11/">十一月 2011</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2011/10/">十月 2011</a><span class="archive-list-count">7</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2011/03/">三月 2011</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2010/11/">十一月 2010</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2010/09/">九月 2010</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2010/08/">八月 2010</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2010/06/">六月 2010</a><span class="archive-list-count">5</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2010/05/">五月 2010</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2010/04/">四月 2010</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2010/03/">三月 2010</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2010/01/">一月 2010</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2009/12/">十二月 2009</a><span class="archive-list-count">6</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2009/10/">十月 2009</a><span class="archive-list-count">8</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2008/04/">四月 2008</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2008/03/">三月 2008</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2007/11/">十一月 2007</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2007/08/">八月 2007</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2007/07/">七月 2007</a><span class="archive-list-count">5</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2007/06/">六月 2007</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2007/05/">五月 2007</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2007/03/">三月 2007</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2006/12/">十二月 2006</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2006/11/">十一月 2006</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2006/10/">十月 2006</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2006/08/">八月 2006</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2006/04/">四月 2006</a><span class="archive-list-count">4</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2005/09/">九月 2005</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2005/08/">八月 2005</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2005/05/">五月 2005</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2005/02/">二月 2005</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2005/01/">一月 2005</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2004/12/">十二月 2004</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2004/11/">十一月 2004</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2004/10/">十月 2004</a><span class="archive-list-count">7</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2004/09/">九月 2004</a><span class="archive-list-count">4</span></li></ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2016 Steven Xu<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
    <a href="/sitemap.xml" class="mobile-nav-link">Sitemap</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css" type="text/css">
  <script src="/fancybox/jquery.fancybox.pack.js" type="text/javascript"></script>


<script src="/js/script.js" type="text/javascript"></script>

  </div>
</body>
</html>