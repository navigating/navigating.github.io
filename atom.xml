<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  
  <title><![CDATA[On The Open Way]]></title>
  <subtitle><![CDATA[自信人生二百年，会当水击三千里！]]></subtitle>
  <link href="/atom.xml" rel="self"/>
  <link href="http://navigating.github.io//"/>
  <updated>2015-08-01T02:27:01.570Z</updated>
  <id>http://navigating.github.io//</id>
  
  <author>
    <name><![CDATA[Steven Xu]]></name>
    <email><![CDATA[xxx@qq.com]]></email>
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title><![CDATA[大数据动态之201507]]></title>
    <link href="http://navigating.github.io/2015/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%8A%A8%E6%80%81%E4%B9%8B201507/"/>
    <id>http://navigating.github.io/2015/大数据动态之201507/</id>
    <published>2015-07-31T08:22:01.000Z</published>
    <updated>2015-08-01T02:27:01.570Z</updated>
    <content type="html"><![CDATA[<p>Hortonworks<br>HDP 2.3发布：<br>HDP 2.3新增加组件Apache Atlas、Apache Calcite<br><a href="http://hortonworks.com/blog/available-now-hdp-2-3/" target="_blank" rel="external">http://hortonworks.com/blog/available-now-hdp-2-3/</a><br><a href="http://hortonworks.com/blog/introducing-availability-of-hdp-2-3-part-2/" target="_blank" rel="external">http://hortonworks.com/blog/introducing-availability-of-hdp-2-3-part-2/</a><br><a href="http://hortonworks.com/blog/introducing-availability-of-hdp-2-3-part-3/" target="_blank" rel="external">http://hortonworks.com/blog/introducing-availability-of-hdp-2-3-part-3/</a><br>Spark 1.2开始支持ORC(Columnar Formats)<br><a href="http://hortonworks.com/blog/bringing-orc-support-into-apache-spark/" target="_blank" rel="external">http://hortonworks.com/blog/bringing-orc-support-into-apache-spark/</a><br>Spark in HDInsight新特性一览<br><a href="http://hortonworks.com/blog/spark-in-hdinsight/" target="_blank" rel="external">http://hortonworks.com/blog/spark-in-hdinsight/</a> </p>
<p>Cloudera<br>HBase 1.0 开始支持Thrift客户端鉴权<br><a href="http://blog.cloudera.com/blog/2015/07/thrift-client-authentication-support-in-apache-hbase-1-0/" target="_blank" rel="external">http://blog.cloudera.com/blog/2015/07/thrift-client-authentication-support-in-apache-hbase-1-0/</a><br>Pig on MR优化<br><a href="http://blog.cloudera.com/blog/2015/07/how-to-tune-mapreduce-parallelism-in-apache-pig-jobs/" target="_blank" rel="external">http://blog.cloudera.com/blog/2015/07/how-to-tune-mapreduce-parallelism-in-apache-pig-jobs/</a><br>Apache Zeppelin on CDH<br><a href="http://blog.cloudera.com/blog/2015/07/how-to-install-apache-zeppelin-on-cdh/" target="_blank" rel="external">http://blog.cloudera.com/blog/2015/07/how-to-install-apache-zeppelin-on-cdh/</a><br>大数据欺诈检测架构<br><a href="http://blog.cloudera.com/blog/2015/07/designing-fraud-detection-architecture-that-works-like-your-brain-does/" target="_blank" rel="external">http://blog.cloudera.com/blog/2015/07/designing-fraud-detection-architecture-that-works-like-your-brain-does/</a> </p>
<p>MapR<br>YARN资源管理实践<br><a href="https://www.mapr.com/blog/best-practices-yarn-resource-management" target="_blank" rel="external">https://www.mapr.com/blog/best-practices-yarn-resource-management</a><br>Hive 1.0对Transaction的支持<br><a href="https://www.mapr.com/blog/hive-transaction-feature-hive-10" target="_blank" rel="external">https://www.mapr.com/blog/hive-transaction-feature-hive-10</a> </p>
<p>Databricks<br>Spark Streaming执行模型<br><a href="https://databricks.com/blog/2015/07/30/diving-into-spark-streamings-execution-model.html" target="_blank" rel="external">https://databricks.com/blog/2015/07/30/diving-into-spark-streamings-execution-model.html</a><br>Spark 1.4 MLP新特性<br><a href="https://databricks.com/blog/2015/07/29/new-features-in-machine-learning-pipelines-in-spark-1-4.html" target="_blank" rel="external">https://databricks.com/blog/2015/07/29/new-features-in-machine-learning-pipelines-in-spark-1-4.html</a><br>从Spark 1.2开始支持ORC<br><a href="https://databricks.com/blog/2015/07/16/joint-blog-post-bringing-orc-support-into-apache-spark.html" target="_blank" rel="external">https://databricks.com/blog/2015/07/16/joint-blog-post-bringing-orc-support-into-apache-spark.html</a><br>从Spark 1.4开始支持窗口函数<br><a href="https://databricks.com/blog/2015/07/15/introducing-window-functions-in-spark-sql.html" target="_blank" rel="external">https://databricks.com/blog/2015/07/15/introducing-window-functions-in-spark-sql.html</a><br>从Spark 1.4开始新的Web UI<br><a href="https://databricks.com/blog/2015/07/08/new-visualizations-for-understanding-spark-streaming-applications.html" target="_blank" rel="external">https://databricks.com/blog/2015/07/08/new-visualizations-for-understanding-spark-streaming-applications.html</a> </p>
<p>Phoenix对join的支持，TPC in Apache Phoenix<br><a href="https://blogs.apache.org/phoenix/entry/tpc_in_apache_phoenix" target="_blank" rel="external">https://blogs.apache.org/phoenix/entry/tpc_in_apache_phoenix</a> </p>
<p>Cassandra<br><a href="http://cassandra.apache.org/" target="_blank" rel="external">http://cassandra.apache.org/</a> </p>
<p>mongoDB<br><a href="https://www.mongodb.org/" target="_blank" rel="external">https://www.mongodb.org/</a> </p>
<p>Confluent<br>基于Kafka的实时流处理<br><a href="http://www.confluent.io/" target="_blank" rel="external">http://www.confluent.io/</a><br>大数据生态系统之Kafka价值<br><a href="http://www.confluent.io/blog/the-value-of-apache-kafka-in-big-data-ecosystem/" target="_blank" rel="external">http://www.confluent.io/blog/the-value-of-apache-kafka-in-big-data-ecosystem/</a> </p>
]]></content>
    <summary type="html">
    <![CDATA[<p>Hortonworks<br>HDP 2.3发布：<br>HDP 2.3新增加组件Apache Atlas、Apache Calcite<br><a href="http://hortonworks.com/blog/available-now-hdp-2-3/" targ]]>
    </summary>
    
      <category term="BigData" scheme="http://navigating.github.io/tags/BigData/"/>
    
      <category term="Cassandra" scheme="http://navigating.github.io/tags/Cassandra/"/>
    
      <category term="Hadoop" scheme="http://navigating.github.io/tags/Hadoop/"/>
    
      <category term="Spark" scheme="http://navigating.github.io/tags/Spark/"/>
    
      <category term="mongoDB" scheme="http://navigating.github.io/tags/mongoDB/"/>
    
      <category term="技术" scheme="http://navigating.github.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[使用Hexo搭建Github静态博客]]></title>
    <link href="http://navigating.github.io/2015/%E4%BD%BF%E7%94%A8Hexo%E6%90%AD%E5%BB%BAGithub%E9%9D%99%E6%80%81%E5%8D%9A%E5%AE%A2/"/>
    <id>http://navigating.github.io/2015/使用Hexo搭建Github静态博客/</id>
    <published>2015-07-28T09:20:22.000Z</published>
    <updated>2015-08-01T02:52:46.672Z</updated>
    <content type="html"><![CDATA[<p>环境：</p>
<pre><code><span class="bullet">1. </span>Windows XP
<span class="bullet">2. </span>Git
</code></pre><p>步骤：</p>
<pre><code><span class="bullet">1. </span>安装Node.js
<span class="bullet">2. </span>安装Hexo
<span class="bullet">3. </span>创建博客(初始化Hexo)
<span class="bullet">4. </span>创建文章本地调试
<span class="bullet">5. </span>配置Github
<span class="bullet">6. </span>远程发布
<span class="bullet">7. </span>支持sitemap和feed
<span class="bullet">8. </span>支持百度统计
<span class="bullet">9. </span>支持图片
<span class="bullet">10. </span>参考资源
</code></pre><h2 id="安装Node-js">安装Node.js</h2><p>下载并安装，<a href="https://nodejs.org/" target="_blank" rel="external">https://nodejs.org/</a></p>
<h2 id="安装Hexo">安装Hexo</h2><p>npm install -g hexo<br>D:\git\navigating.github.io&gt;npm install -g hexo</p>
<pre><code>npm WARN optional dep failed, continuing fsevents<span class="variable">@0</span>.3.6
npm WARN optional dep failed, continuing fsevents<span class="variable">@0</span>.3.6
-


&gt; dtrace-provider<span class="variable">@0</span>.5.0 install C:\Users\stevenxu\AppData\Roaming\npm\node_modules\hexo\node_modules\bunyan\node_modules\dtrace-provider
&gt; node scripts/install.js

C:\Users\stevenxu\AppData\Roaming\npm\hexo -&gt; C:\Users\stevenxu\AppData\Roaming\npm\node_modules\hexo\bin\hexo
hexo<span class="variable">@3</span>.1.1 C:\Users\stevenxu\AppData\Roaming\npm\node_modules\hexo
├── pretty-hrtime<span class="variable">@1</span>.0.0
├── hexo-front-matter<span class="variable">@0</span>.2.2
├── abbrev<span class="variable">@1</span>.0.7
├── titlecase<span class="variable">@1</span>.0.2
├── archy<span class="variable">@1</span>.0.0
├── <span class="keyword">text</span>-table<span class="variable">@0</span>.2.0
├── tildify<span class="variable">@1</span>.1.0 (os-homedir<span class="variable">@1</span>.0.1)
├── <span class="keyword">strip</span>-indent<span class="variable">@1</span>.0.1 (get-stdin<span class="variable">@4</span>.0.1)
├── hexo-i18n<span class="variable">@0</span>.2.1 (sprintf-js<span class="variable">@1</span>.0.3)
├── chalk<span class="variable">@1</span>.1.0 (escape-<span class="keyword">string</span>-regexp<span class="variable">@1</span>.0.3, supports-<span class="keyword">color</span><span class="variable">@2</span>.0.0, ansi-styles<span class="variable">@2</span>.1.0, <span class="keyword">strip</span>-ansi<span class="variable">@3</span>.0.0, has-ansi<span class="variable">@2</span>.0.0)
├── bluebird<span class="variable">@2</span>.9.34
├── minimatch<span class="variable">@2</span>.0.10 (brace-expansion<span class="variable">@1</span>.1.0)
├── through2<span class="variable">@1</span>.1.1 (xtend<span class="variable">@4</span>.0.0, readable-stream<span class="variable">@1</span>.1.13)
├── swig-extras<span class="variable">@0</span>.0.1 (markdown<span class="variable">@0</span>.5.0)
├── hexo-fs<span class="variable">@0</span>.1.3 (escape-<span class="keyword">string</span>-regexp<span class="variable">@1</span>.0.3, graceful-fs<span class="variable">@3</span>.0.8, chokidar<span class="variable">@0</span>.12.6)
├── js-yaml<span class="variable">@3</span>.3.1 (esprima<span class="variable">@2</span>.2.0, argparse<span class="variable">@1</span>.0.2)
├── nunjucks<span class="variable">@1</span>.3.4 (optimist<span class="variable">@0</span>.6.1, chokidar<span class="variable">@0</span>.12.6)
├── warehouse<span class="variable">@1</span>.0.2 (graceful-fs<span class="variable">@3</span>.0.8, cuid<span class="variable">@1</span>.2.5, JSONStream<span class="variable">@0</span>.10.0)
├── cheerio<span class="variable">@0</span>.19.0 (entities<span class="variable">@1</span>.1.1, dom-serializer<span class="variable">@0</span>.1.0, css-<span class="keyword">select</span><span class="variable">@1</span>.0.0, htmlparser2<span class="variable">@3</span>.8.3)
├── bunyan<span class="variable">@1</span>.4.0 (safe-json-stringify<span class="variable">@1</span>.0.3, dtrace-provider<span class="variable">@0</span>.5.0, mv<span class="variable">@2</span>.1.1)

├── hexo-cli<span class="variable">@0</span>.1.7 (minimist<span class="variable">@1</span>.1.2)
├── moment-timezone<span class="variable">@0</span>.3.1
├── moment<span class="variable">@2</span>.10.3
├── hexo-util<span class="variable">@0</span>.1.7 (ent<span class="variable">@2</span>.2.0, highlight.js<span class="variable">@8</span>.6.0)
├── swig<span class="variable">@1</span>.4.2 (optimist<span class="variable">@0</span>.6.1, uglify-js<span class="variable">@2</span>.4.24)
└── lodash<span class="variable">@3</span>.10.0

D:\git\hexo&gt;
</code></pre><h2 id="创建博客(初始化hexo)">创建博客(初始化hexo)</h2><p>创建博客站点的本地目录，然后在文件夹下执行命令：<br>$ hexo init<br>[info] Copying data<br>[info] You are almost done! Don’t forget to run <code>npm install</code> before you start b<br>logging with Hexo!</p>
<p>Hexo会自动在目标文件夹下建立网站所需要的文件。然后按照提示，安装node_modules，执行如下命令：<br>$ hexo install</p>
<h2 id="创建文章本地调试">创建文章本地调试</h2><p>预览本地调试模式，执行如下命令：<br>$ hexo server<br>[info] Hexo is running at <a href="http://localhost:4000/" target="_blank" rel="external">http://localhost:4000/</a>. Press Ctrl+C to stop.</p>
<p>关键命令简介：<br>hexo n     #创建新的文章<br>hexo g     #重新生成站点<br>hexo s     #启动本地服务<br>hexo d     #发布到github</p>
<p>创建文章<br>$ hexo new “使用Hexo搭建Github静态博客”<br>在Hexo工作文件夹下source_posts发现新创建的md文件 使用Hexo搭建Github静态博客.md 。</p>
<h2 id="配置Github">配置Github</h2><p>部署到Github需要修改配置文件_config.yml文件，在Hexo工作目录之下：</p>
<pre><code># Deployment
## <span class="string">Docs:</span> <span class="string">http:</span><span class="comment">//hexo.io/docs/deployment.html</span>
<span class="label">
deploy:</span>
<span class="label">    type:</span> git
<span class="label">    repository:</span> git<span class="annotation">@github</span>.<span class="string">com:</span>&lt;Your Github Username&gt;/&lt;Your github.io url&gt;
<span class="label">    branch:</span> master
</code></pre><p>注意，当前type为git，而不是github</p>
<p>测试Github是否好用<br>ssh -T git@github.com</p>
<h2 id="远程发布">远程发布</h2><p>远程部署到Github，通过执行如下命令：<br>$ hexi deploy</p>
<p>Troubleshooting<br>出现错误：Error: spawn git ENOENT<br>解决方案：<br><a href="http://blog.csdn.net/rainloving/article/details/46595559" target="_blank" rel="external">http://blog.csdn.net/rainloving/article/details/46595559</a> </p>
<p>使用github出现：fatal: unable to access: Failed connect to github.com:8080: No error<br>解决方案：<br><a href="http://www.zhihu.com/question/26954892" target="_blank" rel="external">http://www.zhihu.com/question/26954892</a> </p>
<p>使用github出现：ssh:connect to host github.com port 22: Bad file number<br>解决方案：<br><a href="http://www.xnbing.org/?p=759" target="_blank" rel="external">http://www.xnbing.org/?p=759</a><br><a href="http://blog.csdn.net/temotemo/article/details/7641883" target="_blank" rel="external">http://blog.csdn.net/temotemo/article/details/7641883</a> </p>
<h2 id="添加sitemap和feed">添加sitemap和feed</h2><p>首先安装sitemap和feed插件<br>$ npm install hexo-generator-sitemap<br>$ npm install hexo-generator-feed</p>
<p>修改配置，在文件 _config.yml 增加以下内容</p>
<pre><code><span class="preprocessor"># Extensions</span>
<span class="label">Plugins:</span>
- hexo-generator-feed
- hexo-generator-sitemap

<span class="preprocessor">#Feed Atom</span>
<span class="label">feed:</span>
    type: atom
    path: atom.xml
    limit: <span class="number">20</span>

<span class="preprocessor">#sitemap</span>
<span class="label">sitemap:</span>
    path: sitemap.xml
</code></pre><p>在 themes\landscape_config.yml 中添加：</p>
<pre><code><span class="attribute">menu</span>:
    <span class="attribute">Home</span>: /
    <span class="attribute">Archives</span>: /archives
    <span class="attribute">Sitemap</span>: /sitemap.xml
<span class="attribute">rss</span>: /atom.xml
</code></pre><h2 id="支持百度统计">支持百度统计</h2><p>在 <a href="http://tongji.baidu.com" target="_blank" rel="external">http://tongji.baidu.com</a> 注册帐号，添加网站，生成统计功能的 JS 代码。</p>
<p>在 themes\landscape_config.yml 中新添加一行：</p>
<pre><code><span class="keyword">baidu_t</span>ongji: <span class="keyword">true</span>
</code></pre><p>在 themes\landscape\layout_partial\head.ejs 中head的结束标签  之前新添加一行代码</p>
<pre><code>&lt;<span class="preprocessor">%</span>- partial<span class="comment">('baidu_tongji')</span> <span class="preprocessor">%</span>&gt;
</code></pre><p>在 themes\landscape\layout_partial 中新创建一个文件 baidu_tongji.ejs 并添加如下内容：</p>
<pre><code><span class="xml"></span>&lt;%<span class="ruby"> <span class="keyword">if</span> (theme.baidu_tongji){ </span>%&gt;<span class="xml">
<span class="tag">&lt;<span class="title">script</span> <span class="attribute">type</span>=<span class="value">"text/javascript"</span>&gt;</span><span class="apache">
    <span class="tag">&lt;百度统计的 JS 代码&gt;</span>
</span><span class="tag">&lt;/<span class="title">script</span>&gt;</span>
</span>&lt;%<span class="ruby"> } </span>%&gt;<span class="xml"></span>
</code></pre><p>添加统计，参考：<br><a href="http://ibruce.info/2013/11/22/hexo-your-blog/" target="_blank" rel="external">http://ibruce.info/2013/11/22/hexo-your-blog/</a><br><a href="http://www.cnblogs.com/zhcncn/p/4097881.html" target="_blank" rel="external">http://www.cnblogs.com/zhcncn/p/4097881.html</a> </p>
<h2 id="支持图片">支持图片</h2><p>在source目录下创建images目录，然后将图片放在其中。</p>
<h2 id="添加robots-txt">添加robots.txt</h2><p><a href="http://blog.lmintlcx.com/post/blog-with-hexo.html" target="_blank" rel="external">http://blog.lmintlcx.com/post/blog-with-hexo.html</a> </p>
<h2 id="参考资源">参考资源</h2><p><a href="http://blog.lmintlcx.com/post/blog-with-hexo.html" target="_blank" rel="external">http://blog.lmintlcx.com/post/blog-with-hexo.html</a><br><a href="https://github.com/bruce-sha" target="_blank" rel="external">https://github.com/bruce-sha</a><br><a href="http://zipperary.com/2013/05/28/hexo-guide-2/" target="_blank" rel="external">http://zipperary.com/2013/05/28/hexo-guide-2/</a><br><a href="http://zipperary.com/2013/05/29/hexo-guide-3/" target="_blank" rel="external">http://zipperary.com/2013/05/29/hexo-guide-3/</a><br><a href="http://zipperary.com/2013/05/30/hexo-guide-4/" target="_blank" rel="external">http://zipperary.com/2013/05/30/hexo-guide-4/</a><br><a href="http://cnfeat.com/2014/05/10/2014-05-11-how-to-build-a-blog/" target="_blank" rel="external">http://cnfeat.com/2014/05/10/2014-05-11-how-to-build-a-blog/</a><br><a href="http://www.cnblogs.com/zhcncn/p/4097881.html" target="_blank" rel="external">http://www.cnblogs.com/zhcncn/p/4097881.html</a></p>
]]></content>
    <summary type="html">
    <![CDATA[<p>环境：</p>
<pre><code><span class="bullet">1. </span>Windows XP
<span class="bullet">2. </span>Git
</code></pre><p>步骤：</p>
<pre><code><span ]]>
    </summary>
    
      <category term="blog" scheme="http://navigating.github.io/tags/blog/"/>
    
      <category term="github" scheme="http://navigating.github.io/tags/github/"/>
    
      <category term="hexo" scheme="http://navigating.github.io/tags/hexo/"/>
    
      <category term="技术" scheme="http://navigating.github.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Hello World]]></title>
    <link href="http://navigating.github.io/2015/hello-world/"/>
    <id>http://navigating.github.io/2015/hello-world/</id>
    <published>2015-07-27T09:20:22.000Z</published>
    <updated>2015-07-28T09:21:58.301Z</updated>
    <content type="html"><![CDATA[<p>Welcome to <a href="http://hexo.io/" target="_blank" rel="external">Hexo</a>! This is your very first post. Check <a href="http://hexo.io/docs/" target="_blank" rel="external">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="http://hexo.io/docs/troubleshooting.html" target="_blank" rel="external">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="external">GitHub</a>.</p>
<h2 id="Quick_Start">Quick Start</h2><h3 id="Create_a_new_post">Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure>
<p>More info: <a href="http://hexo.io/docs/writing.html" target="_blank" rel="external">Writing</a></p>
<h3 id="Run_server">Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>
<p>More info: <a href="http://hexo.io/docs/server.html" target="_blank" rel="external">Server</a></p>
<h3 id="Generate_static_files">Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>
<p>More info: <a href="http://hexo.io/docs/generating.html" target="_blank" rel="external">Generating</a></p>
<h3 id="Deploy_to_remote_sites">Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>
<p>More info: <a href="http://hexo.io/docs/deployment.html" target="_blank" rel="external">Deployment</a></p>
]]></content>
    <summary type="html">
    <![CDATA[<p>Welcome to <a href="http://hexo.io/" target="_blank" rel="external">Hexo</a>! This is your very first post. Check <a href="http://hexo.io]]>
    </summary>
    
      <category term="hexo" scheme="http://navigating.github.io/tags/hexo/"/>
    
      <category term="技术" scheme="http://navigating.github.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Hadoop 2.7.1 发布]]></title>
    <link href="http://navigating.github.io/2015/Hadoop-2-7-1-%E5%8F%91%E5%B8%83/"/>
    <id>http://navigating.github.io/2015/Hadoop-2-7-1-发布/</id>
    <published>2015-07-09T13:49:30.000Z</published>
    <updated>2015-07-30T13:50:50.764Z</updated>
    <content type="html"><![CDATA[<p>2015年7月6日，Apache Hadoop的稳定版本 2.7.1 正式发布。<br><a href="http://hadoop.apache.org/releases.html#Release+Notes" target="_blank" rel="external">http://hadoop.apache.org/releases.html#Release+Notes</a> </p>
<p>Hadoop 2.7的一个小版本发布了，本版本属于稳定版本。<br>修复了2.7.0中存在的131个bug。<br>这是2.7.x第一个稳定版本，增强的功能列表请通过2.7.0版本部分查看。<br>按着计划，下一个2.7.x的小版本是2.7.2.</p>
<p>原文：<br>06 July, 2015: Release 2.7.1 (stable) availableA point release for the 2.7 line. This release is now considered stable.<br>Please see the Hadoop 2.7.1 Release Notes for the list of 131 bug fixes and patches since the previous release 2.7.0. Please look at the 2.7.0 section below for the list of enhancements enabled by this first stable release of 2.7.x.</p>
]]></content>
    <summary type="html">
    <![CDATA[<p>2015年7月6日，Apache Hadoop的稳定版本 2.7.1 正式发布。<br><a href="http://hadoop.apache.org/releases.html#Release+Notes" target="_blank" rel="external"]]>
    </summary>
    
      <category term="Hadoop" scheme="http://navigating.github.io/tags/Hadoop/"/>
    
      <category term="技术" scheme="http://navigating.github.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[读《Deploying Apache Kafka: A Practical FAQ》]]></title>
    <link href="http://navigating.github.io/2015/%E8%AF%BB%E3%80%8ADeploying-Apache-Kafka-A-Practical-FAQ%E3%80%8B/"/>
    <id>http://navigating.github.io/2015/读《Deploying-Apache-Kafka-A-Practical-FAQ》/</id>
    <published>2015-07-02T14:57:45.000Z</published>
    <updated>2015-07-30T15:01:55.553Z</updated>
    <content type="html"><![CDATA[<p>Cloudera发布了Kafka的好文，《Deploying Apache Kafka: A Practical FAQ》，参见：<a href="http://blog.cloudera.com/blog/2015/07/deploying-apache-kafka-a-practical-faq" target="_blank" rel="external">http://blog.cloudera.com/blog/2015/07/deploying-apache-kafka-a-practical-faq</a></p>
<p>是否应当为Kafka Broker使用 固态硬盘 (SSD)<br>实际上使用SSD盘并不能显著地改善 Kafka 的性能，主要有两个原因：</p>
<pre><code>* Kafka写磁盘是异步的，不是同步的。就是说，除了启动、停止之外，Kafka的任何操作都不会去等待磁盘同步（sync）完成；而磁盘同步(disk syncs)总是在后台完成的。这就是为什么Kafka消息至少复制到三个副本是至关重要的，因为一旦单个副本崩溃，这个副本就会丢失数据无法同步写到磁盘。
* 每一个Kafka <span class="keyword">Partition</span>被存储为一个串行的WAL（<span class="keyword">Write</span> Ahead <span class="keyword">Log</span>）日志文件。因此，除了极少数的数据查询，Kafka中的磁盘读写都是串行的。现代的操作系统已经对串行读写做了大量的优化工作。
</code></pre><p>如何对Kafka Broker上持久化的数据进行加密<br>目前，Kafka不提供任何机制对Broker上持久化的数据进行加密。用户可以自己对写入到Kafka的数据进行加密，即是，生产者(Producers)在写Kafka之前加密数据，消费者(Consumers)能解密收到的消息。这就要求生产者(Producers)把加密协议(protocols)和密钥(keys)分享给消费者(Consumers)。<br>另外一种选择，就是使用软件提供的文件系统级别的加密，例如Cloudera Navigator Encrypt。Cloudera Navigator Encrypt是Cloudera企业版(Cloudera Enterprise)的一部分，在应用程序和文件系统之间提供了一个透明的加密层。<br>Apache Zookeeper正成为Kafka集群的一个痛点(pain point)，真的吗？<br>Kafka高级消费者(high-level consumer)的早期版本(0.8.1或更早)使用Zookeeper来维护读的偏移量(offsets，主要是Topic的每个Partition的读偏移量)。如果有大量生产者(consumers)同时从Kafka中读数据，对Kafka的读写负载可能就会超出它的容量，Zookeeper就变成一个瓶颈(bottleneck)。当然，这仅仅出现在一些很极端的案例中(extreme cases)，即有成百上千个消费者(consumers)在使用同一个Zookeeper集群来管理偏移量(offset)。<br>不过，这个问题已经在Kafka当前的版本(0.8.2)中解决。从版本0.8.2开始，高级消费者(high-level consumer)能够使用Kafka自己来管理偏移量(offsets)。本质上讲，它使用一个单独的Kafka Topic来管理最近的读偏移量(read offsets)，因此偏移量管理(offset management)不再要求Zookeeper必须存在。然后，用户将不得不面临选择是用Kafka还是Zookeeper来管理偏移量(offsets)，由消费者(consumer)配置参数 offsets.storage 决定。<br>Cloudera强烈推荐使用Kafka来存储偏移量。当然，为了保证向后兼容性，你可以继续选择使用Zookeeper存储偏移量。(例如，你可能有一个监控平台需要从Zookeeper中读取偏移量信息。) 假如你不得不使用Zookeeper进行偏移量(offset)管理，我们推荐你为Kafka集群使用一个专用的Zookeeper集群。假如一个专用的Zookeeper集群仍然有性能瓶颈，你依然可以通过在Zookeeper节点上使用固态硬盘(SSD)来解决问题。<br>Kafka是否支持跨数据中心的可用性<br>Kafka跨数据中心可用性的推荐解决方案是使用MirrorMaker(<a href="https://cwiki.apache.org/confluence/pages/viewpage.action?pageId=27846330" target="_blank" rel="external">https://cwiki.apache.org/confluence/pages/viewpage.action?pageId=27846330</a> ) 。在你的每一个数据中心都搭建一个Kafka集群，在Kafka集群之间使用MirrorMaker来完成近实时的数据复制。<br>使用MirrorMaker的架构模式是为每一个”逻辑”的topic在每一个数据中心创建一个topic：例如，在逻辑上你有一个”clicks”的topic，那么你实际上有”DC1.clicks”和“DC2.clicks”两个topic(DC1和DC2指得是你的数据中心)。DC1向DC1.clicks中写数据，DC2向DC2.clicks中写数据。MirrorMaker将复制所有的DC1 topics到DC2，并且复制所有的DC2 topics到DC1。现在每个DC上的应用程序都能够访问写入到两个DC的事件。这个应用程序能够合并信息和处理相应的冲突。<br>另一种更复杂的模式是在每一个DC都搭建本地和聚合Kafka集群。这个模式已经被Linkedin使用，Linkedin Kafka运维团队已经在这篇Blog(<a href="https://engineering.linkedin.com/kafka/running-kafka-scale" target="_blank" rel="external">https://engineering.linkedin.com/kafka/running-kafka-scale</a> )中有详细的描述(参见“Tiers and Aggregation”)。<br>Kafka支持哪些类型的数据转换(data transformation)<br>数据流过的Kafka的时候，Kafka并不能进行数据转换。为了处理数据转换，我们推荐如下方法：</p>
<pre><code>* 对于简单事件处理，使用<span class="constant">Flume Kafka </span>integration(<span class="symbol">http:</span>/<span class="regexp">/blog.cloudera.com/blog</span><span class="regexp">/2014/</span><span class="number">11</span>/flafka-apache-flume-meets-apache-kafka-<span class="keyword">for</span>-event-processing )，并且写一个简单的<span class="constant">Apache Flume Interceptor。</span>
* 对于复杂(事件)处理，使用<span class="constant">Apache Spark Streaming从Kafka中</span>读数据和处理数据。
</code></pre><p>在这两种情况下，被转换或者处理的数据可被写会到新的Kafka Topic中，或者直接传送到数据的最终消费者(Consumer)那里。<br>对于实时事件处理模式更全面的描述，看看这篇文章(<a href="http://blog.cloudera.com/blog/2015/06/architectural-patterns-for-near-real-time-data-processing-with-apache-hadoop/" target="_blank" rel="external">http://blog.cloudera.com/blog/2015/06/architectural-patterns-for-near-real-time-data-processing-with-apache-hadoop/</a> )。<br>如何通过Kafka发送大消息或者超大负荷量？<br>Cloudera的性能测试表明Kafka达到最大吞吐量的消息大小为10K左右。更大的消息将导致吞吐量下降。然后，在一些情况下，用户需要发送比10K大的多的消息。<br>如果消息负荷大小是每100s处理MB级别，我们推荐探索以下选择：</p>
<pre><code><span class="bullet">* </span>如果可以使用共享存储(HDFS、S3、NAS)，那么将超负载放在共享存储上，仅用Kafka发送负载数据位置的消息。
<span class="bullet">* </span>对于大消息，在写入Kafka之前将消息拆分成更小的部分，使用消息Key确保所有的拆分部分都写入到同一个partition中，以便于它们能被同一个消息着(Consumer)消费的到，在消费的时候将拆分部分重新组装成一个大消息。
</code></pre><p>在通过Kafka发送大消息时，请记住以下几点：<br>压缩配置</p>
<pre><code><span class="keyword">*</span> Kafka生产者(Producers)能够压缩消息。通过配置参数compression.codec确保压缩已经开启。有效的选项为<span class="string">"gzip"</span>和<span class="string">"snappy"</span>。
</code></pre><p>Broker配置</p>
<pre><code>* message.<span class="built_in">max</span>.<span class="keyword">bytes</span> (default: <span class="number">1000000</span>): Broker能够接受的最大消息。增加这个值以便于匹配你的最大消息。
* <span class="built_in">log</span>.<span class="keyword">segment</span>.<span class="keyword">bytes</span> (default: <span class="number">1</span>GB): Kafka数据文件的大小。确保它至少大于一条消息。默认情况下已经够用，一般最大的消息不会超过<span class="number">1</span>G大小。
* replica.fetch.<span class="built_in">max</span>.<span class="keyword">bytes</span> (default: <span class="number">1</span>MB): Broker间复制的最大的数据大小。这个值必须大于message.<span class="built_in">max</span>.<span class="keyword">bytes</span>，否则一个Broker接受到消息但是会复制失败，从而导致潜在的数据丢失。
</code></pre><p>Consumer配置</p>
<pre><code>* <span class="tag">fetch</span><span class="class">.message</span><span class="class">.max</span><span class="class">.bytes</span> (<span class="rule"><span class="attribute">default</span>:<span class="value"> <span class="number">1</span>MB): Consumer所读消息的最大大小。这个值应该大于或者等于Broker配置的message.max.bytes的值。</span></span>
</code></pre><p>其他方面的考虑：</p>
<pre><code>* <span class="tag">Broker</span>需要针对复制为每一个<span class="tag">partition</span>分配一个<span class="tag">replica</span><span class="class">.fetch</span><span class="class">.max</span><span class="class">.bytes</span>大小的缓存区。需要计算确认( <span class="tag">partition</span>的数量 * 最大消息的大小 )不会超过可用的内存，否则就会引发<span class="tag">OOMs</span>（内存溢出异常）。
* <span class="tag">Consumers</span>有同样的问题，因子参数为 <span class="tag">fetch</span><span class="class">.message</span><span class="class">.max</span><span class="class">.bytes</span> ：确认每一个<span class="tag">partition</span>的消费者针对最大的消息有足够可用的内存。
* 大消息可能引发更长时间的垃圾回收停顿(<span class="tag">garbage</span> <span class="tag">collection</span> <span class="tag">pauses</span>)(<span class="tag">brokers</span>需要申请更大块的内存)。注意观察<span class="tag">GC</span>日志和服务器日志。假如发现长时间的<span class="tag">GC</span>停顿导致<span class="tag">Kafka</span>丢失了<span class="tag">Zookeeper</span> <span class="tag">session</span>，你可能需要为<span class="tag">zookeeper</span><span class="class">.session</span><span class="class">.timeout</span><span class="class">.ms</span>配置更长的<span class="tag">timeout</span>值。
</code></pre><p>Kafka是否支持MQTT或JMS协议<br>目前，Kafka针对上述协议不提供直接支持。但是，用户可以自己编写Adaptors从MQTT或者JMS中读取数据，然后写入到Kafka中。</p>
<p>更多关于在CDH中使用Kafka的信息，下载Deployment Guide(<a href="http://www.cloudera.com/content/cloudera/en/resources/library/datasheet/kafka-reference-architecture.html" target="_blank" rel="external">http://www.cloudera.com/content/cloudera/en/resources/library/datasheet/kafka-reference-architecture.html</a> ) 或者 观看webinar “Bringing Real-Time Data to Hadoop”(<a href="http://www.cloudera.com/content/cloudera/en/resources/library/recordedwebinar/kafka-webinar-recording.html" target="_blank" rel="external">http://www.cloudera.com/content/cloudera/en/resources/library/recordedwebinar/kafka-webinar-recording.html</a> )。</p>
]]></content>
    <summary type="html">
    <![CDATA[<p>Cloudera发布了Kafka的好文，《Deploying Apache Kafka: A Practical FAQ》，参见：<a href="http://blog.cloudera.com/blog/2015/07/deploying-apache-kafka-a-]]>
    </summary>
    
      <category term="CDH" scheme="http://navigating.github.io/tags/CDH/"/>
    
      <category term="Kafka" scheme="http://navigating.github.io/tags/Kafka/"/>
    
      <category term="技术" scheme="http://navigating.github.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[大数据动态之201506]]></title>
    <link href="http://navigating.github.io/2015/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%8A%A8%E6%80%81%E4%B9%8B201506/"/>
    <id>http://navigating.github.io/2015/大数据动态之201506/</id>
    <published>2015-06-09T13:52:23.000Z</published>
    <updated>2015-08-01T02:16:57.704Z</updated>
    <content type="html"><![CDATA[<p>Pinot：LinkedIn的实时数据分析系统<br><a href="http://www.infoq.com/cn/news/2014/10/linkdln" target="_blank" rel="external">http://www.infoq.com/cn/news/2014/10/linkdln</a><br><a href="https://engineering.linkedin.com/analytics/real-time-analytics-massive-scale-pinot" target="_blank" rel="external">https://engineering.linkedin.com/analytics/real-time-analytics-massive-scale-pinot</a></p>
<p>Twitter Heron：Twitter发布新的大数据实时分析系统Heron<br><a href="http://geek.csdn.net/news/detail/33750" target="_blank" rel="external">http://geek.csdn.net/news/detail/33750</a><br><a href="http://www.longda.us/?p=529" target="_blank" rel="external">http://www.longda.us/?p=529</a> </p>
<p>Cloudera<br>HBase对MOBs( Moderate Objects, 主要是大小100K到10M的对象存储 )的支持<br><a href="http://blog.cloudera.com/blog/2015/06/inside-apache-hbases-new-support-for-mobs/" target="_blank" rel="external">http://blog.cloudera.com/blog/2015/06/inside-apache-hbases-new-support-for-mobs/</a><br>准实时计算架构模式<br><a href="http://blog.cloudera.com/blog/2015/06/architectural-patterns-for-near-real-time-data-processing-with-apache-hadoop/" target="_blank" rel="external">http://blog.cloudera.com/blog/2015/06/architectural-patterns-for-near-real-time-data-processing-with-apache-hadoop/</a><br>(翻译：<a href="http://zhuanlan.zhihu.com/donglaoshi/20082628" target="_blank" rel="external">http://zhuanlan.zhihu.com/donglaoshi/20082628</a> )<br>CDH 5.4 新功能：敏感数据处理(Sensitive Data Redaction)<br><a href="http://blog.cloudera.com/blog/2015/06/new-in-cdh-5-4-sensitive-data-redaction/" target="_blank" rel="external">http://blog.cloudera.com/blog/2015/06/new-in-cdh-5-4-sensitive-data-redaction/</a> </p>
<p>Hortonworks<br>YARN的CapacityScheduler对Resource-preemption的支持<br><a href="http://hortonworks.com/blog/better-slas-via-resource-preemption-in-yarns-capacityscheduler/" target="_blank" rel="external">http://hortonworks.com/blog/better-slas-via-resource-preemption-in-yarns-capacityscheduler/</a><br>Hadoop集群对Multihoming的支持<br><a href="http://hortonworks.com/blog/multihoming-on-hadoop-yarn-clusters/" target="_blank" rel="external">http://hortonworks.com/blog/multihoming-on-hadoop-yarn-clusters/</a><br>HDP 2.3企业级HDFS数据加密<br><a href="http://hortonworks.com/blog/new-in-hdp-2-3-enterprise-grade-hdfs-data-at-rest-encryption/" target="_blank" rel="external">http://hortonworks.com/blog/new-in-hdp-2-3-enterprise-grade-hdfs-data-at-rest-encryption/</a><br>Apache Slider 0.80.0版本发布<br><a href="http://hortonworks.com/blog/announcing-apache-slider-0-80-0/" target="_blank" rel="external">http://hortonworks.com/blog/announcing-apache-slider-0-80-0/</a><br>Apache Spark 1.3.1 on HDP 2.2<br><a href="http://hortonworks.com/blog/apache-spark-on-hdp-learn-try-and-do/" target="_blank" rel="external">http://hortonworks.com/blog/apache-spark-on-hdp-learn-try-and-do/</a><br><a href="http://hortonworks.com/hadoop-tutorial/using-apache-spark-technical-preview-with-hdp-2-2/" target="_blank" rel="external">http://hortonworks.com/hadoop-tutorial/using-apache-spark-technical-preview-with-hdp-2-2/</a><br>Ambari 2.0.1 和 HDP 2.2.6 发布<br><a href="http://docs.hortonworks.com/HDPDocuments/HDP2/HDP-2.2.6/bk_HDP_RelNotes/content/ch_relnotes_v226.html" target="_blank" rel="external">http://docs.hortonworks.com/HDPDocuments/HDP2/HDP-2.2.6/bk_HDP_RelNotes/content/ch_relnotes_v226.html</a><br><a href="http://docs.hortonworks.com/HDPDocuments/Ambari-2.0.1.0/bk_releasenotes_ambari_2.0.1.0/content/ch_relnotes-ambari-2.0.1.0.html" target="_blank" rel="external">http://docs.hortonworks.com/HDPDocuments/Ambari-2.0.1.0/bk_releasenotes_ambari_2.0.1.0/content/ch_relnotes-ambari-2.0.1.0.html</a></p>
<p>其他：<br>Graphite的百万Metrics实践之路<br><a href="http://calvin1978.blogcn.com/articles/graphite.html" target="_blank" rel="external">http://calvin1978.blogcn.com/articles/graphite.html</a><br>HBaseCon 2015 大会幻灯片 &amp; 视频<br><a href="http://hbasecon.com/archive.html" target="_blank" rel="external">http://hbasecon.com/archive.html</a><br>HBase在腾讯大数据的应用实践<br><a href="http://www.d1net.com/bigdata/news/353500.html" target="_blank" rel="external">http://www.d1net.com/bigdata/news/353500.html</a><br>从Spark到Hadoop的架构实践<br><a href="http://www.csdn.net/article/2015-06-08/2824889" target="_blank" rel="external">http://www.csdn.net/article/2015-06-08/2824889</a><br>56网大数据<br><a href="http://share.csdn.net/slides/10903" target="_blank" rel="external">http://share.csdn.net/slides/10903</a><br>七牛技术总监陈超：记Spark Summit China 2015<br><a href="http://www.csdn.net/article/2015-04-30/2824594-spark-summit-china-2015" target="_blank" rel="external">http://www.csdn.net/article/2015-04-30/2824594-spark-summit-china-2015</a><br>唯品会美研中心郭安琪：2015 Hadoop Summit见闻<br><a href="http://zhuanlan.zhihu.com/donglaoshi/20072576" target="_blank" rel="external">http://zhuanlan.zhihu.com/donglaoshi/20072576</a><br>华为叶琪：论Spark Streaming的数据可靠性和一致性<br><a href="http://www.csdn.net/article/2015-06-12/2824938" target="_blank" rel="external">http://www.csdn.net/article/2015-06-12/2824938</a><br>Hadoop Summit 2015<br><a href="http://2015.hadoopsummit.org/san-jose/agenda/" target="_blank" rel="external">http://2015.hadoopsummit.org/san-jose/agenda/</a><br>Spark Summit 2015<br><a href="https://spark-summit.org/2015/" target="_blank" rel="external">https://spark-summit.org/2015/</a> </p>
]]></content>
    <summary type="html">
    <![CDATA[<p>Pinot：LinkedIn的实时数据分析系统<br><a href="http://www.infoq.com/cn/news/2014/10/linkdln" target="_blank" rel="external">http://www.infoq.com/cn/]]>
    </summary>
    
      <category term="CDH" scheme="http://navigating.github.io/tags/CDH/"/>
    
      <category term="HBase" scheme="http://navigating.github.io/tags/HBase/"/>
    
      <category term="HDP" scheme="http://navigating.github.io/tags/HDP/"/>
    
      <category term="Hadoop" scheme="http://navigating.github.io/tags/Hadoop/"/>
    
      <category term="Spark" scheme="http://navigating.github.io/tags/Spark/"/>
    
      <category term="技术" scheme="http://navigating.github.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[大数据动态之201505]]></title>
    <link href="http://navigating.github.io/2015/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%8A%A8%E6%80%81%E4%B9%8B201505/"/>
    <id>http://navigating.github.io/2015/大数据动态之201505/</id>
    <published>2015-05-19T02:17:28.000Z</published>
    <updated>2015-08-01T02:19:41.246Z</updated>
    <content type="html"><![CDATA[<p>近期动态：<br>Hadoop 2.7发布。<br>Hortonworks HDP 2.2.4.2发布。<br>Ambari 2.0发布。<br>Cloudera Enterperise 5.4发布。<br>Hive 1.2.0 发布，支持Hive on Spark。</p>
<p>HDP 2.2/HDP 2.2.4/Ambari 2.0/Ambari 2.0.1</p>
<pre><code><span class="bullet">1. </span>HDP支持异构存储Heterogeneous storage，主要是对SSD的支持；
<span class="bullet">2. </span>Hive开始支持 ACID 事务，向企业级应用场景前进了一大步；
<span class="bullet">3. </span>HDP支持Spark 1.2.1；
<span class="bullet">4. </span>HDP支持通过DominantResourceCalculator对CPU的资源隔离与资源调度；
<span class="bullet">5. </span>Ambari 支持Blurprint，通过 REST API 管理和运维有更好的支持；
<span class="bullet">6. </span>Ambari 支持Stacks，通过Stacks方式来定义一系列的集成组件；
<span class="bullet">7. </span>Ambari 2.0支持HDP 2.2平台的Rolling Upgrades；
<span class="bullet">8. </span>Ambari 2.0支持安装、配置Apache Ranger；
<span class="bullet">9. </span>Ambari 2.0开始集成Ambari Alerts；
<span class="bullet">10. </span>Ambari 2.0开始集成Ambari Metrics，替代之前的Ganglia；
<span class="bullet">11. </span>Ambari 2.0开始支持User Views功能，User Views提供给运维人员更好的界面，包括Tez View、Capacity Scheduler View、Hive View、Pig View、Files View；
</code></pre><p>HDP 2.2之后部署的结构与之前有调整，新部署的结构与说明如下：</p>
<p>目录结构<br>从HDP 2.2之后，HDP安装后的目录结构发生了变化，之前安装后的Hadoop在/usr/lib目录下，现在变更到/usr/hdp目录下，结构如下：<br>{code}<br>├── /usr/hdp/2.2.0.0-2041/hadoop<br>│   ├── /usr/hdp/2.2.0.0-2041/hadoop/bin<br>│   ├── /usr/hdp/2.2.0.0-2041/hadoop/conf -&gt; /etc/hadoop/conf<br>│   ├── /usr/hdp/2.2.0.0-2041/hadoop/lib<br>│   │   ├── /usr/hdp/2.2.0.0-2041/hadoop/lib/native<br>│   ├── /usr/hdp/2.2.0.0-2041/hadoop/libexec<br>│   ├── /usr/hdp/2.2.0.0-2041/hadoop/man<br>│   └── /usr/hdp/2.2.0.0-2041/hadoop/sbin<br>├── /usr/hdp/2.2.0.0-2041/hadoop-hdfs<br>│   ├── /usr/hdp/2.2.0.0-2041/hadoop-hdfs/bin<br>│   ├── /usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib<br>│   ├── /usr/hdp/2.2.0.0-2041/hadoop-hdfs/sbin<br>│   └── /usr/hdp/2.2.0.0-2041/hadoop-hdfs/webapps<br>├── /usr/hdp/2.2.0.0-2041/hbase<br>│   ├── /usr/hdp/2.2.0.0-2041/hbase/bin<br>│   ├── /usr/hdp/2.2.0.0-2041/hbase/conf -&gt; /etc/hbase/conf<br>│   ├── /usr/hdp/2.2.0.0-2041/hbase/doc<br>│   ├── /usr/hdp/2.2.0.0-2041/hbase/include<br>│   ├── /usr/hdp/2.2.0.0-2041/hbase/lib<br>└── /usr/hdp/2.2.0.0-2041/zookeeper<br>├── /usr/hdp/2.2.0.0-2041/zookeeper/bin<br>├── /usr/hdp/2.2.0.0-2041/zookeeper/conf -&gt; /etc/zookeeper/conf<br>├── /usr/hdp/2.2.0.0-2041/zookeeper/doc<br>├── /usr/hdp/2.2.0.0-2041/zookeeper/lib<br>├── /usr/hdp/2.2.0.0-2041/zookeeper/man<br>{code}<br>{code}<br>/usr/hdp/2.2.3.0-2611<br>├── /usr/hdp/2.2.3.0-2611/hadoop<br>│   ├── /usr/hdp/2.2.3.0-2611/hadoop/bin<br>│   ├── /usr/hdp/2.2.3.0-2611/hadoop/conf -&gt; /etc/hadoop/conf<br>│   ├── /usr/hdp/2.2.3.0-2611/hadoop/lib<br>│   │   ├── /usr/hdp/2.2.3.0-2611/hadoop/lib/native<br>│   ├── /usr/hdp/2.2.3.0-2611/hadoop/libexec<br>│   ├── /usr/hdp/2.2.3.0-2611/hadoop/man<br>│   └── /usr/hdp/2.2.3.0-2611/hadoop/sbin<br>├── /usr/hdp/2.2.3.0-2611/hadoop-hdfs<br>│   ├── /usr/hdp/2.2.3.0-2611/hadoop-hdfs/bin<br>│   ├── /usr/hdp/2.2.3.0-2611/hadoop-hdfs/lib<br>│   ├── /usr/hdp/2.2.3.0-2611/hadoop-hdfs/sbin<br>│   └── /usr/hdp/2.2.3.0-2611/hadoop-hdfs/webapps<br>├── /usr/hdp/2.2.3.0-2611/hbase<br>│   ├── /usr/hdp/2.2.3.0-2611/hbase/bin<br>│   ├── /usr/hdp/2.2.3.0-2611/hbase/conf -&gt; /etc/hbase/conf<br>│   ├── /usr/hdp/2.2.3.0-2611/hbase/doc<br>│   ├── /usr/hdp/2.2.3.0-2611/hbase/include<br>│   ├── /usr/hdp/2.2.3.0-2611/hbase/lib<br>└── /usr/hdp/2.2.3.0-2611/zookeeper<br>├── /usr/hdp/2.2.3.0-2611/zookeeper/bin<br>├── /usr/hdp/2.2.3.0-2611/zookeeper/conf -&gt; /etc/zookeeper/conf<br>├── /usr/hdp/2.2.3.0-2611/zookeeper/doc<br>├── /usr/hdp/2.2.3.0-2611/zookeeper/lib<br>├── /usr/hdp/2.2.3.0-2611/zookeeper/man<br>{code}<br>管理活动版本<br>HDP 2.0之后推出了hdp-select服务，通过这个服务可以管理活动版本，默认就会安装hdp-select，可以通过hdp-select命令验证是否安装。</p>
<blockquote>
<p>hdp-select<br>hdp-select versions<br>同样支持管理命令，例如：<br>hdp-select set hadoop-hdfs-datanode 2.2.3.0-2600</p>
</blockquote>
<p>安装后的库、工具和脚本<br>库<br>HDP 2.0之前安装后库放在/usr/lib下，现在放在/usr/hdp/current下：<br>/usr/hdp/current/hadoop-hdfs-namenode/<br>/usr/hdp/current/hadoop-yarn-resourcemanager<br>/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-examples.jar</p>
<p>Daemon Scripts<br>/usr/hdp/current/hadoop-hdfs-namenode/../hadoop/sbin/hadoop-deamon.sh<br>/usr/hdp/current/hadoop-yarn-resourcemanager/sbin/yarn-daemon.sh<br>/usr/hdp/current/hadoop-yarn-nodemanager/sbin/yarn-daemon.sh<br>Configuration files<br>/etc/hadoop/conf<br>Bin Scripts<br>/usr/bin/hadoop -&gt; /usr/hdp/current/hadoop-client/bin/hadoop</p>
]]></content>
    <summary type="html">
    <![CDATA[<p>近期动态：<br>Hadoop 2.7发布。<br>Hortonworks HDP 2.2.4.2发布。<br>Ambari 2.0发布。<br>Cloudera Enterperise 5.4发布。<br>Hive 1.2.0 发布，支持Hive on Spark。</p]]>
    </summary>
    
      <category term="Ambari" scheme="http://navigating.github.io/tags/Ambari/"/>
    
      <category term="CDH" scheme="http://navigating.github.io/tags/CDH/"/>
    
      <category term="HDP" scheme="http://navigating.github.io/tags/HDP/"/>
    
      <category term="Hadoop" scheme="http://navigating.github.io/tags/Hadoop/"/>
    
      <category term="Hive" scheme="http://navigating.github.io/tags/Hive/"/>
    
      <category term="技术" scheme="http://navigating.github.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[大数据动态之201502]]></title>
    <link href="http://navigating.github.io/2015/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%8A%A8%E6%80%81%E4%B9%8B201502/"/>
    <id>http://navigating.github.io/2015/大数据动态之201502/</id>
    <published>2015-03-24T14:10:07.000Z</published>
    <updated>2015-08-01T02:27:00.393Z</updated>
    <content type="html"><![CDATA[<p>本月Hadoop技术动态：<br>1.经过6年的孵化，Hive 1.0 发布了。<br>2.经过7年的孵化，HBase 1.0 发布了。<br>3.Cloudera 开始提供 Hive-on-Spark Beta版的下载。</p>
<p>HBase 1.0 需要特别关注的特性：<br>1.API的重新组织和变更；<br>2.读的高可用；<br>3.在线配置变更；</p>
<p>HDP 2.2 发布有一段时间：<br><a href="http://hortonworks.com/blog/announcing-hive-1-0-stable-moment-time/" target="_blank" rel="external">http://hortonworks.com/blog/announcing-hive-1-0-stable-moment-time/</a><br><a href="http://hortonworks.com/blog/start-new-era-apache-hbase-1-0/" target="_blank" rel="external">http://hortonworks.com/blog/start-new-era-apache-hbase-1-0/</a><br><a href="http://blog.cloudera.com/blog/2015/02/apache-hbase-1-0-is-released/" target="_blank" rel="external">http://blog.cloudera.com/blog/2015/02/apache-hbase-1-0-is-released/</a><br><a href="http://blog.cloudera.com/blog/2015/02/download-the-hive-on-spark-beta/" target="_blank" rel="external">http://blog.cloudera.com/blog/2015/02/download-the-hive-on-spark-beta/</a><br><a href="https://issues.apache.org/jira/secure/attachment/12652517/Hive-on-Spark.pdf" target="_blank" rel="external">https://issues.apache.org/jira/secure/attachment/12652517/Hive-on-Spark.pdf</a></p>
<p>Cluster Manager Framework:<br>1.YARN<br>2.Apache Helix</p>
]]></content>
    <summary type="html">
    <![CDATA[<p>本月Hadoop技术动态：<br>1.经过6年的孵化，Hive 1.0 发布了。<br>2.经过7年的孵化，HBase 1.0 发布了。<br>3.Cloudera 开始提供 Hive-on-Spark Beta版的下载。</p>
<p>HBase 1.0 需要特别关注的特]]>
    </summary>
    
      <category term="CDH" scheme="http://navigating.github.io/tags/CDH/"/>
    
      <category term="HDP" scheme="http://navigating.github.io/tags/HDP/"/>
    
      <category term="Hadoop" scheme="http://navigating.github.io/tags/Hadoop/"/>
    
      <category term="Spark" scheme="http://navigating.github.io/tags/Spark/"/>
    
      <category term="技术" scheme="http://navigating.github.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Java 5.0的Instrumentation特性]]></title>
    <link href="http://navigating.github.io/2007/Java-5-0%E7%9A%84Instrumentation%E7%89%B9%E6%80%A7/"/>
    <id>http://navigating.github.io/2007/Java-5-0的Instrumentation特性/</id>
    <published>2007-05-19T03:30:36.000Z</published>
    <updated>2015-08-01T03:50:31.536Z</updated>
    <content type="html"><![CDATA[<p>Java 5发布有一段时间了，Instrumentation这个feature是Java 5新提供的。其方式是通过修改字节码的方式使得Java开发人员能够操作类。官方文档说主要是给工具提供修改应用的状态、行为使用的:)<br>先来个简单的例子看看到底什么是Instrumentation:<br>在JSE 1.5.0的Javadoc的看到java.lang.instrument仅有两个接口ClassFileTransformer和Instrumentation。我们就看看着两个接口的用法：</p>
<pre><code><span class="keyword">public</span> <span class="keyword">class</span> <span class="title">Greeting</span> <span class="title">implements</span> <span class="title">ClassFileTransformer</span> {

    <span class="comment">//字节码转换在这个方法中进行。</span>
    <span class="keyword">public</span> <span class="keyword">byte</span>[] transform(ClassLoader arg0, String classname, Class arg2, ProtectionDomain arg3, <span class="keyword">byte</span>[] arg4)
    throws IllegalClassFormatException {
        System.<span class="keyword">out</span>.printf(<span class="string">"hello:"</span> + classname);
        <span class="keyword">return</span> <span class="keyword">new</span> <span class="keyword">byte</span>[]{};
    }

    <span class="comment">//options是通过命令行传递给虚拟机的参数。</span>
    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">premain</span>(<span class="params">String options, Instrumentation ins</span>) </span>{
        <span class="keyword">if</span> (options != <span class="keyword">null</span>) {
            System.<span class="keyword">out</span>.printf(<span class="string">" I've been called with options: \"%s\"\n"</span>, options);
        } <span class="keyword">else</span>
            System.<span class="keyword">out</span>.println(<span class="string">" I've been called with no options."</span>);
            ins.addTransformer(<span class="keyword">new</span> Greeting());
        }

    }

    <span class="keyword">public</span> <span class="keyword">class</span> <span class="title">Sample</span> {

    <span class="comment">/**
    * @param args
    */</span>
    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span>(<span class="params">String[] args</span>) </span>{
        (<span class="keyword">new</span> Sample()).hello();

    }

    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">hello</span>(<span class="params"></span>) </span>{
        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">10000</span>; i++) {
        <span class="keyword">int</span> index =<span class="number">0</span>;
        index++;
        }
    }

}
</code></pre><p>使用命令行参数的命令行：</p>
<pre><code><span class="tag">java</span> <span class="rule"><span class="attribute">-javaagent</span>:<span class="value">Greeting.jar=<span class="string">"Hello, Sample"</span> Sample</span></span>
</code></pre><p>因此下一步是需要打个jar包，jar包中包含META-INF/MANIFEST.MF和Class文件。<br>其中META-INF/MANIFEST.MF的内容如下：<br>    Manifest-Version: 1.0<br>    Premain-Class: Timing</p>
<p>包含的类文件有：Greeting.class和Sample.class<br>打包：</p>
<pre><code>jar cvfM greeting<span class="class">.jar</span> *
</code></pre><p>输出：<br>    adding: Greeting.class(in = 1774) (out= 869)(deflated 51%)<br>    adding: META-INF/(in = 0) (out= 0)(stored 0%)<br>    adding: META-INF/MANIFEST.MF(in = 44) (out= 46)(deflated -4%)<br>    adding: Sample.class(in = 556) (out= 371)(deflated 33%)</p>
<pre><code>运行命令行：

<span class="tag">java</span> <span class="rule"><span class="attribute">-javaagent</span>:<span class="value">greeting.jar=<span class="string">"Hello,Sample"</span> Greeting</span></span>
</code></pre><p>控制台输出：<br>    I’ve been called with options: “Hello,Sample”</p>
<p>运行命令行：</p>
<pre><code><span class="tag">java</span> <span class="rule"><span class="attribute">-javaagent</span>:<span class="value">greeting.jar=<span class="string">"Hello,Sample"</span> Sample</span></span>
</code></pre><p>控制台输出：<br>    I’ve been called with options: “Hello,Sample”<br>    hello:Sample</p>
<p>通过这个例子估计Instrutment API使用的方法已经基本上有了个理解了。<br>下面就是举一个用apache bcel构造bytecode的Instrutment的实际的例子：</p>
<p>使用 instrumentation ，使用Apache 开源项目 BCEL修改bytecode，实现用于计算一个方法运行时间的功能。这种方式，用于性能测量的语句与业务逻辑完全分离，同时也可以用于测量任意类的任意方法的 运行时间，提高了代码的重用性。</p>
<pre><code><span class="keyword">import</span> java.io.<span class="type">ByteArrayOutputStream</span>;
<span class="keyword">import</span> java.io.<span class="type">IOException</span>;
<span class="keyword">import</span> java.lang.instrument.<span class="type">ClassFileTransformer</span>;
<span class="keyword">import</span> java.lang.instrument.<span class="type">IllegalClassFormatException</span>;
<span class="keyword">import</span> java.lang.instrument.<span class="type">Instrumentation</span>;

<span class="keyword">import</span> org.apache.bcel.<span class="type">Constants</span>;
<span class="keyword">import</span> org.apache.bcel.classfile.<span class="type">ClassParser</span>;
<span class="keyword">import</span> org.apache.bcel.classfile.<span class="type">JavaClass</span>;
<span class="keyword">import</span> org.apache.bcel.classfile.<span class="type">Method</span>;
<span class="keyword">import</span> org.apache.bcel.<span class="keyword">generic</span>.<span class="type">ClassGen</span>;
<span class="keyword">import</span> org.apache.bcel.<span class="keyword">generic</span>.<span class="type">ConstantPoolGen</span>;
<span class="keyword">import</span> org.apache.bcel.<span class="keyword">generic</span>.<span class="type">InstructionConstants</span>;
<span class="keyword">import</span> org.apache.bcel.<span class="keyword">generic</span>.<span class="type">InstructionFactory</span>;
<span class="keyword">import</span> org.apache.bcel.<span class="keyword">generic</span>.<span class="type">InstructionList</span>;
<span class="keyword">import</span> org.apache.bcel.<span class="keyword">generic</span>.<span class="type">MethodGen</span>;
<span class="keyword">import</span> org.apache.bcel.<span class="keyword">generic</span>.<span class="type">ObjectType</span>;
<span class="keyword">import</span> org.apache.bcel.<span class="keyword">generic</span>.<span class="type">PUSH</span>;
<span class="keyword">import</span> org.apache.bcel.<span class="keyword">generic</span>.<span class="type">Type</span>;

public class <span class="type">Timing</span> implements <span class="type">ClassFileTransformer</span> {

    private <span class="type">String</span> methodName;

    private <span class="type">Timing</span>(<span class="type">String</span> methodName) {
        this.methodName = methodName;
        <span class="type">System</span>.<span class="keyword">out</span>.println(methodName);
    }

    public byte[] transform(<span class="type">ClassLoader</span> loader, <span class="type">String</span> className, <span class="type">Class</span> cBR, java.security.<span class="type">ProtectionDomain</span> pD, byte[] classfileBuffer) throws <span class="type">IllegalClassFormatException</span> {
        <span class="keyword">try</span> {
            <span class="type">ClassParser</span> cp = new <span class="type">ClassParser</span>(new java.io.<span class="type">ByteArrayInputStream</span>(classfileBuffer), className + <span class="string">".java"</span>);
            <span class="type">JavaClass</span> jclas = cp.parse();
            <span class="type">ClassGen</span> cgen = new <span class="type">ClassGen</span>(jclas);
            <span class="type">Method</span>[] methods = jclas.getMethods();
            <span class="type">int</span> index;
            <span class="keyword">for</span> (index = <span class="number">0</span>; index &lt; methods.length; index++) {
                <span class="keyword">if</span> (methods[index].getName().equals(methodName)) {
                    <span class="keyword">break</span>;
                }
            }

            <span class="keyword">if</span> (index &lt; methods.length) {
                addTimer(cgen, methods[index]);
                <span class="type">ByteArrayOutputStream</span> bos = new <span class="type">ByteArrayOutputStream</span>();
                cgen.getJavaClass().dump(bos);
                <span class="keyword">return</span> bos.toByteArray();
            }
            <span class="type">System</span>.err.println(<span class="string">"Method "</span> + methodName + <span class="string">" not found in "</span> + className);
            <span class="type">System</span>.exit(<span class="number">0</span>);

        } catch (<span class="type">IOException</span> e) {
            <span class="type">System</span>.err.println(e);
            <span class="type">System</span>.exit(<span class="number">0</span>);
        }
        <span class="keyword">return</span> null; // <span class="type">No</span> transformation required
    }

    private <span class="keyword">static</span> <span class="type">void</span> addTimer(<span class="type">ClassGen</span> cgen, <span class="type">Method</span> <span class="keyword">method</span>) {

        // <span class="type">set</span> up the construction tools
        <span class="type">InstructionFactory</span> ifact = new <span class="type">InstructionFactory</span>(cgen);
        <span class="type">InstructionList</span> ilist = new <span class="type">InstructionList</span>();
        <span class="type">ConstantPoolGen</span> pgen = cgen.getConstantPool();
        <span class="type">String</span> cname = cgen.getClassName();
        <span class="type">MethodGen</span> wrapgen = new <span class="type">MethodGen</span>(<span class="keyword">method</span>, cname, pgen);
        wrapgen.setInstructionList(ilist);

        // rename a copy <span class="keyword">of</span> the original <span class="keyword">method</span>
        <span class="type">MethodGen</span> methgen = new <span class="type">MethodGen</span>(<span class="keyword">method</span>, cname, pgen);
        cgen.removeMethod(<span class="keyword">method</span>);
        <span class="type">String</span> iname = methgen.getName() + <span class="string">"_timing"</span>;
        methgen.setName(iname);
        cgen.addMethod(methgen.getMethod());
        <span class="type">Type</span> <span class="literal">result</span> = methgen.getReturnType();

        // compute the size <span class="keyword">of</span> the calling parameters
        <span class="type">Type</span>[] parameters = methgen.getArgumentTypes();
        <span class="type">int</span> stackIndex = methgen.isStatic() ? <span class="number">0</span> : <span class="number">1</span>;
        <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; parameters.length; i++) {
            stackIndex += parameters[i].getSize();
        }

        // save time prior to invocation
        ilist.append(ifact.createInvoke(<span class="string">"java.lang.System"</span>, <span class="string">"currentTimeMillis"</span>, <span class="type">Type</span>.<span class="type">LONG</span>, <span class="type">Type</span>.<span class="type">NO_ARGS</span>, <span class="type">Constants</span>.<span class="type">INVOKESTATIC</span>));
        ilist.append(<span class="type">InstructionFactory</span>.createStore(<span class="type">Type</span>.<span class="type">LONG</span>, stackIndex));

        // call the wrapped <span class="keyword">method</span>
        <span class="type">int</span> offset = <span class="number">0</span>;
        short invoke = <span class="type">Constants</span>.<span class="type">INVOKESTATIC</span>;
        <span class="keyword">if</span> (!methgen.isStatic()) {
            ilist.append(<span class="type">InstructionFactory</span>.createLoad(<span class="type">Type</span>.<span class="type">OBJECT</span>, <span class="number">0</span>));
            offset = <span class="number">1</span>;
            invoke = <span class="type">Constants</span>.<span class="type">INVOKEVIRTUAL</span>;
        }
        <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; parameters.length; i++) {
            <span class="type">Type</span> <span class="keyword">type</span> = parameters[i];
            ilist.append(<span class="type">InstructionFactory</span>.createLoad(<span class="keyword">type</span>, offset));
            offset += <span class="keyword">type</span>.getSize();
        }
        ilist.append(ifact.createInvoke(cname, iname, <span class="literal">result</span>, parameters, invoke));

        // store <span class="literal">result</span> <span class="keyword">for</span> <span class="keyword">return</span> later
        <span class="keyword">if</span> (<span class="literal">result</span> != <span class="type">Type</span>.<span class="type">VOID</span>) {
            ilist .append(<span class="type">InstructionFactory</span>.createStore(<span class="literal">result</span>, stackIndex + <span class="number">2</span>));
        }

        // print time required <span class="keyword">for</span> <span class="keyword">method</span> call
        ilist.append(ifact.createFieldAccess(<span class="string">"java.lang.System"</span>, <span class="string">"out"</span>, new <span class="type">ObjectType</span>(<span class="string">"java.io.PrintStream"</span>), <span class="type">Constants</span>.<span class="type">GETSTATIC</span>));
        ilist.append(<span class="type">InstructionConstants</span>.<span class="type">DUP</span>);
        ilist.append(<span class="type">InstructionConstants</span>.<span class="type">DUP</span>);
        <span class="type">String</span> text = <span class="string">"Call to method "</span> + methgen.getName() + <span class="string">" took "</span>;
        ilist.append(new <span class="type">PUSH</span>(pgen, text));
        ilist.append(ifact.createInvoke(<span class="string">"java.io.PrintStream"</span>, <span class="string">"print"</span>, <span class="type">Type</span>.<span class="type">VOID</span>, new <span class="type">Type</span>[] { <span class="type">Type</span>.<span class="type">STRING</span> }, <span class="type">Constants</span>.<span class="type">INVOKEVIRTUAL</span>));
        ilist.append(ifact.createInvoke(<span class="string">"java.lang.System"</span>, <span class="string">"currentTimeMillis"</span>, <span class="type">Type</span>.<span class="type">LONG</span>, <span class="type">Type</span>.<span class="type">NO_ARGS</span>, <span class="type">Constants</span>.<span class="type">INVOKESTATIC</span>));
        ilist.append(<span class="type">InstructionFactory</span>.createLoad(<span class="type">Type</span>.<span class="type">LONG</span>, stackIndex));
        ilist.append(<span class="type">InstructionConstants</span>.<span class="type">LSUB</span>);
        ilist.append(ifact.createInvoke(<span class="string">"java.io.PrintStream"</span>, <span class="string">"print"</span>,
        <span class="type">Type</span>.<span class="type">VOID</span>, new <span class="type">Type</span>[] { <span class="type">Type</span>.<span class="type">LONG</span> }, <span class="type">Constants</span>.<span class="type">INVOKEVIRTUAL</span>));
        ilist.append(new <span class="type">PUSH</span>(pgen, <span class="string">" ms."</span>));
        ilist.append(ifact.createInvoke(<span class="string">"java.io.PrintStream"</span>, <span class="string">"println"</span>, <span class="type">Type</span>.<span class="type">VOID</span>, new <span class="type">Type</span>[] { <span class="type">Type</span>.<span class="type">STRING</span> }, <span class="type">Constants</span>.<span class="type">INVOKEVIRTUAL</span>));

        // <span class="keyword">return</span> <span class="literal">result</span> <span class="keyword">from</span> wrapped <span class="keyword">method</span> call
        <span class="keyword">if</span> (<span class="literal">result</span> != <span class="type">Type</span>.<span class="type">VOID</span>) {
            ilist.append(<span class="type">InstructionFactory</span>.createLoad(<span class="literal">result</span>, stackIndex + <span class="number">2</span>));
        }
        ilist.append(<span class="type">InstructionFactory</span>.createReturn(<span class="literal">result</span>));

        // finalize the constructed <span class="keyword">method</span>
        wrapgen.stripAttributes(<span class="literal">true</span>);
        wrapgen.setMaxStack();
        wrapgen.setMaxLocals();
        cgen.addMethod(wrapgen.getMethod());
        ilist.dispose();
    }

    public <span class="keyword">static</span> <span class="type">void</span> premain(<span class="type">String</span> options, <span class="type">Instrumentation</span> ins) {
        <span class="keyword">if</span> (options != null) {
            ins.addTransformer(new <span class="type">Timing</span>(options));
        } <span class="keyword">else</span> {
            <span class="type">System</span>.<span class="keyword">out</span>.println(<span class="string">"Usage: java -javaagent:Timing.jar=\"class:method\""</span>);
            <span class="type">System</span>.exit(<span class="number">0</span>);
        }

    }
}
</code></pre><p>打jar包:</p>
<pre><code>$ jar cvfM timing<span class="class">.jar</span> *
</code></pre><p>输出：<br>    adding: META-INF/(in = 0) (out= 0)(stored 0%)<br>    adding: META-INF/MANIFEST.MF(in = 44) (out= 46)(deflated -4%)<br>    adding: Sample.class(in = 556) (out= 371)(deflated 33%)<br>    adding: Timing.class(in = 7372) (out= 3442)(deflated 53%)</p>
<p>运行命令行：</p>
<pre><code>$ java -classpath bcel-<span class="number">5.2</span><span class="class">.jar</span> -javaagent:timing.jar=<span class="string">"hello"</span> Sample
</code></pre><p>输出：<br>    hello<br>    Call to method hello_timing took 2047 ms.</p>
<p>运行命令：</p>
<pre><code>$ java -classpath bcel-<span class="number">5.2</span><span class="class">.jar</span> -javaagent:timing.jar=<span class="string">"main"</span> Sample
</code></pre><p>输出：<br>    main<br>    Call to method main_timing took 2469 ms.</p>
<p>通过这段代码，基本能够了解Instrument的用处之一了:)</p>
<p>参考：<a href="http://www.ibm.com/developerworks/cn/java/j-lo-instrumentation/" target="_blank" rel="external">http://www.ibm.com/developerworks/cn/java/j-lo-instrumentation/</a></p>
]]></content>
    <summary type="html">
    <![CDATA[<p>Java 5发布有一段时间了，Instrumentation这个feature是Java 5新提供的。其方式是通过修改字节码的方式使得Java开发人员能够操作类。官方文档说主要是给工具提供修改应用的状态、行为使用的:)<br>先来个简单的例子看看到底什么是Instrumen]]>
    </summary>
    
      <category term="技术" scheme="http://navigating.github.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[2006年年终总结(原名：一篇没有写完的BLOG)]]></title>
    <link href="http://navigating.github.io/2007/2006%E5%B9%B4%E5%B9%B4%E7%BB%88%E6%80%BB%E7%BB%93-%E5%8E%9F%E5%90%8D%EF%BC%9A%E4%B8%80%E7%AF%87%E6%B2%A1%E6%9C%89%E5%86%99%E5%AE%8C%E7%9A%84BLOG/"/>
    <id>http://navigating.github.io/2007/2006年年终总结-原名：一篇没有写完的BLOG/</id>
    <published>2007-03-13T03:29:17.000Z</published>
    <updated>2015-08-01T03:29:46.155Z</updated>
    <content type="html"><![CDATA[<p>2006已经过去，2007已经开始。<br>过去的一年，有高兴，有激动，有不少难以忘记的时刻，有很多痛苦的思考。当我面对和回首自己过去的一年，我不知道自己除了时间之外究竟还失去了什么，自己除了痛苦之外还有多少收获？<br>人是可以活的洒脱些，就看一个人究竟要的是什么？就看你付出了多少？<br>要行动，要思考，要计划，要不断的沟通。<br>技术的狂热，当我在Miami Java User Group第一次聚会上看到Michael Feather的依然这么执着，依然的狂热，对于C++,对于functional programming，一个普通的程序员的极限就是这样吗。</p>
<p>一个Senior Programmer</p>
<p>首先是一个人，要做一个什么样子的人？<br>“观身如身，观心如心。”<br>如果是一个人，一个人的架构一定要比程序员的架构高。我们要一个什么样的身，基本的是健康的，就要经常锻炼了；中国一向有一个修身的传统，可见修身包括很多，怎么去修身，社会有社会的价值，个人有个人的志向。修身对谁都是一个既迷茫又痛苦的话题，“求仁得仁”，回到一个很糟乱的话题了，一个人到底想要得是什么？为了想要的得到底付出了什么？包括痛苦，包括性命，“求仁得仁”这个成语本身，伯夷、叔齐并没有欢天喜地的结局，相反，太执著，太倔强，为了得到可以牺牲了权利，身份，温饱，生命。一个人想来想去，问来问去，问的都是自己，都是自己的心。屈原先生应当是这方面的最有权威的专家了。能研究做学问的学问—哲学的人智商肯定不能低，“观身如身，观心如心。”这句话理解起来费力；还说了“观身观心”，痛苦的时候观自己的心；走投无路的时候寻找去观他人的心。<br>如果人一生有幸福和痛苦的话，那痛苦和幸福一定有一个起点，那是不是凡事都有起点。如果一生有起点的话，这个起点在哪儿？一个人能不能自己选择起点？<br>技术，技术是什么？什么是技术？如果技术是一个世界，技术之外呢？技术之外的世界呢？<br>人类也不知道生命出现之前的状态，一个人是不知道前世的；也无法将来到这个世界的最初的感觉的存储在自己的大脑的。那么一个人还是能想象死亡的。<br>一个人最痛苦的是什么，失去生命吗？如果说失去生命是最痛苦的，那是为什么呢，有人体验过吗？肯定没有。为什么人要惧怕死亡呢，因为要失去一些东西吗还是人的状态要发生了转变还是人类无法预知死亡之后的东西？如果是这样，恐惧的是失去，恐惧的是巨变，恐惧的是未知。如果一个人要恐惧失去，就应该恐惧死亡；如果一个人恐惧巨变，就应该恐惧死亡；如果一个人恐惧未知，就应该恐惧死亡。同样，一个人恐惧死亡，肯定会恐惧失去，恐惧巨变，恐惧未知。</p>
]]></content>
    <summary type="html">
    <![CDATA[<p>2006已经过去，2007已经开始。<br>过去的一年，有高兴，有激动，有不少难以忘记的时刻，有很多痛苦的思考。当我面对和回首自己过去的一年，我不知道自己除了时间之外究竟还失去了什么，自己除了痛苦之外还有多少收获？<br>人是可以活的洒脱些，就看一个人究竟要的是什么？就看你]]>
    </summary>
    
      <category term="生活" scheme="http://navigating.github.io/categories/%E7%94%9F%E6%B4%BB/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[开聊有益]]></title>
    <link href="http://navigating.github.io/2007/%E5%BC%80%E8%81%8A%E6%9C%89%E7%9B%8A/"/>
    <id>http://navigating.github.io/2007/开聊有益/</id>
    <published>2007-03-13T03:27:30.000Z</published>
    <updated>2015-08-01T03:28:00.083Z</updated>
    <content type="html"><![CDATA[<p>偶尔看一下中央二套的两会节目，竟然在讨论青少年上网的社会/教育问题。<br>抨击我国现状教育的不在少数，学校教育大体上就是一种“推”的教育方式，是一种社会培养人才的最重要的体系，是对未来人才的储备机制，正如宣传所说青少年就是花儿的年华。人生只有一次，家长，社会的期望终归是一种期望，孩子有孩子的乐趣，孩子的年华，孩子的思想。<br>就针对个人而言，回想数十年“寒窗读书”有意思的好像真没多少，或许是背了些英语单词，记了些简单的英语句子；还有就是几篇语文的文章名字或者几个名句；还有几个数理化的专业术语。如果说是从业研究方向，可能还正能捡起些东西来。一般人对于孩子教育不外乎认为培养兴趣，培养性格等几个方面，当我们进入社会，发现做人本身就不是件容易的事情，何况培养人，培养人才。<br>一提到问题/隐患，很多人不约而同的想到改革这个话题，我有个朋友谈到，教育抓得是人的未来，医疗抓得人的命，谁都无法逃脱其中，改革这两项何其难啊。这真是一阵见血的评论。<br>培养性格是很重要的一方面，培养什么样的人才至少需要前瞻性的眼界了解社会的人才需求方向，所以做大师就不是那么简单的事情了。<br>一个人走出校门的同时进入社会，肯定能强烈感觉到社会需要什么样的人才的，很多时候就是社会在“拉”了，在这个过程中人类表现了异常聪明的一面，总是在做自我培养，提高自身。中国哲学的本身很大成分上都是和自己斗争的过程，大体上是自我培养的哲学体系，可见中国人对于社会还是异常重视尊重的。学校教育带来的很大的弊端就是自闭，一不小心就走入了以自我为中心的圈子；同时容易让人抑郁。估计很多人在人生的某些阶段都会有抑郁，自闭的问题；要提高自我必须要认清出这个问题，解决这个问题。<br>中国人大体上不怎么提倡Open这种方式，我们在社会中愈来愈发现Open的重要性，所以更多人都宁愿自己是一个心理，眼睛，思维都很Open的人。<br>我自身已近从事软件开发三年多，如果让我回首认为该毕业的时候如何策划培养自己，除了性格之外有三点：<br>1。沟通能力，做好任何一件事情，寻找任何一个机会，每一次自我的提高，都是从沟通开始的。世界变得越来越平，沟通的空间时间也在增长。<br>2。语言(掌控)能力，能够多掌握一门语言，相当于给自己多了一个世界，机会，眼界，空间。。。。。。<br>3。技术能力，这是一个从事软件开发人员的立身基础，也是对于行业知识的积累。<br>世界如此美丽，希望每一个人都要好好的珍惜。</p>
]]></content>
    <summary type="html">
    <![CDATA[<p>偶尔看一下中央二套的两会节目，竟然在讨论青少年上网的社会/教育问题。<br>抨击我国现状教育的不在少数，学校教育大体上就是一种“推”的教育方式，是一种社会培养人才的最重要的体系，是对未来人才的储备机制，正如宣传所说青少年就是花儿的年华。人生只有一次，家长，社会的期望终归是一]]>
    </summary>
    
      <category term="生活" scheme="http://navigating.github.io/categories/%E7%94%9F%E6%B4%BB/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[JUnit 4 实战]]></title>
    <link href="http://navigating.github.io/2006/JUnit-4-%E5%AE%9E%E6%88%98/"/>
    <id>http://navigating.github.io/2006/JUnit-4-实战/</id>
    <published>2006-12-20T03:12:38.000Z</published>
    <updated>2015-08-01T03:16:48.735Z</updated>
    <content type="html"><![CDATA[<p>尝试使用JDK 5.0进行开发，当然不能少了JUnit这个framework了。尽管在pre-release的时候我已经开始使用JUnit 4.0，真正用的时候还是翻了翻一下文档<a href="http://www.junit.org/index.htm，自己写了一个小例子。" target="_blank" rel="external">http://www.junit.org/index.htm，自己写了一个小例子。</a><br>JUnit通过Annotation的方式，让自己写完的Test Case看起来干净，简单，少了很多杂质似的。</p>
<pre><code><span class="keyword">import</span> <span class="keyword">static</span> org.junit.Assert.assertTrue;
<span class="keyword">import</span> <span class="keyword">static</span> org.junit.Assert.fail;
<span class="keyword">import</span> junit.framework.JUnit4TestAdapter;


<span class="keyword">import</span> org.junit.After;
<span class="keyword">import</span> org.junit.AfterClass;
<span class="keyword">import</span> org.junit.Before;
<span class="keyword">import</span> org.junit.BeforeClass;
<span class="keyword">import</span> org.junit.Ignore;
<span class="keyword">import</span> org.junit.Test;


<span class="comment">/**
* <span class="doctag">@author</span> Steven
* 
*/</span>
<span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">JUnit4ExampleTest</span> </span>{


      <span class="keyword">public</span> <span class="keyword">static</span> junit.framework.<span class="function">Test <span class="title">suite</span><span class="params">()</span> </span>{
            <span class="keyword">return</span> <span class="keyword">new</span> JUnit4TestAdapter(JUnit4ExampleTest.class);
      }


      <span class="annotation">@BeforeClass</span>
      <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">setUpBeforeClass</span><span class="params">()</span> <span class="keyword">throws</span> Exception </span>{
      }


      <span class="annotation">@AfterClass</span>
      <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">tearDownAfterClass</span><span class="params">()</span> <span class="keyword">throws</span> Exception </span>{
      }


      <span class="annotation">@Before</span>
      <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setUp</span><span class="params">()</span> <span class="keyword">throws</span> Exception </span>{
      }


      <span class="annotation">@After</span>
      <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">tearDown</span><span class="params">()</span> <span class="keyword">throws</span> Exception </span>{
      }


      <span class="annotation">@Test</span>
      <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">testCase</span><span class="params">()</span> </span>{
            assertTrue(<span class="keyword">true</span>);
      }


      <span class="annotation">@Test</span>(expected = RuntimeException.class)
      <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">testException</span><span class="params">()</span> </span>{
            throwException();
            fail(<span class="string">"after exception"</span>);
      }


      <span class="annotation">@Test</span>
      <span class="annotation">@Ignore</span>(<span class="string">"Ignore flag!"</span>)
      <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">testIgnore</span><span class="params">()</span> </span>{
            fail(<span class="string">"The case should be ignored."</span>);
      }


      <span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">throwException</span><span class="params">()</span> </span>{
            <span class="keyword">throw</span> <span class="keyword">new</span> RuntimeException(<span class="string">"Random"</span>);
      }


}
</code></pre><p>注：Maven2的surefire plugin对于JUnit4没有进行支持或者说仍然不兼容，这点是需要注意的。</p>
]]></content>
    <summary type="html">
    <![CDATA[<p>尝试使用JDK 5.0进行开发，当然不能少了JUnit这个framework了。尽管在pre-release的时候我已经开始使用JUnit 4.0，真正用的时候还是翻了翻一下文档<a href="http://www.junit.org/index.htm，自己写了一个小例]]>
    </summary>
    
      <category term="技术" scheme="http://navigating.github.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Miami Everglades]]></title>
    <link href="http://navigating.github.io/2006/Miami-Everglades/"/>
    <id>http://navigating.github.io/2006/Miami-Everglades/</id>
    <published>2006-11-01T03:10:54.000Z</published>
    <updated>2015-08-01T03:11:48.785Z</updated>
    <content type="html"><![CDATA[<p>原文第一次发表在：<a href="http://www.blogbus.com/navigating-logs/3745900.html" target="_blank" rel="external">http://www.blogbus.com/navigating-logs/3745900.html</a></p>
<p>周末闲暇，和同事们驱车去了Everglades，身临其境，自然风光和静谧之境，让人流连忘返。</p>
]]></content>
    <summary type="html">
    <![CDATA[<p>原文第一次发表在：<a href="http://www.blogbus.com/navigating-logs/3745900.html" target="_blank" rel="external">http://www.blogbus.com/navigating-l]]>
    </summary>
    
      <category term="生活" scheme="http://navigating.github.io/categories/%E7%94%9F%E6%B4%BB/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[失落与决断(原名: 重拾心情)]]></title>
    <link href="http://navigating.github.io/2006/%E5%A4%B1%E8%90%BD%E4%B8%8E%E5%86%B3%E6%96%AD-%E5%8E%9F%E5%90%8D-%E9%87%8D%E6%8B%BE%E5%BF%83%E6%83%85/"/>
    <id>http://navigating.github.io/2006/失落与决断-原名-重拾心情/</id>
    <published>2006-10-27T03:09:56.000Z</published>
    <updated>2015-08-01T03:10:23.928Z</updated>
    <content type="html"><![CDATA[<p>星移斗转 世事变换，不期来到了Miami；而且已经呆了快两个月了。<br>重拾心情，决定回来写BLOG了，开始多写东西；尽管这一年没有post几篇文章，可没有停止过胡思乱想，考虑未来的去向，出差来到miami做项目，经历用户的折磨，看到了异样的文化背景,异样的开发理念,异样的管理方式；休闲时间去了Disney，去了Everglades看到了Alligator，参加了美国式的party。。。。。<br>差异<br>在过去的两个多月里，感受到了完全不一样的社会文化—享受型社会，分工精细，四五十岁仍然在coding的程序员，悠闲的工作氛围和生活氛围。<br>人性<br>美国一向是个民主自由的国度，众口铄金，简直一个天堂的地方。来到这里，才发现无论任何地方，人性都是一样，是没有国界的。<br>挑战<br>一向在我的眼中，开发就是技术，软件就是技术，突然到了新的环境，周围都是数十年的软件经验，技术已经不在任何风险控制之内；都是三十岁以上的人，不需要太多复杂的过程，不需要太多的流程，管理之中充满了太多的经验的因素。一个高级管理者甚至能够随手找到几行代码和你讨论一个具体的细节问题。也见识了什么叫着一堆经验丰富的高手在一起不能作出一个好的project。<br>学习<br>很久没有静下来思考技术，学习技术，今天去深入的学习和思考CVS，内心的喜悦再一次提醒我，我需要继续前进。。。单纯的积累性的学习已经显得那么苍白无力，我们的目标在哪里，能用我们的所学能给自己留下什么，给这个世界留下什么？遗憾吗？在这一两个月的时间，一下子从公司大学式的生活中释放出来，看到了很多或者简单，或者复杂的大小摩擦，一下子感觉到这个世界是如此的复杂，到处充满了挑战；学会了要去换位思考，学会了要尊重别人的思考，给别人机会把想法讲完的机会并试图理解他，每个人都需要一个释放的窗口，总是需要不断的学习和交流。用平静的心态思考，真心的帮助每一个人是一个永远的方向，每一个人都有自己的想法，就看怎么来表达了；每一个人都是又聪明又智慧，就看他如何来使用这些聪明和智慧了。<br>美<br>最近连续的拍了很多照片，发现拍照片是一个培养一个人发现美的很好的方式。<br>选择<br>当我平静的思考自己的时候，发现人生还是很少时候是有选择的。结果往往都是很明显的，方向决定了，大不了来个殊路同归。太多的时候是我们经历的太少，见识的太少，勇敢的走出去！<br>简介<br>前一阶段看了如何使用maven2,ssh2,cvs,cruisecontrol构建一个development environment。现在正在看如何使用CVS进行项目的多团队并行开发的source code版本控制；同时在看ruby的source code.<br>下一步<br>静心学习english，看source code，看CVS，接受挑战，在这个美丽的世界上。<br>胸怀<br>想明白了我们所能选择的，想明白了我们所能失去的，想明白了我们所能付出的，想明白了我们所能留下的，想明白了我们所想要得的，enjoy所想，所说，所做。。。<br>有趣<br>有时候我们不知道自己真正想要的，却在哪里漫无目的的期待，漫无目的的辛勤积累。<br>要看软件这个行业，还是要到硅谷去，那里或许值得一看。</p>
]]></content>
    <summary type="html">
    <![CDATA[<p>星移斗转 世事变换，不期来到了Miami；而且已经呆了快两个月了。<br>重拾心情，决定回来写BLOG了，开始多写东西；尽管这一年没有post几篇文章，可没有停止过胡思乱想，考虑未来的去向，出差来到miami做项目，经历用户的折磨，看到了异样的文化背景,异样的开发理念,异样]]>
    </summary>
    
      <category term="生活" scheme="http://navigating.github.io/categories/%E7%94%9F%E6%B4%BB/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[2006年中期反思]]></title>
    <link href="http://navigating.github.io/2006/2006%E5%B9%B4%E4%B8%AD%E6%9C%9F%E5%8F%8D%E6%80%9D/"/>
    <id>http://navigating.github.io/2006/2006年中期反思/</id>
    <published>2006-08-12T03:08:04.000Z</published>
    <updated>2015-08-01T03:08:30.673Z</updated>
    <content type="html"><![CDATA[<p>一本流水账<br>1.前一段时间，换了几次机器，我就把我的数据导到了一块portal hard disk，包括我自己从去年到今年写的不少日志。这些数据随着portal hard disk一声巨响摔在地板上而销声匿迹。<br>2.考虑合同的问题，结果是和公司续约了。<br>3.dreamhead离开沈阳，去了北京。<br>4.定位项目组重组了。<br>5.学习英语.<br>6.在这近一年的项目开发之中，作为核心开发人员，实践迭代开发，试图让agile drive development，每一个月我们发布一个版本给最终用户试用，使得用户对我们的系统了解的成竹在其胸；在开发中引入了单元测试的全套方案，最大力度的进行功能单元测试和集成单元测试，开发的发布版本即是给用户的予发布版本；极力推崇简单设计，简单的解决方案；在项目组不断讨论，甚至到不带改进开发的许多细小环节；开始考虑自动build。在迭代开发，可能问题域不断的变化，对于软件的架构设计带来极大的考验，而且对于问题域的关注凸现重要出来。在项目结束之际，我们发现架构是如此重要，我们的架构是如此的脆弱，发现我们很多的软件设计没有架构或者不能称之为架构(有人把架构定义为一系列解决方案/模式的集合)，迭代要求架构的灵活性要更高。不论业务模型，架构模型，都应该有大的思想方向。<br>7.非常大的收获是vvenli送给我们的日记本，带有每天日期的日记本。在读SICP的时候，发现无论是一个规律，一个模式，都是循序渐进的积累过程。任何目标，理想，成功都不是一朝一夕的事情，在规律范围之类都是可以切分，度量的，都需要我们循序渐进的完成小单元的目标。<br>8.在最近一段时间和一些同事接触，觉得唯有好学才是进步和才力的源泉。想起诸葛亮的一句话，从google搜索下来：<br>夫君子之行，静以修身，俭以养德。非淡泊无以明志，非宁静无以致远。夫学须静也，才须学也，非学无以广才，非志无以成学。淫慢则不能励精，险躁则不能治性。年与时驰，意与日去，遂成枯落，多不接世，悲守穷庐，将复何及！<br>—&lt;&lt;诫子书&gt;&gt;<br>9.这半年书看的少，想问题想的多。<br>10.生命太短暂,太脆弱，谁都可能下一时刻看到上帝；生命需要关注眼前，需要策划。</p>
]]></content>
    <summary type="html">
    <![CDATA[<p>一本流水账<br>1.前一段时间，换了几次机器，我就把我的数据导到了一块portal hard disk，包括我自己从去年到今年写的不少日志。这些数据随着portal hard disk一声巨响摔在地板上而销声匿迹。<br>2.考虑合同的问题，结果是和公司续约了。<br>3]]>
    </summary>
    
      <category term="生活" scheme="http://navigating.github.io/categories/%E7%94%9F%E6%B4%BB/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[走向设计(To Consider Design)]]></title>
    <link href="http://navigating.github.io/2006/%E8%B5%B0%E5%90%91%E8%AE%BE%E8%AE%A1-To-Consider-Design/"/>
    <id>http://navigating.github.io/2006/走向设计-To-Consider-Design/</id>
    <published>2006-04-13T03:05:07.000Z</published>
    <updated>2015-08-01T03:05:55.954Z</updated>
    <content type="html"><![CDATA[<p>recently i always consider design:<br>1.keeping it simple,keeping it clean<br>2.coding for modularity<br>3.when working Bottom-Up,then working Top-Down.<br>4.abstract and high-cohesion,low-coupling<br>5.open one’s eyes for contract<br>today,when i’m reading the art of unix programming and get it:<br>Perfection in design is attained not when there is nothing more to add, but when there is nothing more to remove.</p>
<p>The followings from 《the art of unix programming 》-Modularity</p>
<p>There are two ways of constructing a software design. One is to make it so simple that there are obviously no deficiencies; the other is to make it so complicated that there are no obvious deficiencies. The first method is far more difficult.<br>1.Modularity:Keeping It Clean,Keeping It Simple.<br>2.Hatton himself suggests as a rule of thumb a 2x conversion between logical and physical lines, suggesting an optimal range of 400–800 physical lines.<br>3.Perfection in design is attained not when there is nothing more to add, but when there is nothing more to remove<br>4.Modularity is expressed in good code, but it primarily comes from good design.<br>5.A good API makes sense and is understandable without looking at the implementation behind it.The classic test is this: Try to describe it to another programmer over the phone. If you fail, it is very probably too complex, and poorly designed.<br>6.Coding for Modularity</p>
]]></content>
    <summary type="html">
    <![CDATA[<p>recently i always consider design:<br>1.keeping it simple,keeping it clean<br>2.coding for modularity<br>3.when working Bottom-Up,then wo]]>
    </summary>
    
      <category term="技术" scheme="http://navigating.github.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[转: How To Become A Hacker]]></title>
    <link href="http://navigating.github.io/2006/%E8%BD%AC-How-To-Become-A-Hacker/"/>
    <id>http://navigating.github.io/2006/转-How-To-Become-A-Hacker/</id>
    <published>2006-04-13T02:04:23.000Z</published>
    <updated>2015-08-01T03:06:34.274Z</updated>
    <content type="html"><![CDATA[<p>look to the master,<br>follow the master,<br>walk with the master,<br>see through the master,<br>become the master.</p>
]]></content>
    <summary type="html">
    <![CDATA[<p>look to the master,<br>follow the master,<br>walk with the master,<br>see through the master,<br>become the master.</p>
]]>
    </summary>
    
  </entry>
  
  <entry>
    <title><![CDATA[读《Managing Open Source Projects》]]></title>
    <link href="http://navigating.github.io/2006/%E8%AF%BB%E3%80%8AManaging-Open-Source-Projects%E3%80%8B/"/>
    <id>http://navigating.github.io/2006/读《Managing-Open-Source-Projects》/</id>
    <published>2006-04-05T03:01:50.000Z</published>
    <updated>2015-08-01T03:02:13.047Z</updated>
    <content type="html"><![CDATA[<p>The following are two general principles of organization:<br>People must understand the organizational structure in which they are supposed to work.<br>There has to be someone who can make final decisions. This is especially important if the project or company is in a crisis. If the ship goes down, the captain does not call for a meeting. Everyone must obey orders, know exactly where to go and what to do, and do it without argument.</p>
]]></content>
    <summary type="html">
    <![CDATA[<p>The following are two general principles of organization:<br>People must understand the organizational structure in which they are suppos]]>
    </summary>
    
      <category term="读书" scheme="http://navigating.github.io/categories/%E8%AF%BB%E4%B9%A6/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[入手《Code Complete Second Edition》]]></title>
    <link href="http://navigating.github.io/2006/%E5%85%A5%E6%89%8B%E3%80%8ACode-Complete-Second-Edition%E3%80%8B/"/>
    <id>http://navigating.github.io/2006/入手《Code-Complete-Second-Edition》/</id>
    <published>2006-04-02T03:00:36.000Z</published>
    <updated>2015-08-01T03:02:17.176Z</updated>
    <content type="html"><![CDATA[<p>昨天冒着大雨和redwood跑去华储买回了cc2e。买的时候还是有些犹豫—这本书真是太重了。我们刚买完书出来，dreamhead打电话过来他在华储正在买这本书。:)感谢redwood帮我把这本书背回了家。<br>拿到这本书我最大的期望是：我早在一年前能拿到这本书该是多么美妙的事情啊。<br>“这个世界从来就不缺少十几岁的少年天才,而三十几岁的优秀软件设计师凤毛麟角”。<br>我们重来都不缺少工程师，总是缺少尽可能多的优秀的工程师。任何想成为优秀工程师的人都不能容忍忽略这本书—cc2e的价值。(“最好是好的敌人”)<br>我们深信，这本书就是献给那些愿意成为优秀软件构造者长期以来进行不断的努力、奉献、执著追求的人。只有这样的人，才能把这么一本“砖头”饶有兴趣的读下去、读完。</p>
]]></content>
    <summary type="html">
    <![CDATA[<p>昨天冒着大雨和redwood跑去华储买回了cc2e。买的时候还是有些犹豫—这本书真是太重了。我们刚买完书出来，dreamhead打电话过来他在华储正在买这本书。:)感谢redwood帮我把这本书背回了家。<br>拿到这本书我最大的期望是：我早在一年前能拿到这本书该是多么美妙]]>
    </summary>
    
      <category term="读书" scheme="http://navigating.github.io/categories/%E8%AF%BB%E4%B9%A6/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[读《Expert One on One J2EE Development Without EJB》C2]]></title>
    <link href="http://navigating.github.io/2005/%E8%AF%BB%E3%80%8AExpert-One-on-One-J2EE-Development-Without-EJB%E3%80%8BC2/"/>
    <id>http://navigating.github.io/2005/读《Expert-One-on-One-J2EE-Development-Without-EJB》C2/</id>
    <published>2005-09-06T02:59:07.000Z</published>
    <updated>2015-08-01T02:59:44.792Z</updated>
    <content type="html"><![CDATA[<p>1.j2ee提出了规范，给出了一个标准。On the other hand, I feel it has come up short on a number of measures.j2ee也确实降低了企业应用级项目的失败。<br>2.任何规范和特定的实现都没有一个技术思想重要。如同重构的时机一样：OO原则，针对接口编程；将任何特定的规范已经实现尽量隐藏一般特性之后，比如ejb的接口隐藏在pojo之后。<br>3.在我自己的技术选择中，几乎都是选择OpenSource社区的，很少受到规范驱动或者vendor驱动的影响。正好相反，也vendor driven才造就今天的我们。:)<br>4.项目成功，检验架构的标准：<br>simplicity<br>productivity<br>the fundamental importance of object orientation<br>the primacy of business requirements<br>the importance of empirical process<br>the importance of testability<br>5.一切皆来源于经验过程。spring比Expert One-on-One J2EE还要早。(没有working code就无法写出这本书。)springframework是Rod Johnson几个商业项目的经验而产生的。开发这个framework也应该是在模式大量复用中找到了突破点,如果一些模式大量的被复用，那么把这些模式的职责转嫁给framework来做，dry原则。当然，必须优先考虑模块化的原则，比方说对于log4j的如何集成到framework的方式。<br>6.Architecture and implementation should always be undertaken with clear goals in mind.</p>
<p>Productivity<br>1.framework不断抽象，不断重构产生的,framework与代码生成的转换：If we see a requirement for boring repetitive code, we should apply an OO solution and abstract it into a framework,rather than generate it and live with the resulting duplication.<br>2.代码生成技术在解决生产率中扮着十分重要的角色。在j2ee开发中涉及到代码生成的层次很多。从dll,database schema到jsp.<br>3.There shouldn’t be vast amounts of repetitive plumbing code in J2EE applications.Better architectural choices and better frameworks can virtually eliminate such code,meaning that nearly all application code can be hand-authored.(注：framework形成的时机之一。)I’m not saying that code generation is a bad technology in general—merely that,when properly designed and built on appropriate frameworks, most J2EE applications should not contain enough boilerplate code to justify it and outweigh its negatives.<br>4.关于代码生成以及MDA作者的观点：The natural path of our industry is toward higher levels of abstraction. Perhaps one day MDA-powered code generation will prove to be an appropriate abstraction. However, I feel that this is 10–15 years away, if it ever happens.<br>5.Better Solutions for Higher Productivity：<br>Architecture<br>    Avoid unnecessary architectural complexity.<br>    Avoid unnecessary use of EJB.<br>    Use abstraction layers to hide the complexity of core J2EE and J2SE APIs.<br>    If possible, use an O/R mapping product to simplify the persistence layer.<br>    Use a good application framework.  </p>
<p>Focus and methodology<br>    Focus! Know what problems you should be solving, and concentrate on them.<br>    Use a reference architecture and start from a template application.<br>    Use an agile development process.</p>
<p>Use appropriate tools.<br>6.Different developers do the same thing in different ways, wasting<br>valuable development time and complicating maintenance.程序设计始终要做的就是不发生这样的事情。<br>7.Know What Problems to Solve 生产率即是知道要解决得是什么问题，将主要是domain problems而不是generic problems.<br>8.Use Reference Architectures and Templates一旦选择了技术，将着手reference architecture.begin work using a skeleton application that establishes the overall plumbing.<br>9.And remember that the more upfront effort before arriving at a working prototype, the greater the risk of inadequate performance or an unworkable architecture. 项目组也应该精化，微型化。<br>10.J2EE developers are fortunate in that all these requirements can be met by free, open source tools, such as Eclipse, JUnit, Ant, a good Eclipse XML plugin, CVS, and the standard Eclipse JUnit and CVS integration.</p>
<p>OO<br>1.本身OO是一种范式，是一个模型，在SICP中对于讲到代换模型的理论：In general, when modeling phenomena in science and engineering, we begin with simplified, incomplete models. As we examine things in greater detail, these simple models become inadequate and must be replaced by more refined models.关于OO的讨论算是一个检查考虑问题的讨论。<br>2.作者提出的实践中运用oo的四个方面：封装domains concepts;运用polymorphism将共性和差异分离;代码复用；extensibility.<br>3.j2ee应用的对象常常都是一些fake objects，即是不具备objects的某些特征:identity,state,behavior.<br>4.oo针对接口编程的优点和误区。</p>
<p>The importance of business requirements<br>1.这个问题因不同的角色而已。就我而言，如同我一样的普通程序员，对于generic technical problems常常都是难题，故而在这方面的需要长足的学习和提高的;对于我们而言，我们domain problems就是如何具备了generic technical方面的强大能力只是第一步。<br>The Importance of an Empirical Process<br>1.Always develop a vertical slice to validate your application’s architecture early in the project. Don’t trust our advice or anyone else’s without establishing that it’s appropriate to your needs.验证自己的想法。</p>
]]></content>
    <summary type="html">
    <![CDATA[<p>1.j2ee提出了规范，给出了一个标准。On the other hand, I feel it has come up short on a number of measures.j2ee也确实降低了企业应用级项目的失败。<br>2.任何规范和特定的实现都没有一个技术思想]]>
    </summary>
    
      <category term="读书" scheme="http://navigating.github.io/categories/%E8%AF%BB%E4%B9%A6/"/>
    
  </entry>
  
</feed>